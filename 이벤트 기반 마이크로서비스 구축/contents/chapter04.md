# Chapter 4. 기존 시스템에 이벤트 기반 아키텍처 통합
이벤트 기반 마이크로서비스로 전환한다면 먼저 이벤트 브로커에 있는 비즈니스 도메인 데이터를 이벤트 스트림으로 소비할 수 있도록 놓아주어야 한다. 이것이 바로 데이터가 포함된 기존 시스템 및 상태 저장소에서 데이터를 소싱하는 **데이터 해방 프로세스**다.

데이터를 이벤트 스트림에 생산하면 이벤트 기반이든 아니든 모든 시스템이 데이터에 접근할 수 있다. 이벤트 기반 애플리케이션은 스트리밍 프레임워크와 네이티브 컨슈머를 이용해 이벤트를 읽을 수 있지만 레거시 애플리케이션은 기술, 성능상 제약 때문에 이벤트에 접근하기 어려울 수 있다. 이럴 때는 이벤트 스트림에서 기존 상태 저장소로 이벤트를 싱크해야 한다.

## 데이터 해방이란?
**데이터 해방이란 교차 도메인 데이터 세트를 식별해서 각 이벤트 스트림에 발행하는, 이벤트 기반 아키텍처의 마이그레이션 전략의 일부분**이다. 이 때 다른 외부 시스템이 필요로 하는 데이터 저장소에 저장된 모든 데이터 역시 교차 도메인 데이터 세트에 포함된다. 따라서 기존 서비스들과 데이터 저장소 간의 점대점 디펜던시를 분석하면 해방시켜야 할 교차 도메인 데이터가 분명해진다.

<img width="567" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/e922e633-8e9c-4e02-803a-dc1d0082b8e5">

데이터를 해방하면 단일 진실 공급원을 제공하고 시스템 간 직접 결합을 방지하는, 이벤트 기반 아키텍처의 두 가지 중요한 특징이 적용된다. 해방된 이벤트 스트림 덕분에 적시에 기존 시스템을 마이그레이션하고 새로 개발한 이벤트 기반 마이크로서비스를 컨슈머로 구축할 수 있다. 본질적으로 리액티브한 이벤트 기반 프레임워크와 서비스를 이용해 데이터를 소비/처리하면 다운스트림 컨슈머가 직접 소스 데이터 시스템에 결합하지 않아도 된다.

데이터 스트림이 단일 진실 공급원 역할을 하므로 조직 전체 시스템이 데이터에 접근하는 방식 역시 표준화할 수 있다. 이제 시스템은 하부 데이터 저장소 또는 애플리케이션과 직접 결합하지 않고 이벤트 스트림의 데이터 규약만 바라보면 된다.

<img width="567" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/d46690c7-bda5-4513-b739-7ba29a51bf49">

### 데이터 해방 시 고려 사항
**데이터 세트와 해방된 이벤트 스트림은 완전히 동기화돼야 한다.** 해방된 이벤트 스트림은 반드시 똑같이 복제한 소스 테이블의 레플리카로 다시 구체화해야 하며 이런 성질은 이벤트 기반 마이크로서비스에서 아주 광범위하게 활용된다. 이와 달리, 자체 백업/복구 메커니즘이 탑재된 레거시 시스템은 이벤트 스트림에서 데이터 세트를 재구성하지 않고 실제로 해방된 이벤트 스트림에서 아무것도 다시 읽어들이지 않는다.

새 마이크로서비스와 리팩터링한 레거시 애플리케이션 모두 이벤트 브로커에 상태를 유지하는 게 가장 이상적이지만 모든 애플리케이션에서 그렇게까지 할 필요는 없고 또 실용적이지도 않다. 특히, 변경 데이터 캡처(change-data capture, CDC) 메커니즘으로 처음 한 번 통합하면 그 이후로는 리팩터링하거나 변경할 일이 거의 없을 듯한 서비스가 그렇다.

리팩터링이 절대적으로 필요한 경우지만 실천에 옮기려면 풀어야 할 숙제들이 많다.

- 개발자 지원 제약
- 리팩터링 비용
- 레거시 지원 리스크

먼저, 데이터 해방 패턴을 이용해 데이터 저장소에서 데이터를 꺼내고 필요한 이벤트 스트림을 생성한다. 이렇게 해방된 이벤트 스트림을 레거시 시스템이 읽어들일 필요는 없기 때문에 단방향 이벤트 기반 아키텍처의 형태다.

<img width="567" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/5b6f851e-fa68-4c96-b71f-fc68007b8be6">

기본적인 목표는 이벤트 데이터 발행을 엄격하게 통제함으로써 내부 데이터 세트를 외부 이벤트 스트림과 계속 동기화하는 것이다. 이벤트 스트림은 결국 언젠가 레거시 애플리케이션의 내부 데이터 세트와 동기화 된다.

<img width="542" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/cd812296-2986-4dce-90bf-72a337277fb0">

### 해방된 데이터를 이벤트로 변환
해방된 데이터도 다른 이벤트처럼 동일한 스키마화 권장 사항을 따라야 한다.

**가장 우선적으로 해방시켜야 할 데이터는 당연히 비즈니스 전반에 걸쳐 가장 연관성이 많고 자주 사용하는 데이터다.** 새 필드를 생성하거나 기존 필드를 변경/삭제하는 식으로 소스 데이터 정의를 변경하면 다운스트림 컨슈머를 따라 데이터 변경이 내리 전파된다. 해당 데이터를 명시적인 스키마로 정의하지 않으면 다운스트림 컨슈머는 호환되지 않는 부분을 어쩔 수 없이 알아서 해결해야 한다. 하지만 그렇다고 다운스트림 컨슈머가 임의로 데이터를 파싱/해석하면 안 되기 때문에 단일 진실 공급원을 제공하는 측면에서 큰 문제가 된다. 생산된 데이터에 견고한 최신 스키마를 제공하고 시간 경과에 따른 데이터의 진화를 신중하게 고려하는 것이 매우 중요하다.

## 데이터 해방 패턴
하부 데이터 저장소에서 데이터를 추출하는 데이터 해방 패턴은 크게 세 가지가 있다. 데이터를 해방하는 것은 결국 새로운 단일 진실 공급원을 만들겠다는 의도다. 따라서 마땅히 데이터 저장소에 있는 전체 데이터 세트를 담아야 하고 이후로 데이터를 삽입, 수정, 삭제하면서 계속 최신 상태로 유지해야 한다.

- 쿼리 기반
- 로그 기반
- 테이블 기반

세 가지 패턴 모두 개성이 뚜렷하지만 한 가지 공통점이 있다. **출력 이벤트 레코드 헤더에 있는 소스 레코드의 최근 업데이트 시간 컬럼을 이용해 이벤트를 타임스탬프 순서대로 생산해야 한다는 점이다.** 따라서 프로듀서가 이벤트를 발행한 시간이 아닌, 이벤트 자체가 발생한 시간이 타임스탬프로 찍힌 이벤트 스트림이 생성된다. 데이터 해방에선 실제로 이벤트가 워크플로에서 발생한 시간을 정확하게 나타낼 수 있어야 하므로 아주 중요한 문제다.

## 데이터 해방 프레임워크
데이터를 해방하는 한 가지 방법은, 데이터를 이벤트 스트림으로 추출하는 Kafka Connect, Apahce Gobblin, Apache NiFi 같은 중앙화 프레임워크를 사용하는 것이다. 이런 프레임워크를 사용하면 하부 데이터 세트를 쿼리한 결과를 출력 이벤트 스트림에 흘릴 수 있고 필요시 인스턴스를 더 추가해 CDC 작업 용량을 늘리는 식으로 확장할 수도 있다.

그러나 모든 데이터 해방 프로세스에 반드시 전용 프레임워크가 필요한 것은 아니다. 이벤트 스트림 데이털르 직접 알아서 생산하는 편이 더 적합한 시스템도 많다. 사실 데이터 해방 프레임워크는 자칫 데이터 접근 안티패턴을 조장할 우려가 있다. 내부 데이터 모델을 외부 시스템에 노출시켜 결합도가 외려 증가하고 이벤트 기반 아키텍처의 중요한 이점 중 하나가 흐려지는 가장 일반적인 안티패턴이다.

## 쿼리로 데이터 해방
데이터 저장소를 쿼리한 결과를 관련 이벤트 스트림에 흘려보내는 것이다. 클라이언트는 API, SQL, 또는 유사 SQL 언어를 이용해 데이터 저장소에서 원하는 데이터 세트를 요청한다. 데이터 세트는 최초 1회 벌크 쿼리한 다음 주기적으로 업데이트해서 변경분을 출력 이벤트 스트림에 생산한다.

### 벌크 로딩
벌크 쿼리를 실행해서 전체 데이터를 로드한다. 앞으로 계속할 증분 업데이트를 하기 직전, 그리고 각 폴링 주기마다 전체 테이블을 로드할 경우에 수행하는 작업이다.

벌크 로드는 데이터 저장소에서 전체 데이터 세트를 가져오기 때문에 비용이 많이 든다.

### 증분 타임스탬프 로딩
이전 쿼리 결과의 최종 타임스탬프 이후에 쌓인 데이털르 쿼리해서 적재한다. 최근 업데이트 시간 컬럼/필드를 기준으로 레코드가 가장 마지막에 수정된 시간을 찾아 매번 증분 업데이트할 때마다 최종 수정 시간 컬럼/필드가 이 시간 이후인 레코드만 가져온다.

### 자동증가 ID 로딩
증분 업데이틀르 할 때마다 ID 값이 마지막으로 처리한 ID보다 큰 데이터만 쿼리해서 적재한다. 선후 관계가 분명한 자동증가 정수 또는 `Long` 타입 필드가 필요하다. 아웃박스 테이블처럼 불변 레코드가 있는 테이블을 쿼리할 때 자주 사용하는 방법이다.

### 맞춤 쿼리
커스텀 쿼리, 즉 클라이언트 쿼리 언어로 제한한다. 대용량 데이터 중 일부만 필요하거나 내부 데이터 모델이 과도하게 노출되는 것을 막기 위해 여러 테이블의 데이터를 조인하고 반정규화할 때 이런 맞춤 쿼리를 사용한다. 예를 들어, 사용자가 제휴사 데이터 중 어떤 필드에 부합하는 것만 필터링해서 각 제휴사별 이벤트 스트림으로 보내는 경우 알맞은 방식이다.

### 증분 업데이트
증분 업데이트를 하려면 먼저 데이터 세트의 레코드에 필요한 타임스탬프나 자동 증가 ID를 생성해야 한다. 쿼리가 아직 처리하지 않은 레코드에서 이미 처리한 레코드를 필터링하려면 이런 필드가 꼭 필요하다. 만약 최근 업데이트 시간 컬럼이나 자동증가 ID 필드가 없으면 데이터 저장소가 알아서 추가해서 채우도록 설정한다. 이런 필드를 데이터 세트에 추가할 수 없다면 쿼리 기반 패턴의 증분 업데이트는 불가능하다.

다음으로, 폴링 빈도와 업데이트 지연 시간을 정해야 한다. 업데이트를 자주하면 다운스트림 데이터를 업데이트하는 지연이 줄어드는 반면, 데이터 저장소에 걸리는 총 부하량이 늘어난다. 요청 간격이 전체 데이터를 로드하기에 충분한지도 잘 살펴봐야 한다. 앞 쿼리가 아직 로드중인데 쿼리를 또 시작하면 옛 데이터가 출력 이벤트 스트림의 새 데이터를 덮어 쓰는 경합 조건이 발생할 수 있다.

증분 업데이트 필드와 업데이트 빈도가 결정되면 마지막으로 벌크 로드를 1회 수행한다.

### 쿼리 기반 업데이트의 장점
- 맞춤성
- 독립적인 폴링 주기
- 내부 데이터 모델의 격리

### 쿼리 기반 업데이트의 단점
- 최종 업데이트 시간 타임스탬프가 필수다.
- 하드 삭제 추적 불가 → 플래그 기반의 소프트 삭제만 추적 가능하다.
- 데이터 세트 스키마, 출력 이벤트 스키마 간의 취약한 의존 관계
- 간헐접 캡처
- 생산 리소스 낭비
- 데이터 변경 때문에 쿼리 성능이 오르락내리락한다.

## CDC 로그로 데이터 해방
**데이터 저장소에 내장된 CDC 로그(MySQL의 BINLog, PostgresSQL의 write-ahead log) 기능을 활용하는 방법이다.** 시간 경과에 따라 데이터 세트에 발생한 모든 일을 붙임 전용 로그 형태로 남기는 것이다. 대상은 개별 레코드의 생성, 수정, 삭제는 물론 각 데이터 세트 및 스키마의 생성, 수정, 삭제까지 해당된다.

모든 데이터 저장소가 불변의 변경 로깅 기능을 지원하는 것은 아니므로 CDC는 쿼리로 캡처하는 것에 비해 기술 선택의 폭은 좁다. 그래서 이 방법은 주로 MySQL, PostgresSQL 등 몇몇 RDB에서만 가능하지만 포괄적인 변경 로그 세트가 탑재된 데이터 저장소라면 고려해봄직하다. 최신 데이터 저장소 대부분은 물리적 로그 선행 기입(WAL)의 프록시 역할을 하는 이벤트 API를 표출한다. MongoDB는 체인지 스트림즈라는 인터페이스를 제공한다.

데이터 저장소 로그는 어마어마하게 커질 가능성이 높고 따로 장기 보관할 필요는 없기 때문에 처음부터 발생한 변경 기록을 전부 포함하고 있지는 않다. 그래서 **데이터 저장소 로그에서 CDC 프로세스를 시작하기 전에 기존 데이터의 스냅샷을 찍어야 한다.** 흔히 부트스트래핑이라 부르는 이 작업은 대개 성능에 영향을 미칠 정도의 대용량 쿼리가 수반되므로 부트스트랩한 쿼리 결과에 있는 레코드와 로그에 쌓인 레코드를 정확히 중첩시켜 혹시라도 실수로 레코드를 빠뜨리는 일이 없도록 해야 한다.

changelog에서 이벤트를 캡처하면 체크포인트를 전진시켜야 한다. 체크포인트는 CDC 장애 발생 시 마지막으로 저장된 체인지로그 인덱스를 복구하는 용도로 쓰인다. 적어도 한 번 이상 레코드를 제공할 수 있기 때문에 엔티티 기반의 데이터 해방 시 적절한 방법이다. 엔티티 데이터를 업데이트하는 행위는 멱등적이라서 추가 레코드 생산은 중요하지 않다.

<img width="524" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/c7e00427-2d5f-4649-beb0-5bf2e508ec96">

### 데이터 저장소 로그의 장점
- 삭제 추적
- 데이터 저장소 성능에 미치는 영향 최소화
- 저지연 업데이트

### 데이터 저장소 로그의 단점
- 내부 데이터 모델 노출
- 데이터 저장소 외부에서 반정규화  
  체인지로그에는 이벤트 데이터만 들어있다. 구체화 뷰에서 이벤트를 추출할 수 있는 CDC 메커니즘도 있지만 대부분 데이터 저장소 외부에서 반정규화가 일어난다. 따라서 고도로 정규화한 이벤트 스트림을 생성해야 할 수도 있는데, 그러러면 다운스트림 마이크로서비스가 외래 키 조인 및 반정규화를 처리해야 한다.
- 데이터 세트 스키마와 출력 이벤트 스키마 사이의 취약한 의존 관계

## 아웃박스 테이블로 데이터 해방
아웃박스 테이블에는 데이터 저장소의 내부 데이터에 관한 중요한 업데이트가 로우 단위로 삽입된다. CDC 대상으로 표시된 데이터 저장소에서 테이블 레코드가 삽입, 수정, 삭제될 때마다 해당 레코드가 아웃박스 테이블에 발행되는 구조다. CDC하는 테이블마다 자체 아웃박스 테이블을 두거나, 모든 변경분을 하나의 아웃박스 테이블에 기록한다.

내부 테이블의 업데이트와 아웃박스 테이블의 업데이트는 단일 트랜잭션으로 묶어 트랜잭션 성공 시에만 두 업데이트가 일어나게 한다. 그렇지 않으면 단일 진실 공급원 역할을 하는 이벤트 스트림이 결국 여러 갈래로 쪼개져 데이터를 관리하기 어렵다. 이 패턴은 데이터 저장소나 애플리케이션 레이어 중 한 군데는 수정해야 하는데 둘 다 데이터 저장소 개발자가 개입해야 하므로 CDC보다 더 침습적인 접근 방법이라 할 수 있다. 아웃박스 테이블 패턴은 데이터 저장소의 보존성을 십분 활용하여 외부 이벤트 스트림에 발행 대기 중인 이벤트를 선행 기입 로깅하는 기능을 제공한다.

아웃박스 테이블에서는 PK가 동일한 레코드가 짧은 시간 동안 여러 번 업데이트될 수 있으므로 정렬 식별자가 명확해야 한다. 이전에 동일한 PK로 업데이트된 레코드를 덮어 써도 되지만 그 레코드를 먼저 찾아야 하는 만큼 성능 오버헤드가 발생한다. 그리고 덮어 쓴 레코드는 다운스트림으로 흘러가지 않을 것이다.

**삽입 시 할당되는 자동증가 ID는 이벤트 발행 순서를 정하는 최적의 수단이다.** 데이터 저장소에서 레코드가 생성된 이벤트 시간을 가리키고 이벤트 스트림에 발행하는 동안 walkclock time으로 대용 가능한 생성 시간(`created_at`) 컬럼도 함께 보관해야 한다.

<img width="573" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/ab22ae5d-4b55-4b24-9479-e6814c43c0d3">

위 그림은 종단간 워크플로를 나타낸 것이다. **데이터 저장소 클라이언트는 내부 테이블의 업데이트, 아웃박스 테이블의 업데이트를 각각 하나의 트랜잭션으로 묶어 처리하므로 도중 실패하더라도 두 테이블 간 데이터 정합성이 유지된다.**

한편, 이와 별도의 애플리케이션 스레드나 프로세스는 아웃박스 테이블을 계속 폴링해서 해당 이벤트 스트림에 데이터를 생산한다. 여기까지 성공하면 아웃박스 테이블의 레코드는 삭제된다. 만약 실패하더라도 아웃박스 테이블의 레코드는 소실되는 일 없이 보존될 것이다. 이 패턴은 적어도 한 번 이상 전달을 보장한다.

### 성능 고려 사항
아웃박스 테이블이 위치한 데이터 저장소와 그 요청을 처리하는 애플리케이션의 부하가 가중된다. 부하가 적은 소규모 데이터 저장소라면 미미한 수준이겠지만 대규모 데이터 저장소, 특히 부하가 엄청나고 캡처할 테이블이 많은 경우 비용이 많이 들 것이다. 그때그때 상황에 맞게 비용을 잘 따져보고 CDC 로그 파싱 같은 대응 전략의 비용과 균형을 맞춰야 한다.

### 내부 데이터 모델 격리
**아웃박스 테이블을 내부 테이블과 1:1 매핑할 필요는 없다.** 사실 아웃박스 테이블의 중요한 장점은 데이터 저장소 클라이언트가 다운스트림 컨슈머에 대해 내부 데이터 모델을 격리할 수 있다는 점이다.

도메인 내부 데이터 모델은 관계형 작업에는 최적화되어 있지만 대체로 다운스트림 컨슈머가 소비하기에 적당하지 않은, 고도로 정규화된 많은 테이블들로 이루어져 있을 것이다. 도메인은 단순하지만 다수의 테이블로 구성되어 있어 독립적인 스트림으로 표출하려면 다운스트림 컨슈머가 사용할 수 있게 재구성해야 하는 경우도 있다.

데이터 저장소 클라이언트는 아웃박스 테이블에 퍼블릭 데이터 규약을 잘 반영되도록 삽입 시점에 데이터를 반정규화할 수 있다. 저장 공간을 더 차지하고 성능이 떨어지는 부분은 감수해야 한다. 변경분과 출력 이벤트 스트림을 계속 1:1로 매핑하고 전용 다운스트림 이벤트 처리기를 이용해 스트림을 반정규화하는 방법도 있다. 이렇게 하면 고도로 정규화한 관계형 데이터를 쉽게 소비할 수 있는 하나의 이벤트로 바꿀 수 있는데, 이런 프로세스를 이벤트화라고 부른다.

<img width="578" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/8da8a27e-8af3-4c1e-84f2-457bd4b9e02c">

위 과정은 User 엔티티를 반정규화하고 내부 데이터 모델의 구조를 흔적도 없이 벗겨냄으로써 사용자 정보를 이벤트화하는 셈이다. 이런 작업을 하려면 User, Location, Employer 각각의 구체화 테이블을 유지해서 나중에 업데이트가 발생하면 조인 로직을 다시 실행하여 영향받는 모든 User 업데이트를 다운스트림으로 흘려보내야 한다. 최종 이벤트는 결국 모든 다운스트림 컨슈머가 소비 가능한 조직의 퍼블릭 네임스페이스로 보내질 것이다.

내부 데이터 모델의 격리는 서비스 간 결합을 끊고 독립성을 보장하기 위해, 업스트림 내부 데이터 모델의 변경이 아닌 새로운 비즈니스 요건에 의해서만 시스템이 변경되도록 보장하기 위해 꼭 필요한 작업이다.

### 스키마 호환성 보장
스키마 직렬화 그리고 검증 역시 캡처 워크플로에 구현할 수 있다. 아웃박스 테이블에 이벤트가 기록되기 전후에 수행하면 된다.

데이터 일관성 측면에선 아웃박스 테이블에 트랜잭션을 커밋하기 전에 직렬화하는 것이 가장 강력하다. 직렬화가 실패하면 결국 트랜잭션도 실패할 테니 내부 테이블에 작업한 모든 변경분을 롤백시켜 아웃박스 테이블과 내부 테이블의 동기화를 유지하면 된다.

<img width="509" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/560612c6-acb4-4dfc-823e-a91cac5b618a">

별다른 문제가 없으면 이벤트는 직렬화되고 이벤트 스트림에 발행될 준비가 끝난다. 이렇게 처리하면 내부 상태와 출력 이벤트 스트림 간에 데이터 정합성이 안 맞을 가능성이 현저히 줄어든다. 이벤트 스트림 데이터를 일급 시민으로 취급함으로써 일관된 내부 상태를 유지하는 것만큼 데이터를 정확하게 발행하는 일을 중요시하게 된다.

**아웃박스 테이블에 쓰기 전에 직렬화하면 모든 트랜잭션을 하나의 아웃박스 테이블로 사용할 수 있다.** 거의 대부분 타깃 출력 이벤트 스트림이 매핑된 직렬화 데이터라서 포맷은 단순하다.

<img width="568" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/2cec4585-30b9-45e5-8d5d-1be57b37ae11">

그러나 발행하기 전에 직렬화하면 직렬화 오버헤드 때문에 성능이 떨어질 수 있다.

아웃박스 테이블에 이벤트를 쓴 다음 발행하는 방법도 있다.

<img width="463" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/a21000dc-ca03-4ba3-8f62-1bc28c25d564">

이 방법은 보통 도메인 모델 당 하나씩, 출력 이벤트 스트림의 퍼블릭 스키마에 매핑된 독립적인 아웃박스 테이블을 둔다. 발행기 프로세스는 아웃박스 테이블에서 아직 직렬화되지 않은 이벤트를 읽어 그 이벤트의 스키마로 직렬화한 다음, 출력 이벤트 스트림에 이벤트를 생산한다.

<img width="574" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/593e4e19-ed53-4813-8161-b6d815f063bb">

만약 직렬화 과정에서 실패한다면 이는 스키마를 준수하지 않아 발행 불가한 이벤트라는 뜻이다. 그래서 이 방식이 관리하기 더 어렵다. 이미 완료된 트랜잭션이 비호환 데이터를 아웃박스 테이블에 푸시했다면 트랜잭션이 확실하게 롤백되리란 보장이 없기 때문이다.

결국 실제로 아웃박스 테이블에는 직렬화 안 되는 이벤트가 많이 쌓일 것이다. 그중 일부라도 복구하려면 사람이 개입해야겠지만 시간도 많이 걸리고 작업이 어려울뿐더러 추가 이슈를 예방하려면 중단 시간이 늘어나게 된다. 게다가 이미 발행이 완료된 호환 이벤트도 있을 테니 출력 스트림에서 이벤트 순서가 어긋날 가능성이 있어 골치가 아프다.

**이벤트 스트림에 쓰기 전에 데이터를 검증한 다음 직렬화하면 출력 이벤트 스트림과 소스 데이터 저장소 간 데이터의 최종 일관성을 보장할 수 있고 소스 쪽 내부 데이터 모델도 계속 격리할 수 있다. 이것이 바로 CDC 솔루션의 가장 강력한 기능이다.**

#### 이벤트를 아웃박스 테이블로 생산하면 좋은 점
- 다수의 언어 지원
- 사전 스키마 강화
- 내부 데이터 모델 격리
- 반정규화

#### 이벤트를 아웃박스 테이블로 생산하면 나쁜 점
- 애플리케이션 코드 변경 필수
- 비즈니스 프로세스 성능에 영향을 미친다
- 데이터 저장소 성능에 영향을 미친다

### 변경-데이터를 트리거로 캡처
구형 관계형 DB는 대부분 감사 테이블 생성 수단으로 트리거를 사용한다. 트리거는 정해진 조건에서 자동 실행되도록 설정한다. 트리거가 실패할 경우 트리거를 일으킨 커맨드도 실패하기 때문에 원자적 업데이트가 보장된다.

`AFTER` 트리거를 사용하면 감사 테이블의 로우 레벨 변경을 캡처할 수 있다. 가령, `INSERT`, `UPDATE`, `DELETE` 커맨드를 실행하면 트리거는 변경된 로우를 포착해 변경-데이터 테이블에 기록하면 특정 테이블의 변경 사항을 추적할 수 있다.

<img width="554" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/6d068734-1c8e-4c81-b09f-fd9da773f355">

일반적으로 트리거 실행 중에는 이벤트 스키마로 변경-데이터를 검증할 수 없지만 아예 불가능한 것은 아니다. 다만 트리거는 DB 내부에서 실행되므로 지원 자체가 안 되거나, 지원되더라도 트리거가 지원하는 언어 형태로 한정되는 경우가 많다.

<img width="509" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/e3348cbd-a438-4649-95e3-7760c4b807d3">

CDC 테이블 스키마는 내부 테이블 스키마와 출력 이벤트 스트림 스키마를 연결하는 징검다리 역할을 한다. 출력 이벤트 스트림에 성공적으로 데이터를 생성하려면 이 세 가지 모두 궁합이 잘 맞아야 한다. 출력 스키마는 보통 트리거 실행 중에 검증하지 않기 때문에 변경-데이터 테이블을 출력 이벤트 스키마 포맷으로 동기화하는 것이 가장 좋다.

#### 트리거를 사용하면 좋은 점
- 대부분 DB가 지원
- 데이터 규모가 작을 경우 오버헤드가 낮다
- 맞춤 로직 가능

#### 트리거를 사용하면 나쁜 점
- 성능 오버헤드
- 변경 관리가 복잡하다
- 확장성이 좋지 않다
- 사후 스키마 강화

## 데이터 정의 변경을 캡처 대상 데이터 세트로
데이터 해방 프레임워크에서 데이터 정의 변경까지 통합하는 작업은 쉽지 않다. 대부분의 관계형 DB에선 컬럼 추가, 삭제, 이름 변경, 타입 변경, 기본값 추가/삭제 등을 통해 데이터 정의를 변경하는데 이런 변경 사항을 캡처함으로써 데이터 마이그레이션을 수행하는 것이 보통이다. 그러나 데이터를 해당된 이벤트 스트림으로 생산할 때는 이런 작업들이 문제를 일으킬 수 있다.

가령, 양방향 스키마 진화 호환성이 필요한 경우 옛 스키마를 사용하는 컨슈머는 필드에 어떤 값이 있으리라 기대하므로 캡처할 데이터 세트에 기본값이 없는 널 금지 컬럼은 뺄 수 없다. 규약을 정한 시점엔 아무것도 명시된 바 없으니 컨슈머는 어떤 기본값을 대신 사용할 수 없고 따라서 결국 모호한 상태가 될 것이다. 비호환 변경이 반드시 필요하고 데이터 규약을 근본적으로 깨뜨릴 수 밖에 없는 경우 데이터 프로듀서/컨슈머는 반드시 새로운 데이터 규약을 체결해야 한다.

DDL 변경 캡처는 변경-데이터를 캡처하기 위해 사용하는 통합 패턴에 의존한다. DDL 변경 시 다운스트림 컨슈머에게 큰 영향을 미칠 수 있으므로 캡처 패턴이 DDL 변경을 사전에 감지하는지, 사후에 감지하는지 파악하는게 중요하다.

### 쿼리 패턴, CDC 로그 패턴: 사후 데이터 정의 변경 처리
**쿼리 패턴에서는 쿼리 시점에 스키마를 가져와 이벤트 스키마를 추론할 수 있다.** 새로운 이벤트 스키마는 스키마 호환성 규칙을 이용해 출력 이벤트 스트림의 스키마와 비교하면 된다. 이런 메커니즘은 Kafka Connect의 경우처럼 다양한 쿼리 커넥터에서 사용된다.

**CDC 로그 패턴에서는 데이터 정의 업데이트를 CDC 로그의 일부로 캡처한다.** 즉, 데이터 정의 변경을 로그에서 추출해 데이터 세트의 스키마 표현형으로 추론하는 것이다. 스키마가 일단 생성된 이후엔 다운스트림 이벤트 스키마와 비교/검증하면 된다. 그러나 이 기능은 아직 제한적이며 현재 데베지움 커넥터는 MySQL의 데이터 정의 변경만 지원한다.

### 변경-데이터 테이블 캡처 패턴: 데이터 정의 변경 처리
변경-데이터 테이블은 내부 상태 스키마와 출력 이벤트 스트림 스키마를 연결하는 징검다리 역할을 한다. 애플리케이션 검증 코드나 DB 트리거가 하나라도 짝이 안 맞으면 스택에 오류가 쌓이고 변경-데이터 테이블에 데이터가 기록되지 않는다. CDC 테이블을 수정하려면 그에 맞는 스키마 호환성 규칙에 따라 출력 이벤트 스트림과 호환되는 스키마를 정의해야 한다. 두 단계로 구성된 이 작업 덕에 예기치 않은 변경이 프로덕션에 스며들 가능성이 현저히 줄어드는 효과가 있다.

## 이벤트 데이터를 데이터 저장소에 싱킹
이벤트 스트림 데이터는 이벤트 데이터를 소비해서 데이터 저장소에 삽입하는 싱킹을 수행한다. 일반적으로 싱킹은 중앙화 프레임워크나 단독형 마이크로서비스를 이용해서 수행하며 엔티티, 키 있는 이벤트, 키 없는 이벤트 등 어떤 유형의 이벤트 데이터라도 데이터 저장소에 저장할 수 있다.

**이벤트 싱킹은 이벤트 기반으로 개발되지 않은 애플리케이션을 이벤트 스트림과 통합할 때 특히 유용하다.** 싱크 프로세스는 이벤트 브로커에서 이벤트 스트림을 읽어들여 지정된 데이터 저장소에 데이터를 삽입한다. 또 이벤트 기반이 아닌 애플리케이션과 완벽하게 독립적으로 작동되면서 자신의 소비 오프셋을 추적하고 이벤트 데이터가 도착하는 대로 데이터 저장소에 쓴다.

이벤트 싱킹은 주로 레거시 시스템 간의 직접적인 점대점 결합을 대체하는 용도로 쓰인다. 소스 시스템의 데이터를 일단 이벤트 스트림으로 해방하면 별다른 변경 없이도 목적지 시스템 에 싱크할 수 있다. 싱크 프로세스는 목적지 시스템에 대해 외부적으로 투명하게 작동된다.
데이터 싱킹은 배치 기반의 빅데이터 분석을 수행하는 팀에서도 자주 활용된다. 빅데이터 분석자들은 보통 분석 도구를 제공하는 하둡 분산 파일 시스템 (HDFS)에 데이터를 싱크한다.

카프카 커넥트 같은 공통 플랫폼을 사용하면 간단한 설정만으로 싱크 프로세스를 구성해서 공유 인프라에 올려놓고 실행할 수 있다. 물론 단독형 마이크로서비스를 개발해서 해당 플랫폼에서 실행하고 독립적으로 관리하는 방법도 얼마든지 가능하다.

## 싱킹과 소싱의 비즈니스 영향도
중앙화 프레임워크를 사용하면 데이터를 빠르게 해방할 수 있지만, 팀 간의 데이터 소싱/싱킹 책임 공유와 시스템의 프레임워크와 커넥터에 대한 의존성 증가 등의 문제가 발생할 수 있다.

이러한 문제를 해결하기 위해서는 CDC 프레임워크의 역할을 제대로 인식하고, 팀 스스로 CDC를 구현하도록 하여 팀 간의 의존 관계를 없애야 한다. 이를 통해 CDC 프레임워크 운영팀의 역할을 최소화하고, 이벤트 스트림을 단순히 모놀리스끼리 데이터를 주고받는 수단으로 보는 것이 아니라 전체 이벤트 기반 체계에 동참해야 한다.

또한, 조직 구성원들은 데이터 통신 레이어에 투자를 해야 하며, 데이터 품질이 좋아야 가치가 있다는 것을 인식해야 한다.

마지막으로, 이벤트 기반 아키텍처로 나아가기 위해서는 데이터 통신 레이어 내부의 데이터 품질과 스키마, 데이터 모델, 순서, 지연 등에 관한 SLA를 명확하게 도출해야 한다.