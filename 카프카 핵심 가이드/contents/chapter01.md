# Chapter 1. 카프카 시작하기
## 발행/구독 메시지 전달
Apache Kafka의 특징에 대해 설명하기 전에, 발행/구독 메시지 전달(publish/subscribe messaging)의 개념과 데이터 주도 애플리케이션에서의 중요성을 이해할 필요가 있다.

발행/구독 메시지 전달 패턴의 특징은 전송자가 데이터를 보낼 때 직접 수신자로 보내지 않는다는 것이다. 대신, 전송자는 어떤 형태로든 메시지를 분류해서 보내고, 수신자는 이렇게 분류된 메시지를 구독한다. 발행/구독 시스템에는 대개 발행된 메시지를 전달받고 중계해주는 중간 지점 역할을 하는 **브로커(broker)** 가 있다.

### 초기의 발행/구독 시스템
발행/구독 패턴을 따르는 많은 사례들은 비슷한 형태로 시작한다. 즉, 가운데 간단한 메시지 큐나 프로세스 간 통신 채널을 놓는 것이다.

발행자와 구독자가 직접 연결된 단일 지표 발행자 → 발행자와 구독자가 직접 연결된 여러 지표 발행자 → 지표 발행 및 구독 시스템으로 점차 개선한다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/3f567130-12de-4f5f-a7eb-8bca51c12d7d)

### 개별 메시지 큐 시스템
지표를 다루는 것과 동시에 로그 메시지에 대해서도 비슷한 작업을 해줘야 한다. 또한, 프론트엔드 웹사이트에서의 사용자 활동을 추적해서 이 정보를 기계 학습 개발자에게 제공하거나 관리자용 보고서를 생성하는 데 사용해야 할 수도 있다. 이러한 경우에도 비슷한 시스템을 구성함으로써 정보의 발행자와 구독자를 분리할 수 있다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/aff7da52-eb7d-4efd-b1c3-c0744c3f58f0)

초기의 포인트 투 포인트 연결을 활용하는 방식보다 이쪽이 명백히 더 바람직하지만, 여기에는 중복이 많다. 이렇게 되면 버그도 한계도 제각각인 다수의 데이터 큐 시스템을 유지 관리해야 한다. 여기에 메시지 교환을 필요로 하는 사례가 추가로 생길 수도 있다. 비즈니스가 확장됨에 따라 함께 확장되는, 일반화된 유형의 데이터를 발행하고 구독할 수 있는 중앙 집중화된 시스템이 필요하다.

## 카프카 입문
아파치 카프카는 위에서 설명한 것과 같은 문제를 해결하기 위해 고안된 메시지 발행/구독 시스템이다. '분산 커밋 로그' 혹은 '분산 스트리밍 플랫폼'이라 불리기도 한다.

파일 시스템이나 데이터베이스 커밋 로그는 모든 트랜잭션 기록을 지속성 있게 보존함으로써 시스템의 상태를 일관성 있게 복구할 수 있도록 고안되었다. 이와 유사하게, **카프카에 저장된 데이터는 순서를 유지한 채로 지속성 있게 보관되며 결정적으로 읽을 수 있다.** 또한, 확장시 성능을 향상시키고 실패가 발생하더라도 데이터 사용에는 문제가 없도록 시스템 안에서 데이터를 분산시켜 저장할 수 있다.

### 메시지와 배치
- **카프카에서 데이터의 기본 단위는 메시지다.**
- 카프카의 입장에서 메시지는 **단순한 바이트의 배열**일 뿐이기 때문에 여기에 포함된 데이터는 특정한 형식이나 의미가 없다.
- 메시지는 **키**라 불리는 메타데이터를 포함할 수도 있다. 키는 메시지를 저장할 파티션을 결정하기 위해 사용된다.
- 카프카는 효율성을 위해 메시지를 **배치(batch)** 단위로 저장한다. 배치는 그저 같은 토픽의 파티션에 쓰여지는 메시지들의 집합일 뿐이다.
  - 메시지를 쓸 때마다 네트워크상에서 신호가 오가는 것은 막대한 오버헤드를 발생시키는데, 메시지를 배치 단위로 모아서 쓰면 이것을 줄일 수 있다.
  - 배치 크기가 커질 수록 시간당 처리되는 메시지의 수는 늘어나지만, 각각의 메시지가 전달되는 데 걸리는 시간은 늘어난다.

### 스키마
카프카 입장에서 메시지는 단순한 바이트 배열일 뿐이지만, 내용을 이해하기 쉽도록 일정한 구조(혹은 스키마)를 부여하는 것이 권장된다. 가장 간단한 방법으로는 JSON이나 XML이 있다.

카프카에서는 일관적인 데이터 형식이 중요하다. 메시지 쓰기와 읽기 작업을 분리할 수 있도록 해주기 때문이다. 만약 이 작업들이 서로 결합되어 있다면 우선 메시지를 구독하는 애플리케이션들 먼저 구버전과 신버전 형식을 동시에 함께 지원할 수 있도록 업데이트되어야 할 것이며, 그 다음에야 메시지를 발행하는 애플리케이션이 신버전 형식을 사용하도록 업데이트 될 수 있을 것이다.

잘 정의된 스키마를 공유 저장소에 저장함으로써 카프카는 두 버전 형식을 동시에 지원하도록 하는 작업 없이도 메시지를 처리할 수 있다.

### 토픽과 파티션
- **카프카에 저장되는 메시지는 토픽(topic) 단위로 분류된다.**
- **토픽은 다시 여러 개의 파티션(partition) 으로 나눠진다.**
- 파티션에 메시지가 쓰여질 때는 추가만 가능한 형태로 쓰여지며, 읽을 때는 맨 앞부터 제일 끝까지의 순서로 읽힌다.
- **대개 토픽에 여러 개의 파티션이 있는 만큼 토픽 안의 메시지 전체에 대해 순서는 보장되지 않으며, 단일 파티션 안에서만 순서가 보장될 뿐이다.**
- 파티션은 카프카가 데이터 중복과 확장성을 제공하는 방법이기도 하다. 각 파티션이 서로 다른 서버에 저장될 수 있기 대문에 하나의 토픽이 여러 개의 서버로 수평적으로 확장되어 하나의 서버의 용량을 넘어가는 성능을 보여줄 수 있다.
- 파티션은 복제될 수 있다. 즉, 서로 다른 서버들이 동일한 파티션의 복제본을 저장하고 있기 때문에 서버 중 하나에 장애가 발생한다고 해서 읽거나 쓸 수 없는 상황이 벌어지지는 않는다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/24f98694-5f87-4800-b199-2c2d737b74c4)

### 프로듀서와 컨슈머
카프카 클라이언트는 이 시스템의 사용자이며, 기본적으로 프로듀서와 컨슈머의 두 종류가 있다. 고급 클라이언트 API도 있는데, 데이터 통합에 사용되는 Kafka Connect API와 스트림 처리에 사용되는 카프카 스트림즈가 그것이다.

**프로듀서는 새로운 메시지를 생성한다.** 메시지는 특정한 토픽에 쓰여진다. **기본적으로 프로듀서는 메시지를 쓸 때 토픽에 속한 파티션들 사이에 고르게 나눠서 쓰도록 되어 있다.** 하지만 어떠한 경우에는, 프로듀서가 특정한 파티션을 지정해서 메시지를 쓰기도 한다. 이것은 대개 메시지 키와 키값의 해시를 특정 파티션으로 대응시켜주는 **파티셔너**를 사용해서 구현된다. 이렇게 함으로써 동일한 키 갑을 가진 모든 메시지는 같은 파팃녀에 저장되게 한다.

**컨슈머는 메시지를 읽는다.** **컨슈머는 1개 이상의 토픽을 구독해서 여기에 저장된 메시지들을 각 파티션에 쓰여진 순서대로 읽어 온다.** 컨슈머는 **메시지의 오프셋을 기록함으로써 어느 메시지까지 읽었는지를 유지한다.**

오프셋은 지속적으로 증가하는 정수값으로, 카프카가 메시지를 저장할 때 각각의 메시지에 부여해주는 또 다른 메타데이터이다. 주어진 파티션의 각 메시지는 고유한 오프셋을 가지며, 뒤에 오는 메시지가 앞의 메시지보다 더 큰 오프셋을 가진다.(반드시 단조증가할 필요는 없다) 파티션별로 다음 번에 사용 가능한 오프셋 값을 저장함으로써 컨슈머는 읽기 작업을 정지했다가 다시 시작하더라도 마지막으로 읽었던 메시지의 바로 다음 메시지부터 읽을 수 있다.

컨슈머는 **컨슈머 그룹(consumer group)** 의 일원으로서 작동한다. 컨슈머 그룹은 토픽에 저장된 데이터를 읽어오기 위해 협업하는 하나 이상의 컨슈머로 이루어진다. **컨슈머 그룹은 각 파티션이 하나의 컨슈머에 의해서만 읽히도록 한다.**

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/1bd211cd-5bb9-4239-b2d5-7e270ff8a55c)

컨슈머에서 파티션으로의 대응 관계는 컨슈머의 파티션 소유권이라고도 부른다.

이 방법을 사용함으로써 대량의 메시지를 갖는 토픽들을 읽기 위해 컨슈머들을 수평 확장할 수 있다. 또한, 컨슈머 중 하나에 장애가 발생하더라도, 그룹 안의 다른 컨슈머들이 장애가 발생한 컨슈머가 읽고 있던 파티션을 재할당받은 뒤 이어서 데이터를 읽어올 수 있다.

### 브로커와 클러스터
**하나의 카프카 서버를 브로커라 부른다.** 브로커는 **프로듀서로부터 메시지를 전달받아 오프셋을 할당한 뒤 디스크 저장소에 쓴다.** 브로커는 컨슈머의 파티션 읽기 요청 역시 처리하고 발행된 메시지를 보내준다. 시스템 하드웨어의 성능에 따라 다르겠지만, 하나의 브로커는 초당 수천 개의 파티션과 수백만 개의 메시지를 쉽게 처리할 수 있다.

카프카 브로커는 클러스터의 일부로서 작동하도록 설계되었다. 하나의 클러스터 안에 여러 개의 브로커가 포함될 수 있으며, 그중 하나의 브로커가 클러스터 컨트롤러의 역할을 하게 된다.

- 컨트롤러는 파티션을 브로커에 할당해주거나 장애가 발생한 브로커를 모니터링하는 등의 관리 기능을 담당한다.
- 파티션은 클러스터 안의 브로커 중 하나가 담당하며, 그 브로커를 파티션 리더라고 부른다.
- 복제된 파티션이 여러 브로커에 할당될 수도 있는데 이것들은 파티션의 팔로워라 부른다.
- 복제 기능은 파티션의 메시지를 중복 저장함으로써 리더 브로커에 장애가 발생했을 때 팔로워 중 하나가 리더 역할을 이어받을 수 있도록 한다.
- 모든 프로듀서는 리더 브로커에 메시지를 발행해야 하지만, 컨슈머는 리더나 팔로워 중 하나로부터 데이터를 읽어올 수 있다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/a3101327-31ed-49e9-b643-49eaf12feb14)

아파치 카프카의 핵심 기능 중 일정 기간 동안 메시지를 지속성 있게 보관하는 보존 기능이 있다. **카프카 브로커는 토픽에 대해 기본적인 보존 설정**이 되어 있는데, 특정 기간동안 메시지를 보존하거나 파티션의 크기가 특정 사이즈에 도달할 때까지 데이터를 보존한다. 이러한 한도값에 도달하면 메시지는 만료되어 삭제된다.

이렇게 보존 설정은 어떤 시점에 있어서건 사용 가능한 최소한의 데이터 양을 정의한다. 각각의 토픽에는 메시지가 필요한 정도까지만 저장되도록 보존 설정을 잡아줄 수 있다. 예를 들어, 사용자 활동 추적 토픽은 며칠 동안 유지할 수 있는 반면, 애플리케이션 지표는 겨우 몇 시간만 보존할 수 있는 것이다. 토픽에는 **로그 압착** 기능을 설정할 수도 있는데, 이 경우 같은 키를 갖는 메시지 중 가장 최신의 것만 보존된다. 이 기능은 마지막 변경값만이 중요한 체인지로그 형태의 데이터에 사용하면 좋다.

### 다중 클러스터
설치된 카프카가 확장되어감에 따라 다수의 클러스터를 운용하는 것이 더 나은 경우가 있다. 이 방식에는 다음과 같은 장점이 있다.

- 데이터 유형별 분리
- 보안 요구사항을 충족시키기 위한 격리
- 재해 복구를 대비한 다중 데이터 센터

특히 카프카가 다수의 데이터센터에서 운용될 때는 데이터센터 간의 메시지를 복제해 줄 필요가 있는 경우가 많다. 이렇게 하면 온라인 애플리케이션은 양쪽 데이터센터 모두에서 사용자 활동 정보를 사용할 수 있다.

카프카 프로젝트는 데이터를 다른 클러스터로 복제하는 데 사용되는 **미러메이커** 라는 툴을 포함한다. 근본적으로 미러메이커도 단지 큐로 연결된 카프카 컨슈머와 프로듀서에 불과하다. 하나의 카프카 클러스터에서 메시지를 읽어와서 다른 클러스터에 쓴다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/336daf94-090d-417a-aea1-77e660fae5ab)

## 왜 카프카인가?
카프카가 좋은 이유에는 무엇이 있을까?

- 다중 프로듀서
- 다중 컨슈머: 카프카는 많은 컨슈머가 상호 간섭 없이 어떠한 메시지 스트림도 읽을 수 있도록 설계되었다.
  - 하나의 메시지를 하나의 클라이언트에서만 소비할 수 있도록 되어있는 많은 큐 시스템과의 결정적인 차이점이다.
  - 다수의 카프카 컨슈머는 컨슈머 그룹의 일원으로 작동함으로써 하나의 스트림을 여럿이서 나눠서 읽을 수 있다. 이 경우 주어진 메시지는 전체 컨슈머 그룹에 대해 한 번만 처리된다.
- 디스크 기반 보존
  - 컨슈머들이 항상 실시간으로 데이터를 읽어올 필요는 없다는 의미이기도 하다.
  - 만약 컨슈머가 느린 처리 속도 혹은 트래픽 폭주로 인해 뒤처질 경우에도 데이터 유실의 위험은 없다.
  - 컨슈머를 정지하더라도 메시지는 카프카 안에 남아있게 된다. 컨슈머가 다시 시작되면 작업을 멈춘 지점에서부터 유실 없이 데이터를 처리할 수 있다.
- 확장성
- 고성능
- 플랫폼 기능

## 데이터 생태계
데이터 처리를 위해 구축한 환경에는 많은 애플리케이션이 있다. 입력은 데이터를 생성하거나, 데이터를 시스템에 집어넣은 애플리케이션의 형태로 주어진다. 출력은 지푯값이나, 리포트나, 다른 데이터 제품의 형태로 정의된다. 시스템에서 데이터를 읽어와서, 다른 곳에서 들어온 데이터와 함께 변환하고, 또 다른 곳에서 쓰일 수 있도록 데이터 인프라스트럭처로 보내는 애플리케이션의 형태로 루프를 만들 수도 있다. 이러한 과정은 품질, 크기, 용도가 제각각인 다양한 유형의 데이터에 대해 수행된다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/407bdd81-b879-40d3-8663-acc7019ae67b)

아파치 카프카는 데이터 생태계에 있어 순환 시스템을 제공한다. 모든 클라이언트에 대해 일관된 인터페이스를 제공하면서 다양한 인프라스트럭처 요소들 사이에 메시지를 전달하는 것이다. 메시지 스키마를 제공하는 시스템과 결합하면 프로듀서와 컨슈머는 더 이상 어떤 형태로든 밀접하게 결합되거나 연결될 필요가 없다. 필요할 때마다 관련 컴포넌트를 추가하거나 제거해주면 되며, 프로듀서는 누가 데이터를 사용하는지, 컨슈머 애플리케이션이 몇 개인지와 같은 것에 신경 쓸 필요가 없다.