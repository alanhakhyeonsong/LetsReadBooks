# Chapter 4. 카프카 컨슈머: 카프카에서 데이터 읽기
카프카에서 데이터를 읽는 애플리케이션은 토픽을 구독하고 구독한 토픽들로부터 메시지를 받기 위해 `KafkaConsumer`를 사용한다. 카프카에서 데이터를 읽는 것은 다른 메시지 전달 시스템에서 데이터를 읽는 것과는 조금 다르고, 카프카 특유의 개념과 발상이 관련되어 있다. 중요한 개념들을 알아본 뒤 컨슈머 API 활용 방법들을 살펴보자.

## 카프카 컨슈머: 개념
### 컨슈머와 컨슈머 그룹
카프카 토픽으로부터 메시지를 읽어 몇 가지 검사를 한 후, 다른 데이터 저장소에 저장하는 애플리케이션을 개발한다 가정해보자. 이 애플리케이션은 컨슈머 객체(`KafkaConsumer` 인스턴스)를 생성하고, 해당 토픽을 구독하고, 메시지를 받기 시작한 뒤 받은 메시지를 받아 검사하고 결과를 써야 한다. 만약 프로듀서가 애플리케이션이 검사할 수 있는 속도보다 더 빠른 속도로 토픽에 메시지를 쓰게 될 때, 이 데이터를 읽고 처리하는 컨슈머가 하나뿐이라면 애플리케이션은 새로 추가되는 메시지의 속도를 따라 잡을 수 없기 때문에 메시지 처리가 계속 뒤로 밀리게 될 것이다. 따라서, 토픽으로부터 데이터를 읽어 오는 작업을 확장할 수 있어야 한다. **여러 개의 프로듀서가 동일한 토픽에 메시지를 쓰듯이, 여러 개의 컨슈머가 같은 토픽으로부터 데이터를 분할해서 읽어올 수 있게 해야 하는 것이다.**

카프카 컨슈머는 보통 **컨슈머 그룹(consumer group)** 의 일부로서 작동한다. 동일한 컨슈머 그룹에 속한 여러 개의 컨슈머들이 동일한 토픽을 구독할 경우, 각각의 컨슈머는 해당 토픽에서 서로 다른 파티션의 메시지를 받는 것이다.

네 개의 파티션을 갖는 T1 이라는 토픽이 있고, G1 컨슈머 그룹에 속한 유일한 컨슈머인 C1을 생성해서 해당 토픽을 구독했다 가정해보자. 컨슈머 C1은 T1 토픽의 네 파티션 모두에서 모든 메시지를 받게 될 것이다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/0c1f07af-93a4-47fa-9dac-b8101b24da8d)

G1에 새로운 컨슈머 C2를 추가한다. 이제 각각의 컨슈머는 2개의 파티션에서 메시지를 받으면 된다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/b76147a5-a7d6-405f-8958-9001860001d0)

만약 G1에 컨슈머가 4개 있다면, 각각의 컨슈머가 하나의 파티션에서 메시지를 읽어오게 된다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/e30aa6ec-be62-4b81-b4a9-c041931defc7)

만약 하나의 토픽을 구독하는 하나의 컨슈머 그룹에 파티션 수보다 더 많은 컨슈머를 추가한다면, 컨슈머 중 몇몇은 **유휴 상태**가 되어 메시지를 전혀 받지 못한다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/c4d1ad56-0ff9-4f6d-a1b0-b575d4d1ad3a)

**이처럼 컨슈머 그룹에 컨슈머를 추가하는 것은 카프카 토픽에서 읽어오는 데이터 양을 확장하는 주된 방법이다.** 카프카 컨슈머가 지연 시간이 긴 작업을 수행하는 것은 흔하다. 이런 경우, 하나의 컨슈머로 토픽에 들어오는 데이터의 속도를 감당할 수 없을 수도 있게 때문에 컨슈머를 추가함으로써 단위 컨슈머가 처리하는 파티션과 메시지의 수를 분산시키는 것이 일반적인 규모 확장 방식이다. **토픽을 생성할 때 파티션 수를 크게 잡아주는 게 좋은 이유이기도 한데, 부하가 증가함에 따라 더 많은 컨슈머를 추가할 수 있게 해주기 때문이다.** 토픽에 설정된 파티션 수 이상으로 컨슈머를 투입하는 것이 아무 의미 없다는 점을 명심하자.

한 애플리케이션의 규모를 확장하기 위해 컨슈머 수를 늘리는 경우 이외에도 여러 애플리케이션이 동일한 토픽에서 데이터를 읽어와야 하는 경우 역시 매우 흔하다. 카프카의 주 디자인 목표 중 하나는 카프카 토픽에 쓰여진 데이터를 전체 조직 안에서 여러 용도로 사용할 수 있도록 만드는 것이었다. 이러한 경우 우리는 각각의 애플리케이션이 전체 메시지의 일부만 받는 게 아니라 **전부 다 받도록** 해야 한다. 이렇게 하려면, 애플리케이션이 각자의 컨슈머 그룹을 갖도록 해야 한다. 카프카는 성능 저하 없이 많은 수의 컨슈머와 컨슈머 그룹으로 확장 가능하다.

만약 하나의 컨슈머를 갖는 새로운 컨슈머 그룹 G2를 추가하게 된다면 이 컨슈머는 G1 컨슈머 그룹에서 무엇을 하고 있든지 상관 없이 T1 토픽의 모든 메시지를 받게 된다. G2 역시 2개 이상의 컨슈머를 가질 수 있는데, 이 경우 G1과 마찬가지로 각각의 컨슈머는 전체 파티션을 나눠서 할당 받게 된다. 하지만, G2 전체를 놓고 보면 다른 컨슈머 그룹과는 상관없이 여전히 전체 메시지를 받게 된다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/995a2bc5-a484-413c-9ed2-9bb3726a9216)

요약하자면 다음과 같다. **1개 이상의 토픽에 대해 모든 메시지를 받아야 하는 애플리케이션별로 새로운 컨슈머 그룹을 생성한다. 토픽에서 메시지를 읽거나 처리하는 규모를 확장하기 위해선 이미 존재하는 컨슈머 그룹에 새로운 컨슈머를 추가함으로써 해당 그룹 내의 컨슈머 각각이 메시지의 일부만을 받아 처리하도록 한다.**

### 컨슈머 그룹과 파티션 리밸런스
**컨슈머 그룹에 속한 컨슈머들은 자신들이 구독하는 토픽의 파티션들에 대한 소유권을 공유한다.** 새로운 컨슈머를 컨슈머 그룹에 추가하면 이전에 다른 컨슈머가 읽고 있던 파티션으로부터 메시지를 읽기 시작한다. 컨슈머가 종료되거나 크래시가 났을 경우도 마찬가지다. 해당 컨슈머가 컨슈머 그룹에서 나가면 원래 이 컨슈머가 읽고 있던 그룹에 잔류한 나머지 컨슈머 중 하나가 대신 받아서 읽기 시작한다.

컨슈머에 파티션을 재할당하는 작업은 컨슈머 그룹이 읽고 있는 토픽이 변경되었을 때도 발생한다.(ex. 토픽에 새 파티션을 추가했을 경우) 컨슈머에 할당된 파티션을 다른 컨슈머에게 할당해주는 작업을 **리밸런스**라고 한다.

**리밸런스는 컨슈머 그룹에 높은 가용성과 규모 확장성을 제공하는 기능이기 때문에 매우 중요하지만, 문제없이 작업이 수행되고 있는 와중이라면 달갑지 않은 기능이기도 하다.**

#### 조급한 리밸런스
조급한 리밸런스가 실행되는 와중에 모든 컨슈머는 읽기 작업을 멈추고 자신에게 할당된 모든 파티션에 대한 소유권을 포기한 뒤, 컨슈머 그룹에 다시 참여하여 완전히 새로운 파티션 할당을 전달받는다. 이러한 방식은 근본적으로 **전체 컨슈머 그룹에 대해 짧은 시간 동안 작업을 멈추게 한다.**

즉, 우선 모든 컨슈머가 자신에게 할당된 파티션을 포기하고, 파티션을 포기한 컨슈머 모두가 다시 그룹에 참여한 뒤에야 새로운 파티션을 할당받고 읽기 작업을 재개할 수 있다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/e0e6640f-4c5f-472a-bcaf-a54c945e8f17)

#### 협력적 리밸런스
협력적 리밸런스의 경우, 한 컨슈머에게 할당되어 있던 파티션만을 다른 컨슈머에 재할당한다. 재할당되지 않은 파티션에서 레코드를 읽어서 처리하던 컨슈머들은 작업에 방해받지 않고 하던 일을 계속할 수 있는 것이다.

1. 우선 컨슈머 그룹 리더가 다른 컨슈머들에게 각자에게 할당된 파티션 중 일부가 재할당될 것이라고 통보하면, 컨슈머들은 해당 파티션에서 데이터를 읽어 오는 작업을 멈추고 해당 파티션에 대한 소유권을 포기한다.
2. 컨슈머 그룹 리더가 이 포기된 파티션들을 새로 할당한다.

이 점진적인 방식은 안정적으로 파티션이 할당될 때까지 몇 번 반복될 수 있지만, 전체 작업이 중단되는 사태는 발생하지 않는다. 이 특징은 **리밸런싱 작업에 상당한 시간이 걸릴 위험이 있는, 컨슈머 그룹에 속한 컨슈머 수가 많은 경우에 특히 중요하다.**

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/9e44e2fa-c362-4b00-9432-babc8a7585bb)

**컨슈머는 해당 컨슈머 그룹의 그룹 코디네이터 역할을 지정받은 카프카 브로커에 하트비트를 전송함으로써 멤버십과 할당된 파티션에 대한 소유권을 유지한다.** 하트비트는 컨슈머의 백그라운드 스레드에 의해 전송되는데, 일정한 간격을 두고 전송되는 한 연결이 유지되고 있는 것으로 간주한다.

- 컨슈머가 일정 시간 이상 하트비트를 전송하지 않는다면, 세션 타임아웃이 발생하면서 그룹 코디네이터는 해당 컨슈머가 죽었다고 간주하고 리밸런스를 실행한다.
- 컨슈머에 크래시가 발생해서 메시지 처리를 중단했을 경우, 그룹 코디네이터는 몇 초 이상 하트비트가 들어오지 않는 것을 보고 컨슈머가 죽었다고 판단하고 리밸런스를 실행시킨다.

이 몇 초 동안 죽은 컨슈머에 할당되어 잇던 파티션에선 아무 메시지도 처리되지 않는다. 컨슈머를 깔끔하게 닫아줄 경우 컨슈머는 그룹 코디네이터에게 그룹을 나간다고 통지하는데, 그룹 코디네이터는 즉시 리밸런스를 실행함으로써 처리가 정지되는 시간을 줄인다.

### 정적 그룹 멤버십
기본적으로, 컨슈머가 갖는 컨슈머 그룹의 멤버로서 자격은 일시적이다. 컨슈머가 컨슈머 그룹을 떠나는 순간 해당 컨슈머에 할당되어 있던 파티션들은 해제되고, 다시 참여하면 새로운 멤버 ID가 발급되면서 리밸런스 프로토콜에 의해 새로운 파티션들이 할당된다.

이는 컨슈머에 고유한 `group.instance.id` 값을 잡아주지 않는 한 유효하다. 컨슈머가 정적 멤버로서 컨슈머 그룹에 처음 참여하면 평소와 같이 해당 그룹이 사용하고 있는 파티션 할당 전략에 따라 파티션이 할당된다. 하지만 이 컨슈머가 꺼질 경우, 자동으로 그룹을 떠나지는 않는다. 그리고 컨슈머가 다시 그룹에 조인하면 멤버십이 그대로 유지되기 때문에 리밸런스가 발생할 필요 없이 예전에 할당받았던 파티션들을 그대로 재할당받는다.

그룹 코디네이터는 그룹 내 각 멤버에 대한 파티션 할당을 캐시해 두고 있기 때문에 정적 멤버가 다시 조인해 들어온다고 해서 리밸런스를 발생시키지는 않는다.

만약 같은 `group.instance.id` 값을 갖는 두 개의 컨슈머가 같은 그룹에 조인할 경우, 두 번째 컨슈머에는 동일한 ID를 갖는 컨슈머가 이미 존재한다는 에러가 발생하게 될 것이다.

**정적 그룹 멤버십은 애플리케이션이 각 컨슈머에 할당된 파티션의 내용물을 사용해서 로컬 상태나 캐시를 유지해야 할 때 편리하다.** 다만, 각 컨슈머에 할당된 파티션들이 해당 컨슈머가 재시작된다고 해서 다른 컨슈머로 재할당되지는 않는다는 점을 기억해야 한다. 일정한 기간 동안, 어떤 컨슈머도 이렇게 컨슈머를 잃어버린 파티션들로부터 메시지를 읽어오지 않을 것이기 때문에 정지되었던 컨슈머가 다시 돌아오면 이 파티션에 저장된 최신 메시지에서 한참 뒤에 잇는 밀린 메시지부터 처리하게 된다. 따라서 이 파티션들을 할당받은 컨슈머가 재시작했을 때 밀린 메시지를 따라잡을 수 있는지 확인할 필요가 있다.

## 카프카 컨슈머 생성하기
카프카 레코드를 읽어오기 위해선 `KafkaConsumer` 인스턴스를 생성해야 한다.

우선, 반드시 지정해야만 하는 속성은 다음과 같다.

- `bootstrap.servers`
- `key.deserializer`
- `value.deserializer`

```java
@EnableKafka
@Configuration
public class KafkaConsumerConfig {

    @Bean
    public KafkaConsumer<String, String> kafkaConsumer() {
        Properties props = new Properties();
        kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");
        kafkaProps.put("group.id", "CountryCounter");
        kafkaProps.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        kafkaProps.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        return new KafkaConsumer<String, String>(props);
    }
}
```

Producer와 달리 Java 객체를 바이트 배열로 변환하는 클래스를 지정하는 게 아니라 바이트 배열을 Java 객체로 변환하는 클래스를 지정한다.

일반적으로 `KafkaConsumer` 인스턴스가 속하는 컨슈머 그룹을 지정하기 위해선 `group.id` 속성을 통해 지정한다. 어떤 컨슈머 그룹에도 속하지 않는 컨슈머를 생성하는 것이 가능하지만, 일반적인 것은 아니다.

## 토픽 구독하기
컨슈머를 생성하고 나서 다음으로 할 일은 1개 이상의 토픽을 구독하는 것이다.

Spring을 사용하지 않고 일반적인 Java Application 기준으론 다음과 같이 사용하면 된다.

```java
consumer.subscribe(Collections.singletionList("customerCountries"));
```

단순히 하나의 토픽 이름만으로 목록을 생성한다.

참고로, Spring에서 사용하는 방법은 예시는 다음과 같다.

```java
@Component
public class CouponConsumer {

    @KafkaListener(id = "${coupon.consumer-group.some-request}", topics = "${coupon.topic.some-request}")
    public void someRequestListener(List<CouponSomeRequestMessage> records) {
        // todo something
    }
}
```

## 폴링 루프
컨슈머 API의 핵심은 서버에 추가 데이터가 들어왔는지 폴링하는 단순한 루프다.

```java
Duration timeout = Duration.ofMillis(100);

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(timeout);

    for (ConsumerRecord<String, String> record : records) {
        System.out.printf("topic = %s, partition = %d, offset = %d, customer = %s, country = %s\n",
                          record.topic(), record.partition(), record.offset(),
                          record.key(), record.value());

        int updatedCount = 1;

        if (custCountryMap.containsKey(record.value())) {
            updatedCount = custCountryMap.get(record.value()) + 1;
        }
        custCountryMap.put(record.value(), updatedCount);

        JSONObject json = new JSONObject(custCountryMap);
        System.out.println(json.toString());
    }
}
```

- 컨슈머는 카프카를 계속해서 폴링하지 않으면 죽은 것으로 간주되어 이 컨슈머가 읽어오고 있던 파티션들은 처리를 계속하기 위해 그룹 내의 다른 컨슈머에게 넘겨진다.
- `poll()`에 전달하는 매개변수는 컨슈머 버퍼에 데이터가 없을 경우 `poll()`이 블록될 수 있는 최대 시간을 결정한다. 만약 이 값이 0으로 지정되거나 버퍼 안에 이미 레코드가 준비되어 있을 경우 `poll()`은 즉시 리턴된다. 그게 아니라면 지정된 밀리초만큼 기다린다.
- `poll()`은 레코드들이 저장된 `List`를 리턴한다. 각각의 레코드는 레코드가 저장되어 있던 토픽, 파티션, 파티션에서의 오프셋, 키, 밸류값을 포함한다.
- 처리가 끝났을 땐 결과물을 데이터 저장소에 쓰거나 이미 저장된 레코드를 갱신한다.

이 폴링 루프는 단순히 데이터를 가져오는 것보다 훨씬 더 많은 일을 한다. 새 컨슈머에서 처음으로 `poll()`을 호출하면 컨슈머는 `GroupCoordinator`를 찾아서 컨슈머 그룹에 참가하고, 파티션을 할당받는다. 리밸런스 역시 연관된 콜백들과 함께 여기서 처리된다.

`poll()`이 `max.poll.interval.ms`에 지정된 시간 이상으로 호출되지 않을 경우, 컨슈머는 죽은 것으로 판정되어 컨슈머 그룹에서 퇴출된다는 점을 명심하자. 따라서 폴링 루프 안에서 예측 불가능한 시간 동안 블록되는 작업을 수행하는 것은 피해야 한다.

### 스레드 안정성
하나의 스레드에서 동일한 그룹 내에 여러 개의 컨슈머를 생성할 수는 없으며, 같은 컨슈머를 다수의 스레드가 안전하게 사용할 수도 없다. **하나의 스레드당 하나의 컨슈머, 이것이 원칙이다.**

하나의 애플리케이션에서 동일한 그룹에 속하는 여러 개의 컨슈머를 운용하고 싶다면 스레드를 여러 개 띄워서 각각에 컨슈머를 하나씩 돌리는 수밖에 없다. 컨슈머 로직을 자체적인 객체로 감싼 다음 `ExecutorService`를 사용해서 각자의 컨슈머를 가지는 다수의 스레드를 시작시키면 좋다.

또 다른 방법으로는 이벤트를 받아 큐에 넣는 컨슈머 하나와 이 큐에서 이벤트를 꺼내 처리하는 여러 개의 워커 스레드를 사용하는 것이다.

## 컨슈머 설정하기
프로듀서와 마찬가지로 대부분의 매개변수는 합리적인 기본값을 가지고 있기 때문에 딱히 변경할 필요는 없다. 하지만 몇몇 매개변수는 컨슈머의 성능과 가용성에 영향을 준다.

### `fetch.min.bytes`
컨슈머가 브로커로부터 레코드를 얻어올 때 받는 데이터의 최소량(바이트)를 지정한다. (기본값은 1바이트)

만약 브로커가 컨슈머로부터 레코드 요청을 받았는데 새로 보낼 레코드의 양이 `fetch.min.bytes`보다 작을 경우, 브로커는 충분한 메시지를 보낼 수 있을 때까지 기다린 뒤 컨슈머에게 레코드를 보내준다. 토픽에 새로운 메시지가 많이 들어오지 않거나 하루 중 쓰기 요청이 적은 시간대 같은 상황에서 오가는 메시지 수를 줄임으로써 컨슈머와 브로커 양쪽에 대해 부하를 줄여주는 효과가 있다.

만약 읽어올 데이터가 그리 많지 않을 때 컨슈머가 CPU 자원을 너무 많이 사용하고 있거나 컨슈머 수가 많을 때 브로커의 부하를 줄여야 할 경우 이 값을 기본값보다 더 올려잡아 주는게 좋다. 다만 처리량이 적은 상황에서 지연 또한 증가할 수 있다.

### `fetch.max.wait.ms`
카프카가 컨슈머에게 응답하기 전 충분한 데이터가 모일 때까지 기다리도록 할 수 있다. 이 값은 얼마나 오래 기다릴 것인지를 결정한다. 기본적으로 카프카는 500ms를 기다리도록 되어 있다.

### `fetch.max.bytes`
컨슈머가 브로커를 폴링할 때 카프카가 리턴하는 최대 바이트 수를 지정한다. 기본값은 50MB.

컨슈머가 서버로부터 받은 데이터를 저장하기 위해 사용하는 메모리의 양을 제한하기 위해 사용된다. 얼마나 많은 파티션으로부터 얼마나 많은 메시지를 받았는지와는 무관하다.

브로커가 컨슈머에 레코드를 보낼 때는 **배치 단위**로 보내며, 만약 브로커가 보내야 하는 첫 번째 레코드 배치의 크기가 이 설정값을 넘길 경우, 제한값을 무시하고 해당 배치를 그대로 전송한다. 이것은 컨슈머가 읽기 작업을 계속해서 진행할 수 있도록 보장해준다. 참고로 브로커 설정에도 최대 읽기 크기를 제한할 수 있다.

대량의 데이터에 대한 요청은 대량의 디스크 읽기와 오랜 네트워크 전송 시간을 초래하여 브로커 부하를 증가시킬 수 있기 때문에, 이러한 사태를 막기 위해 브로커 설정을 사용할 수 있다.

### `max.poll.records`
이 속성은 `poll()`을 호출할 때마다 리턴되는 최대 레코드 수를 지정한다.

### `max.partition.fetch.bytes`
서버가 파티션별로 리턴하는 최대 바이트 수를 결정한다. 기본값은 1MB. 특별한 이유가 아닌 한 `fetch.max.bytes` 설정을 대신 사용할 것을 권장한다.

### `session.timeout.ms`, `heartbeat.interval.ms`
컨슈머가 브로커와 신호를 주고받지 않아도 살아 있는 것으로 판정되는 최대 시간의 기본값은 10초다. 이 속성들은 대개 함께 변경되는데 하트비트와 리밸런싱에 관련하여 주기에 대한 설정을 바꾼다.

### `max.poll.interval.ms`
컨슈머가 폴링을 하지 않고도 죽은 것으로 판정되지 않을 수 있는 최대 시간을 지정할 수 있게 해준다. 하트비트와 세션 타임아웃은 카프카가 죽은 컨슈머를 찾아내고 할당된 파티션을 해제할 수 있게 해준다. 하지만, 하트비트는 백그라운드 스레드에 의해 전송된다. 카프카에서 레코드를 읽어오는 메인 스레드가 데드락이 걸렸을 때, 백그라운드 스레드는 멀쩡히 하트비트를 전송하고 있을 수도 있다. 레코드 요청에 대해 예측하기 힘들기 때문에 안전장치 및 예방 조치로 이 설정을 사용한다.

### `default.api.timeout.ms`
API를 호출할 때 명시적인 타임아웃을 지정하지 않는 한, 거의 모든 컨슈머 API 호출에 적용되는 타임아웃 값으로 기본값은 1분이다.

### `request.timeout.ms`
컨슈머가 브로커로부터의 응답을 기다릴 수 있는 최대 시간이다. 만약 브로커가 이 설정에서 지정된 시간 사이에 응답하지 않을 경우, 클라이언트는 브로커가 완전히 응답하지 않을 것이라 간주하고 연결을 닫은 뒤 재연결을 시도한다. 기본값은 30초인데 더 낮추는건 권장하지 않는다.

### `auto.offset.reset`
컨슈머가 예전에 오프셋을 커밋한 적이 없거나, 커밋된 오프셋이 유효하지 않을 때 파티션을 읽기 시작할 때의 작동을 정의한다. 기본 값은 latest인데 유효한 오프셋이 없을 경우 컨슈머는 가장 최신 레코드부터 읽기 시작한다. 다른 값은 earliest인데, 유효한 오프셋이 없을 경우 파티션의 맨 처음부터 모든 데이터를 읽는 방식이다. none으로 설정된 상태에서 유효하지 않은 오프셋부터 읽으려 한다면 예외가 발생한다.

### `enable.auto.commit`
컨슈머가 자동으로 오프셋을 커밋할지의 여부를 결정한다. 기본값은 true.

### `partition.assignment.strategy`
`PartitionAssignor` 클래스는 컨슈머와 이들이 구독한 토픽이 주어졌을 때 어느 컨슈머에게 어느 파티션이 할당될지를 결정하는 역할을 한다. 카프카는 다음과 같은 파티션 할당 전략을 지원한다.

- Range: 컨슈머가 구독하는 각 토픽의 파티션들을 연속된 그룹으로 나눠서 할당한다.
- RoundRobin: 모든 구독된 토픽의 모든 파티션을 가져다 순차적으로 하나씩 컨슈머에 할당한다.
- Sticky: 파티션들을 가능한 한 균등하게 할당하고 리밸런스가 발생했을 때 가능하면 많은 파티션들이 같은 컨슈머에 할당되게 함으로써 할당된 파티션을 하나의 컨슈머에서 다른 컨슈머로 옮길 때 발생하는 오버헤드를 최소화하는 목표가 있다. RoundRobin 방식과 큰 차이는 없지만, 이동하는 파티션 수의 측면에선 더 적고, 더 균형잡히게 할당한다.
- Cooperative Sticky: Sticky와 기본적으로 동일하지만, 컨슈머가 재할당되지 않은 파티션으로부터 레코드를 계속해서 읽어올 수 있도록 해주는 협력적 리밸런스 기능을 지원한다.

## 오프셋과 커밋
`poll()`을 호출할 때마다 카프카에 쓰여진 메시지 중에서 컨슈머 그룹에 속한 컨슈머들이 아직 읽지 않은 레코드가 리턴된다. 이를 이용해서 그룹 내의 컨슈머가 어떤 레코드를 읽었는지 판단할 수 있다. 카프카의 고유한 특성 중 하나는 많은 JMS 큐들이 하는 것처럼 컨슈머로부터의 응답을 받는 방식이 아니다는 점이다. 대신, 컨슈머가 카프카를 사용해서 각 파티션에서의 위치를 추적할 수 있게 한다.

**카프카에선 파티션에서의 현재 위치를 업데이트하는 작업을 오프셋 커밋(offset commit)이라 한다.** 전통적인 메시지 큐완 다르게, 카프카는 레코드를 개별적으로 커밋하지 않는다. 대신, 컨슈머는 파티션에서 성공적으로 처리해 낸 마지막 메시지를 커밋함으로써 그 앞의 모든 메시지들 역시 성공적으로 처리되었음을 암묵적으로 나타낸다.

컨슈머는 오프셋 커밋을 위해 특수 토픽인 `__consumer_offsets` 토픽에 각 파티션별로 커밋된 오프셋을 업데이트하도록 하는 메시지를 보낸다. 모든 컨슈머들이 정상적으로 실행중일 때는 이것이 아무런 영향을 주지 않는다. 하지만, 컨슈머가 크래시되거나 새로운 컨슈머가 그룹에 추가될 경우 리밸런스가 발생한다. 리밸런스 이후 각각의 컨슈머는 리밸런스 이전에 처리하고 있던 것과는 다른 파티션들을 할당받을 수 있다. 어디서부터 작업을 재개해야 하는지를 알아내기 위해 컨슈머는 각 파티션의 마지막으로 커밋된 메시지를 읽어온 뒤 거기서부터 처리를 재개한다.

만약 커밋된 오프셋이 클라이언트가 처리한 마지막 메시지의 오프셋보다 작을 경우, 마지막으로 처리된 오프셋과 커밋된 오프셋 사이의 메시지들은 두 번 처리되게 된다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/abf93b9b-6abc-4e56-91bd-a6ea28f44b3f)

만약 커밋된 메시지가 클라이언트가 실제로 처리한 마지막 메시지의 오프셋보다 클 경우, 마지막으로 처리된 오프셋과 커밋된 오프셋 사이의 모든 메시지들은 컨슈머 그룹에서 누락되게 된다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/76cba8ab-5127-4965-947b-c0386aaa140a)

오프셋 관리는 클라이언트 애플리케이션에 큰 영향을 미친다. `KafkaConsumer` API는 오프셋을 커밋하는 다양한 방법을 지원한다.

### 자동 커밋
오프셋을 커밋하는 가장 쉬운 방법은 컨슈머가 대신하도록 하는 것이다. `enable.auto.commit` 설정을 `true`로 잡아주면 컨슈머는 5초에 한 번, `poll()`을 통해 받은 메시지 중 마지막 메시지의 오프셋을 커밋한다. 5초 간격은 기본값으로, `auto.commit.interval.ms` 설정으로 바꿀 수 있다.

컨슈머의 모든 다른 것들과 마찬가지로, 자동 커밋은 폴링 루프에 의해 실행된다. `poll()` 메서드를 실행할 때마다 컨슈머는 커밋해야 하는지를 확인한 뒤 해당하면 마지막 `poll()` 호출에서 리턴된 오프셋을 커밋한다.

자동 커밋 간격보다 짧은 시점에서 컨슈머가 크래시되는 상황이라면, 리밸런싱이 작동하고 남은 컨슈머들은 크래시된 컨슈머가 읽고 있던 파티션들을 이어받아 읽기 시작하는데, 남은 컨슈머들이 마지막으로 커밋된 오프셋부터 작업을 시작하기 때문에 커밋 이벤트의 중복이 발생할 수 있다. 오프셋을 더 자주 커밋하여 레코드가 중복될 수 있는 윈도우를 줄일수는 있지만, 중복을 완전히 없애는 것은 불가능하다.

### 현재 오프셋 커밋하기
대부분의 개발자들은 오프셋이 커밋되는 시각을 제어하고자 한다. 메시지 유실의 가능성을 제거함과 동시에 리밸런스 발생시 중복되는 메시지의 수를 줄이기 위해서다. 컨슈머 API는 타이머 시간이 아닌, 애플리케이션 개발자가 원하는 시간에 현재 오프셋을 커밋하는 옵션을 제공한다.

`enable.auto.commit=false`로 설정하여 애플리케이션이 명시적으로 커밋하려 할 때만 오프셋이 커밋되게 할 수 있다. 가장 간단하고 신뢰성 있는 커밋 API는 `commitSync()`다. 이는 `poll()`이 리턴한 마지막 오프셋을 커밋한 뒤 커밋이 성공적으로 완료되면 리턴, 어떠한 이유로 실패하면 예외를 발생시킨다. 이는 `poll()`에 의해 리턴된 마지막 오프셋을 커밋한다는 점에 유의하자.

모든 레코드의 처리가 완료되기 전 `commitSync()`를 호출하게 될 경우 애플리케이션이 크래시됐을 때 커밋은 되었지만 아직 처리되지 않은 메시지들이 누락될 위험을 감수해야 한다.

```java
Duration timeout = Duration.ofMillis(100);

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(timeout);
    for (ConsumerRecord<String, String> record : records) {
        System.out.printf("topic = %s, partition = %d, offset = %d, customer = %s, country = %s\n",
                          record.topic(), record.partition(), record.offset(),
                          record.key(), record.value());
    }
    
    try {
        consumer.commitSync();
    } catch (CommitFailedException e) {
        log.error("commit failed", e);
    }
}
```

### 비동기적 커밋
수동 커밋의 단점 중 하나는 브로커가 커밋 요청에 응답할 때까지 애플리케이션이 블록된다는 점이다. 이것은 애플리케이션의 처리량을 제한하게 된다. 덜 자주 커밋한다면 처리량이야 올라가겠지만 리밸런스에 의해 발생하는 잠재적인 중복 메시지의 수는 늘어난다.

또 다른 방법은 비동기적 커밋 API를 사용하는 것이다. 브로커가 커밋에 응답할 때까지 기다리는 대신 요청만 보내고 처리를 계속한다.

```java
Duration timeout = Duration.ofMillis(100);

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(timeout);
    for (ConsumerRecord<String, String> record : records) {
        System.out.printf("topic = %s, partition = %d, offset = %d, customer = %s, country = %s\n",
                          record.topic(), record.partition(), record.offset(),
                          record.key(), record.value());
    }
    
    consumer.commitAsync();
}
```

이 방식의 단점은 `commitSync()`가 성공하거나 재시도 불가능한 실패가 발생할 때까지 재시도하는 반면, `commitAsync()`는 재시도를 하지 않는다는 점이다. `commitAsync()`가 서버로부터 응답을 받은 시점에는 이미 다른 커밋 시도가 성공했을 수도 있기 때문이다.