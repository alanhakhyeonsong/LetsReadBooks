# Chapter 3. 카프카 프로듀서: 카프카에 메시지 쓰기
카프카를 큐로 사용하든, 메시지 버스나 데이터 저장 플랫폼으로 사용하든 간에 카프카를 사용할 때는 카프카에 데이터를 쓸 때 사용하는 프로듀서나 읽어 올 때 사용하는 컨슈머, 혹은 두 가지 기능 모두를 수행하는 애플리케이션을 생성해야 한다.

> ex) 신용카드 트랜잭션 처리 시스템  
> 온라인 쇼핑몰 등에서 결제가 일어나는 순간 카프카에 각각의 트랜잭션을 전송하는 클라이언트 애플리케이션이 있을 것이다. 다른 애플리케이션에선 이 트랜잭션이 발생하는 순간 룰 엔진(rule engine)을 사용해서 이 트랜잭션의 적합 여부를 검사하고 승인 혹은 거부 여부를 결정할 것이다. 결정된 승인/거부 응답은 다시 카프카에 쓰여저서 해당 트랜잭션이 시작된 온라인 쇼핑몰로 전달된다. 그리고 세 번째 애플리케이션이 카프카로부터 트랜잭션과 승인 상태를 읽어와 나중에 분석가들이 확인하고 룰 엔진을 개선할 수 있도록 데이터베이스에 저장할 것이다.

아파치 카프카는 개발자들이 카프카와 상호작용하는 애플리케이션을 개발할 때 사용할 수 있는 클라이언트 API와 함께 배포된다.

## 프로듀서 개요
애플리케이션이 카프카에 메시지를 써야 하는 상황에는 여러 가지가 있을 수 있다.

- 사용자의 행동 기록
- 성능 메트릭 기록
- 로그 메시지 저장
- 스마트 가전에서의 정보 수집
- 다른 애플리케이션과의 비동기적 통신 수행
- 임의의 정보를 데이터베이스에 저장하기 전 버퍼링

이러한 사용 사례들은 목적이 다양한 만큼 요구 조건 역시 다양하다. 모든 메시지가 중요해서 메시지 유실이 용납되지 않는지, 유실이 허용되는지? 중복이 허용되도 상관 없는지? 반드시 지켜야 할 지연이나 처리율이 있는지?

서로 다른 요구 조건은 카프카에 메시지를 쓰기 위해 프로듀서 API를 사용하는 방식과 설정에 영향을 미친다.

프로듀서 API는 매우 단순하지만, 우리가 데이터를 전송할 때 내부적으로는 조금 더 많은 작업들이 이루어진다. 아래 그림은 카프카에 데이터를 전송할 때 수행되는 주요 단계들을 보여준다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/b3b73c51-2338-472f-940a-b89bd232e4b8)

- **카프카에 메시지를 쓰는 작업은 `ProducerRecord` 객체를 생성함으로써 시작된다.** 여기서 레코드가 저장될 토픽과 밸류 지정은 필수사항이지만, 키와 파티션 지정은 선택사항이다.
- `ProducerRecord`를 전송하는 API를 호출했을 때 프로듀서가 가장 먼저 하는 일은 키와 값 객체가 네트워크 상에서 전송될 수 있도록 직렬화해서 바이트 배열로 변환하는 과정이다.
- 만약 파티션을 명시적으로 지정하지 않았다면 해당 데이터를 파티셔너에게로 보낸다.
  - 파티셔너는 파티션을 결정하는 역할을 하는데, 그 기준은 보통 `ProducerRecord` 객체의 키와 값이다.
- 파티션이 결정되어 메시지가 전송될 토픽과 파티션이 확정되면 프로듀서는 이 레코드를 같은 토픽 파티션으로 전송될 레코드들을 모은 레코드 배치(record batch)에 추가한다.
- 이후 별도의 스레드가 레코드 배치를 적절한 카프카 브로커에 전송한다.
- 브로커가 메시지를 받으면 응답을 돌려준다.
  - 메시지가 성공적으로 저장되었을 경우 브로커는 토픽, 파티션, 그리고 해당 파티션 안에서의 레코드의 오프셋을 담은 `RecordMetadata` 객체를 리턴한다.
  - 메시지가 저장에 실패했을 경우에는 에러가 리턴된다.
- 프로듀서가 에러를 수신했을 경우, 메시지 쓰기를 포기하고 사용자에게 에러를 리턴하기 전까지 몇 번 더 재전송을 시도할 수 있다.

## 카프카 프로듀서 생성하기
카프카에 메시지를 쓰려면 우선 원하는 속성을 지정해서 프로듀서 객체를 생성해야 한다. 카프카 프로듀서는 다음 3개의 필수 속성값을 갖는다.

- `bootstrap.servers`: 카프카 클러스터와 첫 연결을 생성하기 위해 프로듀서가 사용할 브로커의 `host:port` 목록이다.
  - 이 값은 모든 브로커를 포함할 필요는 없는데, 프로듀서가 첫 연결을 생성한 뒤 추가 정보를 받아오게 되어 있기 때문이다.
  - 다만 브로커 중 하나가 작동을 정지하는 경우에도 프로듀서가 클러스터에 연결할 수 있도록 **최소 2개 이상을 지정할 것을 권장한다.**
- `key.serializer`: 카프카에 쓸 레코드의 키의 값을 직렬화하기 위해 사용하는 시리얼라이저 클래스의 이름이다. 카프카 브로커는 메시지의 키값, 밸류값으로 바이트 배열을 받는다. 하지만, 프로듀서 인터페이스는 임의의 자바 객체를 키 혹은 밸류로 전송할 수 있도록 매개변수화된 타입을 사용할 수 있도록 한다.
  - `org.apache.kafka.common.serialization.Serializer` 인터페이스를 구현하는 클래스의 이름이 지정되어야 한다.
  - 키값 없이 밸류값만 보낼 때도 `key.serializer` 설정은 해줘야 하지만, `VoidSerializer`를 사용해서 키 타입으로 `Void` 타입을 설정할 수 있다.
- `value.serializer`: 카프카에 쓸 레코드의 밸류값을 직렬화하기 위해 사용하는 시리얼라이저 클래스의 이름이다.

```java
@EnableKafka
@Configuration
public class KafkaProducerConfig {
    
    @Bean
    public KafkaProducer<String, String> kafkaProducer() {
        Properties kafkaProps = new Properties();
kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");
kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        return new KafkaProducer<String, String>(kafkaProps);
    }
}
```

- 메시지의 키값과 밸류값으로 문자열을 사용할 것이므로, 카프카에서 기본 제공되는 `StringSerializer`를 사용한다.
- 적절한 키와 밸류 타입을 설정하고 `Properties` 객체를 넘겨줌으로써 새로운 프로듀서를 생성한다.

단순하게 정확한 설정값을 제공하는 것만으로도 프로듀서의 실행을 제어할 수 있다. 메시지 전송 방법에는 크게 3가지 방법이 있다.

- 파이어 앤 포겟(Fire and forget): 메시지를 서버에 전송만 하고 성공 혹은 실패 여부에는 신경 쓰지 않는다. 카프카가 가용성이 높고 프로듀서는 자동으로 전송 실패한 메시지를 재전송 시도하기 때문에 대부분의 경우 메시지는 성공적으로 전달된다. 다만, 재시도를 할 수 없는 에러가 발생하거나 타임아웃이 발생했을 경우 메시지는 유실되며 애플리케이션은 여기에 대해 아무런 정보나 예외를 전달받지 않게 된다.
- 동기적 전송(Synchronous send): 카프카 프로듀서는 언제나 비동기적으로 작동한다. 즉, 메시지를 보내면 `send()` 메서드는 `Future` 객체를 리턴한다. 하지만 다음 메시지를 전송하기 전 `get()` 메서드를 호출해서 작업이 완료될 때까지 기다렸다가 실제 성공 여부를 확인해야 한다.
- 비동기적 전송(Asynchronous send): 콜백 함수와 함께 `send()` 메서드를 호출하면 카프카 브로커로부터 응답을 받는 시점에서 자동으로 콜백 함수가 호출된다.

이번 장의 모든 예제들은 단일 스레드를 사용하지만, 프로듀서 객체는 메시지를 전송하려는 다수의 스레드가 동시에 사용할 수 있다.

## 카프카로 메시지 전달하기
메시지를 전송하는 가장 간단한 방법은 다음과 같다.

```java
ProducerRecord<String, String> record = 
                    new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
try {
    producer.send(record);
} catch (Exception e) {
    e.printStackTrace();
}
```

- 프로듀서는 `ProducerRecord` 객체를 받으므로 이 객체를 생성하는 것에서부터 시작한다. `ProducerRecord` 클래스에는 생성자가 여러 개 있다. 여기서 사용한 것은 토픽 이름, 키, 밸류값을 사용하는 것이다. 키와 밸류 타입은 앞서 지정했던 `key.serializer`, `value.serializer`와 맞아야 한다.
- `ProducerRecord`를 전송하기 위해 프로듀서 객체의 `send()` 메서드를 사용한다. 앞서 살펴보았듯이 메시지는 버퍼에 저장되었다가 별도 스레드에 의해 브로커로 보내진다. `send()`는 `RecordMetadata`를 포함한 Java `Future` 객체를 리턴하지만, 여기서는 리턴값을 무시하기 때문에 메시지 전송의 성공 여부를 알아낼 방법은 없다. 이러한 방법은 메시지가 조용히 누락되어도 상관없는 경우 사용될 수 있지만, 실제로 사용되는 애플리케이션에서는 대체로 해당사항이 없을 것이다.
- 카프카 브로커에 메시지를 전송할 때 발생하는 에러 혹은 브로커 자체에서 발생한 에러를 무시하더라도 프로듀서가 카프카로 메시지를 보내기 전 에러가 발생할 경우 여전히 예외가 발생할 수 있다.
  - `SerializationException`: 메시지 직렬화 실패
  - `TimeoutException`: 버퍼가 가득 찰 경우
  - `InterruptException`: 전송 작업을 수행하는 스레드에 인터럽트가 걸리는 경우

### 동기적으로 메시지 전송하기
동기적으로 메시지를 전송하는 방법은 단순하지만, 여전히 카프카 브로커가 쓰기 요청(produce request)에 에러 응답을 내놓거나 재전송 횟수가 소진되었을 때 발생하는 예외를 받아서 처리할 수 있다.

여기서 주요한 균형점은 성능이다. 카프카 클러스터에 얼마나 작업이 몰리느냐에 따라 브로커는 쓰기 요청에 응답하기까지 최소 2ms에서 최대 몇 초까지 지연될 수 있다. 동기적으로 메시지를 전송할 경우 전송을 요청하는 스레드는 이 시간 동안 아무것도 안 하면서 기다려야 한다. 다른 메시지를 전송할 수 없는 것은 물론이다. **결과적으로 성능이 크게 낮아지기 때문에 동기적 전송은 실제로 사용되는 애플리케이션에선 잘 사용되지 않는다.**

```java
ProducerRecord<String, String> record = 
                    new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
try {
    producer.send(record).get();
} catch (Exception e) {
    e.printStackTrace();
}
```

- 카프카로부터 응답이 올 때까지 대기하기 위해 `Future.get()` 메서드를 사용하고 있다. 이 메서드는 레코드가 카프카로 성공적으로 전송되지 않았을 경우 예외를 발생시킨다. 에러가 발생하지 않았을 경우, `RecordMetadata` 객체를 리턴하는데 여기서 메시지가 쓰여진 오프셋과 다른 메타데이터를 가져올 수 있다.

`KafkaProducer`에는 두 종류의 에러가 있다.

- 재시도 가능한 에러: 메시지를 다시 전송함으로써 해결될 수 있는 에러를 가리킨다.
  - 연결 에러는 연결이 회복되면 해결될 수 있다.
  - 메시지를 전송받은 브로커가 해당 파티션의 리더가 아닐 경우 발생하는 에러는 해당 파티션에 새 리더가 선출되고 클라이언트 메타데이터가 업데이트되면 해결될 수 있다.
  - 이런 류의 에러가 발생했을 때 자동으로 재시도하도록 `KafkaProducer`를 설정할 수 있기 때문에 이 경우 재전송 횟수가 소진되고서도 에러가 해결되지 않은 경우에 한해 재시도 가능한 예외가 발생한다.
- 재시도를 한다고 해서 해결되지 않는 에러
  - 메시지의 크기가 너무 클 경우 → `KafkaProducer`는 재시도 없이 바로 이 예외를 발생시킨다.

### 비동기적으로 메시지 전송하기
실제로 대부분의 경우 굳이 메시지 전송에 대한 응답이 필요 없다. 카프카는 레코드를 쓴 뒤 해당 레코드의 토픽, 파티션 그리고 오프셋을 리턴하는데, 대부분의 애플리케이션에서는 이런 메타데이터가 필요 없기 때문이다.

반대로, 메시지 전송에 완전히 실패했을 경우에는 그런 내용을 알아야 한다. 그래야 예외를 발생시키든지, 에러를 로그에 쓰든지, 아니면 사후 분석을 위해 에러 파일에 메시지를 쓰거나 할 수 있기 때문이다.

메시지를 비동기적으로 전송하고도 여전히 에러를 처리하는 경우를 위해 프로듀서는 레코드를 전송할 때 콜백을 지정할 수 있도록 한다.

```java
private class DemoProducerCallback implements Callback {
    @Override
    public void onCompletion(RecordMetadata recordMetadata, Exception e) {
        if (e != null) {
            e.printStackTrace();
        }
    }
}

ProducerRecord<String, String> record = 
                    new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
producer.send(record, new DemoProducerCallback());
```

- 콜백을 사용하려면 `org.apache.kafka.clients.producer.Callback` 인터페이스를 구현하는 클래스가 필요하다. 이 인터페이스는 `onCompletion()` 단 하나의 메서드만 정의되어 있다.
- 만약 카프카가 에러를 리턴한다면 `onCompletion()` 메서드가 `null`이 아닌 `Exception` 객체를 받게 된다. 여기서는 그냥 내용을 화면에 출력해주는 정도로 처리했지만, 실제 애플리케이션에선 좀 더 확실한 에러 처리 함수가 필요할 것이다.
- 레코드를 전송할 때 `Callback` 객체를 함께 매개변수로 전달한다.

## 프로듀서 설정하기
프로듀서는 굉장히 많은 수의 설정값을 가지고 있다. 대부분의 경우 합리적인 기본값을 가지고 있기 때문에 각각의 설정값을 일일이 잡아 줄 필요는 없다. 다만, 몇몇 설정값의 경우 메모리 사용량이나 성능, 신뢰성 등에 상당한 영향을 미친다.

### client.id
프로듀서와 그것을 사용하는 애플리케이션을 구분하기 위한 논리적 식별자. 임의의 문자열을 사용할 수 있는데, 브로커는 프로듀서가 보내온 메시지를 서로 구분하기 위해 이 값을 사용한다. 브로커가 로그 메시지를 출력하거나 성능 메트릭 값을 집계할 때, 그리고 클라이언트별로 사용량을 할당할 때 사용된다.

이 값을 잘 선택하는 것은 문제가 발생했을 때 트러불슈팅을 쉽게 한다.

### acks
**`acks` 매개변수는 프로듀서가 임의의 쓰기 작업이 성공했다고 판별하기 위해 얼마나 많은 파티션 레플리카가 해당 레코드를 받아야 하는지를 결정한다.** 기본값은 리더가 해당 레코드를 받은 뒤 쓰기 작업이 성공했다고 응답하는 것이다. 이 매개변수는 메시지가 유실될 가능성에 큰 영향을 미치는데, 구체적인 상황에 따라 기본값이 최적의 선택은 아닐 수 있다.

- `acks = 0`: **프로듀서는 메시지가 성공적으로 전달되었다고 간주하고 브로커의 응답을 기다리지 않는다.** 따라서 만약 뭔가 잘못되어서 브로커가 메시지를 받지 못했을 경우, 프로듀서는 이 상황에 대해 알 방법이 없고 메시지는 그대로 유실된다. 다만, 프로듀서가 서버로부터 응답을 기다리지 않는 만큼 네트워크가 허용하는 한 빠르게 메시지를 보낼 수 있다. 따라서 이 설정은 매우 높은 처리량이 필요할 때 사용될 수 있다.
- `acks = 1`: **프로듀서는 리더 레플리카가 메시지를 받는 순간 브로커로부터 성공했다는 응답을 받는다.** 만약 리더에 메시지를 쓸 수 없다면 프로듀서는 에러 응답을 받을 것이고 데이터 유실을 피하기 위해 메시지 재전송을 시도하게 된다. 하지만 리더에 크래시가 난 상태에서 해당 메시지가 복제가 안 된 채로 새 리더가 선출될 경우에는 여전히 메시지가 유실될 수 있다.
- `acks = all`: **프로듀서는 메시지가 모든 인-싱크 레플리카(in-sync replica)에 전달된 뒤에야 브로커로부터 성공했다는 응답을 받는다.** 이는 **가장 안전한 형태**인데, 최소 2개 이상의 브로커가 해당 메시지를 가지고 있으며, 이는 크래시가 났을 경우에도 유실되지 않기 때문이다. 그러나 단순히 브로커 하나가 메시지를 받는 것보다 더 기다려야 하기 때문에 지연 시간은 더 길어질 것이다.

프로듀서의 `acks` 설정을 내려잡아 신뢰성을 낮추면 그만큼 레코드를 빠르게 보낼 수 있다. 하지만, 레코드가 생성되어 컨슈머가 읽을 수 있을 때까지의 시간을 의미하는 종단 지연의 경우 세 값이 모두 똑같다. **카프카는 일관성을 유지하기 위해 모든 인-싱크 레플리카에 복제가 완료된 뒤에야 컨슈머가 레코드를 읽어갈 수 있게 하기 때문이다.** 따라서, 단순한 프로듀서 지연이 아니라 종단 지연이 주로 고려되어야 하는 경우라면 딱히 절충해야 할 것은 없다. 가장 신뢰성 있는 설정을 택해도 종단 지연은 똑같기 때문이다.

### 메시지 전달 시간
카프카가 성공적으로 응답을 내려보내 줄 때까지 사용자가 기다릴 수 있는 시간이며, 요청 실패를 인정하고 포기할 때까지 기다릴 수 있는 시간이기도 하다.

아파치 카프카 2.1 부터 개발진은 `ProducerRecord`를 보낼 때 걸리는 시간을 두 구간으로 나누어 따로 처리할 수 있도록 했다.

- `send()`에 대한 비동기 호출이 이뤄진 시각부터 결과를 리턴할 때까지 걸리는 시간: 이 시간 동안 `send()`를 호출한 스레드는 블록된다.
- `send()`에 대한 비동기 호출이 성공적으로 리턴한 시각부터 콜백이 호출될 때까지 걸리는 시간: 이것은 `ProducerRecord`가 전송을 위해 배치에 추가된 시점에서부터 카프카가 성공 응답을 보내거나, 재시도 불가능한 실패가 일어나거나, 아니면 전송을 위해 할당된 시간이 소진될 때까지의 시간과 동일하다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/90a127ef-417e-43c0-99ae-7ef8feeaede0)

위 그림은 프로듀서 내부에서의 데이터 흐름과 서로 다른 설정 매개변수들이 어떻게 상호작용하는지를 보여준다.

#### `max.block.ms`
아래의 경우에 프로듀서가 얼마나 오랫동안 블록되는지를 결정한다.
- `send()`를 호출했을 때: `partitionFor`를 호출해서 명시적으로 메타데이터를 요청했을 때
- 위 메서드는 프로듀서의 전송 버퍼가 가득 차거나 메타데이터가 아직 사용 가능하지 않을 때 블록된다. 이 상태에서 `max.block.ms` 만큼 시간이 흐르면 예외가 발생한다.

#### `delivery.timeout.ms`
레코드 전송 준비가 완료된 시점(`send()`가 문제없이 리턴되고 레코드가 배치에 저장된 시점)에서부터 브로커의 응답을 받거나 아니면 전송을 포기하게 되는 시점까지의 제한시간을 결정한다.
- `linger.ms`와 `request.timeout.ms`보다 커야 한다.
- 만약 이 제한 조건을 벗어난 설정으로 카프카 프로듀서를 생성한다면 예외가 발생할 것이다.
- 메시지는 `delivery.timeout.ms`보다 빨리 전송될 수 있으며 실제로도 보통 그렇다.
- 만약 프로듀서가 재시도를 하는 도중 `delivery.timeout.ms`가 넘어가버린다면, 마지막으로재시도 하기 전에 브로커가 리턴한 에러에 해당하는 예외와 함께 콜백이 호출된다.
- 레코드 배치가 전송을 기다리는 와중에 `delivery.timeout.ms`가 넘어가버리면 타임아웃 예외와 함께 콜백이 호출된다.

#### `request.timeout.ms`
프로듀서가 데이터를 전송할 때 서버로부터 응답을 받기 위해 얼마나 기다릴 것인지를 결정한다. 이 값은 각각의 쓰기 요청 후 전송을 포기하기까지 대기하는 시간임을 명심하자.
- 재시도 시간이나, 실제 전송 이전에 소요되는 시간 등을 포함하지 않는다.
- 응답 없이 타임아웃이 발생할 경우, 프로듀서는 재전송을 시도하거나 아니면 `TimeoutException`과 함께 콜백을 호출한다.

#### `retries`, `retry.backoff.ms`
프로듀서가 서버로부터 에러 메시지를 받았을 때 이것이 일시적인 에러일 수도 있다. **이때 `retries` 매개변수는 프로듀서가 메시지 전송을 포기하고 에러를 발생시킬 때까지 메시지를 재전송하는 횟수를 결정한다.** 기본적으로 프로듀서는 각각의 재시도 사이에 100ms 동안 대기하는데, `retry.backoff.ms` 매개변수를 사용해서 이 간격을 조정할 수 있다.

이 값들을 조정하는 것을 권장하지 않는다. 대신, 크래시가 난 브로커가 정상으로 돌아오기까지(모든 파티션에 대해 새 리더가 선출되는 데 얼마나 시간이 걸리는지)의 시간을 테스트한 뒤 `delivery.timeout.ms` 매개변수를 잡아 주는 것을 권장한다. 재전송을 시도하는 전체 시간이 카프카 클러스터가 크래시로부터 복구되기까지의 시간보다 더 길게 잡히도록 잡아주는 것이다.

일반적으로, 프로듀서가 알아서 재전송을 처리해주기 때문에 애플리케이션 코드에는 관련 처리를 수행하는 코드가 필요 없다. 개발자는 재시도 불가능한 에러를 처리하거나 재시도 횟수가 고갈되었을 경우에 대한 처리에만 집중하면 된다.

### `linger.ms`
현재 배치를 전송하기 전까지 대기하는 시간을 결정한다.

`KafkaProducer`는 현재 배치가 가득 차거나 `linger.ms`에 설정된 제한 시간이 되었을 때 메시지 배치를 전송한다. 기본적으로, 프로듀서는 메시지 전송에 사용할 수 있는 스레드가 있을 때 곧바로 전송하도록 되어 있다. `linger.ms`를 0보다 큰 값으로 설정하면 프로듀서가 브로커에 메시지 배치를 전송하기 전에 메시지를 추가할 수 있도록 몇 ms가량 더 기다리도록 할 수 있다.

이것은 지연을 조금 증가시키는 대신 처리율을 크게 증대시킨다.

### `buffer.memory`
프로듀서가 메시지를 전송하기 전에 메시지를 대기시키는 버퍼의 크기를 결정한다. 만약 애플리케이션이 서버에 전달 가능한 속도보다 더 빠르게 메시지를 전송한다면 버퍼 메모리가 가득 찰 수 있다. 이 경우 추가로 호출되는 `send()`는 `max.block.ms` 동안 블록되어 버퍼 메모리에 공간이 생기기를 기다리게 되는데, 해당 시간 동안 대기하고서도 공간이 확보되지 않으면 예외를 발생시킨다. 대부분의 프로듀서 예외와는 달리 이 타임아웃은 `send()` 메서드에서 발생하지, `send()`가 리턴하는 `Future` 객체에서 발생하지 않는다.

### `compression.type`
기본적으로 메시지는 압축되지 않은 상태로 전송된다. 하지만 이 매개변수를 `snappy`, `gzip`, `lz4`, `zstd` 중 하나로 설정하면 해당 압축 알고리즘을 사용해서 메시지를 압축한 뒤 브로커로 전송된다.

구글에서 개발된 Sanppy 압축 알고리즘은 CPU 부하가 작으면서도 성능이 좋으며 꽤 괜찮은 압축률을 보여준다. 그래서 압축 성능과 네트워크 대역폭 모두가 중요할 때 권장된다.

Gzip 압축 알고리즘은 보통 CPU와 시간을 더 많이 사용하지만 압축률은 더 좋다. 따라서 이것은 네트워크 대역폭이 제한적일 때 사용하면 좋다.

압축 기능을 활성화함으로써 카프카로 메시지를 전송할 때 자주 병목이 되곤 하는 네트워크 사용량과 저장 공간을 절약할 수 있다.

### `batch.size`
같은 파티션에 다수의 레코드가 전송될 경우 프로듀서는 이것들을 배치 단위로 모아서 한꺼번에 전송한다. 이 매개변수는 각각의 배치에 사용될 메모리의 양을 결정한다. 참고로, '개수'가 아니라 **'바이트' 단위**임에 주의하자.

배치가 가득 차면 해당 배치에 들어 있는 모든 메시지가 한꺼번에 전송된다. 하지만 이것이 프로듀서가 각각의 배치가 가득 찰 때까지 기다린다는 의미는 아니다. 프로듀서는 절반만 찬 배치나 심지어 하나의 메시지만 들어 있는 배치도 전송한다. 그렇기 때문에 이 매개변수를 지나치게 큰 값으로 유지한다해서 메시지 전송에 지연이 발생하진 않는다. 반면, 이 값을 지나치게 작게 설정할 경우 프로듀서가 지나치게 자주 메시지를 전송해야 하기 때문에 약간의 오버헤드가 발생한다.

### `max.in.flight.requests.per.connection`
프로듀서가 서버로부터 응답을 받지 못한 상태에서 전송할 수 있는 최대 메시지의 수를 결정한다. 이 값을 올려잡아 주면 메모리 사용량이 증가하지만 처리량 역시 증가한다.

📌 순서 보장  
카프카는 파티션 내에서 메시지의 순서를 보존하게 되어 있다. 만약 프로듀서가 메시지를 특정한 순서로 보낼 경우 브로커가 받아서 파티션에 쓸 때나 컨슈머가 읽어올 때 해당 순서대로 처리된다는 것이다. `retries`를 0보다 큰 값으로 설정한 상태에서 `max.in.flight.requests.per.connection`을 1 이상으로 잡아줄 경우 메시지의 순서가 뒤집어질 수 있다. 즉, 브로커가 첫 번째 배치를 받아서 쓰려다 실패했는데, 두 번째 배치를 쓸 때는 성공한 상황에서 다시 첫 번째 배치가 재전송 시도되어 성공한 경우 메시지의 순서가 뒤집어진다.  
성능상의 고려 때문에 in-flight 요청이 최소 2 이상은 되어야 한다는 점 그리고 신뢰성을 보장하기 위해 재시도 횟수 또한 높아야 한다는 점을 감안하면, 가장 합당한 선택은 **`enable.idempotence=true`** 로 설정하는 것이다. 이 설정은 최대 5개의 in-flight 요청을 허용하면서도 순서를 보장하고, 재전송이 발생하더라도 중복이 발생하는 것 또한 방지해 준다.

### `max.request.size`
프로듀서가 전송하는 쓰기 요청의 크기를 결정한다. 이 값은 메시지의 최대 크기를 제한하기도 하지만, 한 번의 요청에 보낼 수 있는 메시지의 최대 개수 역시 제한한다. 이 매개변수의 기본값은 1MB인데, 이 경우 전송 가능한 메시지의 최대 크기는 1MB가 되고 한 번에 보낼 수 있는 1KB 크기의 메시지 개수는 1024개가 된다.

이에 더해, 브로커에는 브로커가 받아 들일 수 있는 최대 메시지 크기를 결정하는 `message.max.bytes` 매개변수가 있다. 이 두 매개변수를 동일하게 맞춤으로써 프로듀서가 브로커가 받아들이지 못하는 크기의 메시지를 전송하려 하지 않게 하는 것이 좋다.

### `receive.buffer.bytes`, `send.buffer.bytes`
데이터를 읽거나 쓸 때 소켓이 사용하는 TCP 송수신 버퍼의 크기를 결정한다. 각각의 값이 -1일 경우 운영체제의 기본값이 사용된다. 프로듀서나 컨슈머가 다른 데이터센터에 위치한 브로커와 통신할 경우 네트워크 대역폭은 낮고 지연은 길어지는 것이 보통이기 때문에 이 값들을 올려잡아 주는 것이 좋다.

### `enable.idempotence`
카프카는 0.11부터 **'정확히 한 번' 의미 구조**를 지원하기 시작했다. 멱등적 프로듀서는 그중 간단하면서도 매우 강력한 부분이라 할 수 있다.

신뢰성을 최대화하는 방향으로 프로듀서를 설정했다고 가정해보자. `acks=all`로 잡고 실패가 나더라도 충분히 재시도하도록 `delivery.timeout.ms`는 꽤 큰 값으로 잡는다. 이 경우 메시지는 반드시 최소 한 번 카프카에 쓰여지게 된다.

예를 들어, 브로커가 프로듀서로부터 레코드를 받아 로컬 디스크에 쓰고, 다른 브로커에도 성공적으로 복제되었다고 가정하자. 여기서 첫 번째 브로커가 프로듀서로 응답을 보내기 전에 크래시가 났다고 생각해보자. 프로듀서는 `request.timeout.ms` 만큼 대기한 뒤 재전송을 시도하게 된다. 이 때 새로 보내진 메시지는 이미 메시지를 받은 바 있는 새 리더 브로커로 전달되게 된다. 결국 메시지가 중복되어 저장되는 것이다.

`enable.idempotence=true` 설정을 잡아주는 것은 바로 이러한 사태를 방비하기 위함이다. 멱등적 프로듀서 기능이 활성화된다면, 프로듀서는 레코드를 보낼 때마다 순차적인 번호를 붙여 보내게 된다. 만약 브로커가 동일한 번호를 가진 레코드를 2개 이상 받을 경우 하나만 저장하게 되며, 프로듀서는 별다른 문제를 발생시키지 않는 `DuplicateSequenceException`을 받게 된다.

## 시리얼라이저
**프로듀서를 설정할 때는 반드시 시리얼라이저를 지정해주어야 한다.**

### 커스텀 시리얼라이저
카프카로 전송해야 하는 객체가 단순한 문자열이나 정숫값이 아닐 경우에는 두 가지의 선택지가 있다.

- 레코드를 생성하기 위해 Avro, Thrift, Protobuf와 같은 범용 직렬화 라이브러리를 사용한다.
- 사용하고 있는 객체를 직렬화하기 위한 커스텀 직렬화 로직을 작성한다.

첫 번째 방식을 강력하게 권장한다. 예제를 통해 비교해보자.

```java
@Getter
@AllArgsConstructor
public class Customer {
    private int id;
    private String name;
}
```

위 클래스를 위한 커스텀 시리얼라이저를 작성해보자.

```java
public class CustomerSerializer implements Serializer<Customer> {
    
    @Override
    public void configure(Map configs, boolean isKey) {
        // nothing to configure
    }

    @Override
    public byte[] serialize(String topic, Customer data) {
        try {
            byte[] serializedName;
            int stringSize;
            if (data == null) {
                return null;
            } else {
                if (data.getName() != null) {
                    serializedName = data.getName().getBytes("UTF-8");
                    stringSize = serializedName.length;
                } else {
                    serializedName = new byte[0];
                    stringSize = 0;
                }
            }

            ByteBuffer buffer = ByteBuffer.allocate(4 + 4 + stringSize);
            buffer.putInt(data.getId());
            buffer.putInt(stringSize);
            buffer.put(serializedName);

            return buffer.array();
        } catch (Exception e) {
            throw new SerializationException("Error when serializing Customer to byte[] " + e);
        }
    }

    @Override
    public void close() {
        // nothing to close
    }
}
```

프로듀서를 생성할 때 `CustomerSerializer`를 사용해서 설정값을 잡아 주면, `ProducerRecord<String, Customer>`를 사용해서 `Customer` 객체를 바로 프로듀서에 전달할 수 있다. 단순한 예시지만, 코드에 취약점이 있음을 알 수 있을 것이다. 예를 들어 만약 고객이 너무 많을 경우 `id`의 타입을 `Long`으로 변경해야 하고, `Customer`에 `startDate` 필드를 추가해야 할 경우 기존 형식과 새 형식 사이의 호환성을 유지해야 하는 심각한 문제를 안게 된다.

더 심각한 문제는, 만약 같은 회사의 여러 팀에서 `Customer` 데이터를 카프카로 쓰는 작업을 수행하고 있다면 모두가 같은 로직을 사용하고 있어야 하기 때문에 코드를 동시에 코드를 변경해야 하는 상황이 발생한다.

이러한 이유 때문에 JSON, 아파치 에이브로, 스리프트 혹은 프로토버프와 같은 범용 라이브러리를 사용할 것을 권장한다.

## 파티션
