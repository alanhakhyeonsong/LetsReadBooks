# 6장. 파티셔닝
앞장에선 동일한 데이터의 복사본 여러 개를 다른 노드에 저장하는 개념인 복제를 다뤘다. 데이터셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으론 부족하고 데이터를 **파티션**으로 쪼갤 필요가 있다. 이 작업을 **샤딩**이라고도 한다.

파티션을 나눌 때는 보통 각 데이터 단위(레코드, 로우, 문서)가 하나의 파티션에 속하게 한다. 데이터베이스가 여러 파티션을 동시에 건드리는 연산을 지원할 수도 있지만 결과적으로 각 파티션은 그 자체로 작은 데이터베이스가 된다.

**데이터 파티셔닝을 원하는 주된 이유는 확장성이다.** 비공유 클러스터에서 다른 파티션은 다른 노드에 저장될 수 있다. 따라서 대용량 데이터셋이 여러 디스크에 분산될 수 있고 질의 부하는 여러 프로세서에 분산될 수 있다.

단일 파티션에 실행되는 질의를 생각해보면 각 노드에서 자신의 파티션에 해당하는 질의를 독립적으로 실행할 수 있으므로 노드를 추가함으로써 질의 처리량을 늘릴 수 있다. 크고 복잡한 질의는 훨씬 더 어렵긴 하지만 여러 노드에서 병렬 실행이 가능하다.

## 파티셔닝과 복제
**보통 복제와 파티셔닝을 함게 적용해 각 파티션의 복사본을 여러 노드에 저장한다.** 각 레코드는 정확히 한 파티션에 속하더라도 이를 여러 다른 노드에 저장해서 내결함성을 보장할 수 있다는 의미다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/2c58f206-f448-4cff-bbdd-53d24c599726)

한 노드에 여러 파티션을 저장할 수도 있다. 리더 팔로워 복제 모델을 사용한다면 파티셔닝과 복제의 조합은 위와 같은 형태가 된다. 각 파티션의 리더는 하나의 노드에 할당되고 팔로워들은 다른 노드에 할당된다. 각 노드는 어떤 파티션에게는 리더이면서 다른 파티션에게는 팔로워가 될 수 있다. 데이터베이스 복제에 관한 모든 내용은 파티션의 복제에도 동일하게 적용된다.

## 키-값 데이터 파티셔닝
대량의 데이터를 파티셔닝한다 생각해보자. 어떤 레코드를 어떤 노드에 저장할지 어떻게 결정해야 할까?

**파티셔닝의 목적은 데이터와 질의 부하를 노드 사이에 고르게 분산시키는 것이다.** 모든 노드가 동일한 분량을 담당한다 가정할 때 10대의 노드를 사용하면 한 대를 사용할 때보다 이론상으로 10배의 데이터를 저장하고 10배의 읽기, 쓰기 요청을 처리할 수 있다.

파티셔닝이 고르게 이뤄지지 않아 다른 파티션보다 데이터가 많거나 질의를 많이 받는 파티션이 있다면 쏠렸다고 한다. 그결과 파티셔닝의 효과는 매우 떨어진다. 극단적인 경우 모든 부하가 한 파티션에 몰려 10개 중 9개 노드는 유휴 상태에 있고 요청을 받는 노드 하나가 병목이 될 수 있다. 불균형하게 부하가 높은 파티션을 **핫스팟**이라고 한다.

**핫스팟을 회피하는 가장 단순한 방법은 레코드를 할당할 노드를 무작위로 선택하는 것이다.** 데이터가 노드들 사이에 매우 고르게 분산되지만 어떤 레코드를 읽으려고 할 때 해당 레코드가 어느 노드에 저장됐는지 알 수 없으므로 모든 노드에서 병렬적으로 질의를 실행해야 하는 커다란 단점이 있다.

### 키 범위 기준 파티셔닝
파티셔닝하는 방법 중 하나는 종이 백과사전처럼 각 파티션에 연속된 범위의 키를 할당하는 것이다. 각 범위들 사이의 경계를 알면 어떤 키가 어느 파티션에 속하는지 쉽게 찾을 수 있다. 또 어떤 파티션이 어느 노드에 할당됐는지 알면 적절한 노드로 요청을 직접 보낼 수 있다.

키 범위 크기가 반드시 동일할 필요는 없다. 데이터가 고르게 분포하지 않을 수도 있기 때문이다. 데이터를 고르게 분산시키려면 파티션 경계를 데이터에 맞춰 조정해야 한다.

파티션 경계는 관리자가 수동으로 선택하거나 데이터베이스에서 자동으로 선택되게 할 수 있다. 이런 식으로 파티셔닝하는 전략은 HBase, 2.4 이전 버전의 MongoDB에서 사용된다.

각 파티션 내에서는 키를 정렬된 순서로 저장할 수 있다. 이렇게 하면 범위 스캔이 쉬워지는 이점이 있고, 키를 연쇄된 색인으로 간주해서 질의 하나로 관련 레코드 여러 개를 읽어오는 데 사용할 수 있다. 예를 들어 센서 네트워크 데이터를 저장하는 애플리케이션에서 측정값의 타임스탬프를 키로 사용한다고 하자. 이 경우 범위 스캔이 매우 유용하다.

**그러나 키 범위 기준 파티셔닝은 특정한 접근 패턴이 핫스팟을 유발하는 단점이 있다.** 타임스탬프가 키라면 파티션은 시간 범위에 대응된다. 유감스럽게도 센서에서 값이 측정될 때마다 데이터를 데이터베이스에 기록하므로 쓰기 연산이 모두 동일한 파티션으로 전달되어 해당 파티션만 과부하가 걸리고 나머지 파티션은 유휴 상태로 남아 있을 수 있다.

이 문제를 피하려면 키의 첫 번째 요소로 타임스탬프가 아닌 다른 것을 사용해야 한다. 에를 들어 타임스탬프 앞에 센서 이름을 붙여 파티셔닝할 때 센서 이름을 먼저 사용한 후 시간을 사용하게 할 수 있다. 동시에 동작하는 센서가 많이 있다면 쓰기 부하가 파티션 사이에 더 균등하게 퍼진다.

### 키의 해시값 기준 파티셔닝
**쏠림과 핫스팟의 위험 때문에 많은 분산 데이터스토어는 키의 파티션을 정하는 데 해시 함수를 사용한다.**

좋은 해시 함수는 쏠린 데이터를 입력으로 받아 균일하게 분산되게 한다. 문자열을 입력으로 받는 32bit 해시 함수가 있다고 하자. 이 함수에 문자열을 넣으면 겉보기에는 `0 ~ 2^32 - 1` 사이의 무작위 숫자를 반환한다. 입력 문자열이 거의 유사해도 해시값은 숫자 범위 내에서 균일하게 분산된다.

**파티셔닝용 해시 함수는 암호적으로 강력할 필요는 없다.** 키에 적합한 해시 함수를 구했다면 각 파티션에 키 범위 대신 해시값 범위를 할당하고 해시값이 파티션의 범위에 속하는 모든 키를 그 파티션에 할당하면 된다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/418e629b-67b1-410a-8e6d-b0af53829df9)

이 기법은 키를 파티션 사이에 균일하게 분산시키는 데 좋다. 파티션 경계는 크기가 동일하도록 나눌 수도 있고 무작위에 가깝게 선택할 수도 있다. 이런 기법을 일관성 해싱이라고 부르기도 한다.

그러나 유감스럽게도 파티셔닝에 키의 해시값을 사용해서 파티셔닝하면 키 범위 파티셔닝의 좋은 속성을 잃어 버린다. 바로 범위 질의를 효율적으로 실행할 수 있는 능력이다. 전에는 인접했던 키들이 이제는 모든 파티션에 흩어져 정렬 순서가 유지되지 않는다. MongoDB에선 해시 기반 샤딩 모드를 활성화하면 범위 질의가 모든 파티션에 전송돼야 한다.

카산드라는 두 가지 파티셔닝 전략 사이에서 타협한다. 테이블을 선언할 때 여러 칼럼을 포함하는 **복합 기본키**를 지정할 수 있다. 키의 첫 부분에만 해싱을 적용해 파티션 결정에 사용하고, 남은 칼럼은 카산드라의 SS테이블에서 데이터를 정렬하는 연쇄된 색인으로 사용한다. 따라서 복합 키의 첫 번째 칼럼에 대해선 값 범위로 검색하는 질의를 쓸 순 없지만 첫 번째 칼럼에 고정된 값을 지정하면 키의 다른 칼럼에 대해선 범위 스캔을 효율적으로 실행할 수 있다.

### 쏠린 작업부하와 핫스팟 완화
키를 해싱해서 파티션을 정하면 핫스팟을 줄이는 데 도움이 된다. 그렇지만 핫스팟을 완벽히 제거할 수는 없다. 항상 동일한 키를 읽고 쓰는 극단적인 상황에선 모든 요청이 동일한 파티션으로 쏠리게 된다.

**현대 데이터 시스템은 대부분 크게 쏠린 작업부하를 자동으로 보정하지 못하므로 애플리케이션에서 쏠림을 완화해야 한다.** 예를 들어 요청이 매우 많이 쏠리는 키를 발견했을 때 간단한 해결책은 각 키의 시작이나 끝에 임의의 숫자를 붙이는 것이다. 임의의 10진수 두 개만 붙이더라도 한 키에 대한 쓰기 작업이 100개의 다른 키로 균등하게 분산되고 그 키들은 다른 파티션으로 분산될 수 있다.

그러나 다른 키에 쪼개서 쓰면 읽기를 실행할 때 추가적인 작업이 필요해진다. 100개의 키에 해당하는 데이터를 읽어서 조합해야 하기 때문이다. 추가적으로 저장해야 할 정보도 있다. 이 기법은 요청이 몰리는 소수의 키에만 적용하는 게 타당하다. 쓰기 처리량이 낮은 대다수의 키에도 적용하면 불필요한 오버헤드가 생긴다. 따라서 어떤 키가 쪼개졌는지 추적할 방법도 있어야 한다.

## 파티셔닝과 보조 색인
지금까지 설명한 파티셔닝 방식은 키-값 데이터 모델에 의존한다. 레코드를 기본키를 통해서만 접근한다면 키로부터 파티션을 결정하고 이를 사용해 해당 키를 담당하는 파티션으로 읽기 쓰기 요청을 전달할 수 있다.

**보조 색인이 연관되면 상황은 복잡해진다. 보조 색인은 보통 레코드를 유일하게 식별하는 용도가 아니라 특정한 값이 발생한 항목을 검색하는 수단이다.** 보조 색인은 관계형 데이터베이스의 핵심 요소이며 문서 데이터베이스에서도 흔하다. 많은 키-값 저장소에선 구현 복잡도가 추가되는 것을 피하려고 보조 색인을 지원하지 않지만 보조 색인은 데이터 모델링에 매우 유용하므로 (리악 같은) 일부 저장소에서는 이를 추가하기 시작했다. 그리고 보조 색인은 Elasticsearch 같은 검색 서버에게는 존재의 이유다.

보조 색인은 파티션에 깔끔하게 대응되지 않는 문제점이 있다. 보조 색인이 있는 데이터베이스를 파티셔닝하는 데 널리 쓰이는 두 가지 방법은 문서 기반 파티셔닝과 용어 기반 파티셔닝이다.

### 문서 기준 보조 색인 파티셔닝
![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/5fb34049-39c9-41b9-b706-1a2ea0fce90f)

중고차를 판매하는 웹사이트를 운영한다고 하자. **각 항목에는 문서 ID라고 부르는 고유 ID가 있고 데이터베이스를 문서 ID 기준으로 파티셔닝한다.** 사용자들이 차를 검색할 때 색상과 제조사로 필터링할 수 있게 하려면 `color`와 `make`에 보조색인을 만들어야 한다. 색인을 선언했다면 데이터베이스가 자동으로 색인 생성을 할 수 있다.

이런 색인 방법을 사용하면 각 파티션이 완전히 독립적으로 동작한다. 각 파티션은 자신의 보조 색인을 유지하며 그 파티션에 속하는 문서만 담당한다. 다른 파팃녀에 어떤 데이터가 저장되는지는 신경 쓰지 않는다. 데이터베이스에 문서 추가, 삭제, 갱신 등의 쓰기 작업을 실행할 때는 쓰려고 하는 문서 ID를 포함하는 파티션만 다루면 된다. 따라서 문서 파티셔닝 색인은 **지역 색인**이라고도 한다.

그러나 문서 기준으로 파티셔닝된 색인을 써서 읽을 때는 주의를 기울여야 한다. **문서 ID에 뭔가 특별한 작업을 하지 않는다면 특정한 색상이거나 특정한 제조사가 만든 자동차가 동일한 파팃녀에 저장되리라는 보장이 없다.** 빨간색 자동차를 찾고 싶다면 모든 파티션으로 질의를 보내 얻은 결과를 모두 모아야 한다.

**파티셔닝된 데이터베이스에 이런 식으로 질의를 보내는 방법을 scatter/getter라고도 하는데 보조 색인을 써서 읽는 질의는 큰 비용이 들 수 있다.** 여러 파티션에서 질의를 병렬 실행 하더라도 스캐터/개더는 꼬리 지연 시간 증폭이 발생하기 쉽다. 그럼에도 보조 색인을 문서 기준으로 파티셔닝하는 경우가 많다. MongoDB, Cassandra, Elasticsearch는 모두 문서 기준으로 파티셔닝된 보조 색인을 사용한다.

데이터베이스 벤더들은 대부분 보조 색인 질의가 단일 파티션에서만 실행되도록 파티셔닝 방식을 설계하기를 권장하지만 항상 그렇지는 않다. 특히 단일 질의에서 여러 보조 색인을 사용할 때 그렇다.

### 용어 기준 보조 색인 파티셔닝
![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/f8d06489-7b1e-40e7-8698-c4b6e51bca81)

**각 파티션이 자신만의 보조 색인을 갖게 하는 대신, 모든 파티션의 데이터를 담당하는 전역 색인을 만들 수도 있다.** 그러나 한 노드에만 색인을 저장할 수는 없다. 해당 노드가 병목이 되어 파티셔닝의 목ㅈ거을 해치기 때문이다. **전역 색인도 파티셔닝해야 하지만 기본키 색인과는 다른 식으로 할 수 있다.**

찾고자 하는 용어에 따라 색인의 파티션이 결정되므로 이런 식의 색인을 **용어 기준으로 파티셔닝됐다**고 한다. 용어라는 이름은 전문 색인에서 나왔는데 용어란 문서에 등장하는 모든 단어를 말한다.

이전처럼 색인을 파티셔닝할 때 용어 자체를 쓸 수도 있고 용어의 해시값을 사용할 수도 있다. 용어 자체로 파티셔닝하면 범위 스캔에 유용한 반면, 용어의 해시값을 사용해 파티셔닝하면 부하가 좀 더 고르게 분산된다.

문서 파티셔닝 색인에 비해 전역 색인이 갖는 이점은 **읽기가 효율적이라는 것이다.** 클라이언트는 모든 파티션에 스캐터/개더를 실행할 필요 없이 원하는 용어를 포함하는 파티션으로만 요청을 보내면 된다. 그렇지만 전역 색인은 쓰기가 느리고 복잡하다는 단점이 있다. 단일 문서를 쓸 때 해당 색인의 여러 파티션에 영향을 줄 수 있기 때문이다.

이상적이라면 색인은 항상 최신 상태에 있고 데이터베이스에 기록된 모든 문서는 바로 색인에 반영돼야 한다. 하지만 용어 파티셔닝 색인을 사용할 때 그렇게 하려면 쓰기에 영향받는 모든 파티션에 걸친 분산 트랜잭션을 실행해야 하는데, 모든 데이터베이스에서 분산 트랜잭션을 지원하지는 않는다.

**현실에서는 번역 보조 색인은 대개 비동기로 갱신된다.** 예를 들어 AWS DynamoDB는 정상적인 상황에서는 전역 보조 색인을 갱신하는 데 1초도 안걸리지만 인프라에 결함이 생기면 반영 지연 시간이 더 길어질 수도 있다.

## 파티션 재균형화
시간이 지나면 데이터베이스에 변화가 생긴다.

- 질의 처리량이 증가해서 늘어난 부하를 처리하기 위해 CPU를 더 추가하고 싶다.
- 데이터셋 크기가 증가해서 데이터셋 저장에 사용할 디스크와 램을 추가하고 싶다.
- 장비에 장애가 발생해서 그 장비가 담당하던 역할을 다른 장비가 넘겨받아야 한다.

**이런 변화가 생기면 데이터와 요청이 한 노드에서 다른 노드로 옮겨져야 한다. 클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정을 재균형화(rebalancing)라고 한다.**

어떤 파티셔닝 방식을 쓰는지에 무관하게 재균형화가 실행될 때 보통 만족시킬 것으로 기대되는 최소 요구사항이 있다.

- 재균형화 후, 부하가 클러스터 내에 있는 노드들 사이에 균등하게 분배돼야 한다.
- 재균형화 도중에도 데이터베이스는 읽기 쓰기 요청을 받아들여야 한다.
- 재균형화가 빨리 실행되고 네트워크와 디스크 I/O 부하를 최소화할 수 있도록 노드들 사이에 데이터가 필요 이상으로 옮겨져서는 안 된다.

### 재균형화 전략
파티션을 노드에 할당하는 몇 가지 방법이 있다.

#### 쓰면 안 되는 방법: 해시값에 mod N 연산을 실행
키의 해시값 기준으로 파티셔닝할 때는 사용 가능한 해시값 범위를 나누고 각 범위를 한 파티션에 할당하는 게 최선이라 했다. 왜 그냥 mod 연산을 쓰지 않을까? **mod N 방식의 문제는 노드 개수 N이 바뀌면 대부분 키가 노드 사이에 옮겨져야 한다는 점이다.** 키가 자주 이동하면 재균형화 비용이 지나치게 커진다. 따라서 데이터를 필요 이상으로 이동하지 않는 방법이 필요하다.

#### 파티션 개수 고정
**파티션을 노드 대수보다 많이 만들고 각 노드에 여러 파티션을 할당하는 방법으로 간단하게 해결할 수 있다.** 클러스터에 노드가 추가되면 새 노드는 파티션이 다시 균일하게 분배될 때까지 기존 노드에서 파티션 몇 개를 뺏어올 수 있다. 클러스터에서 노드가 제거되면 이 과정이 반대로 실행된다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/55aa9419-6b01-434c-8937-5485deed59d2)

파티션은 노드 사이에서 통째로 이동하기만 한다. 파티션 개수는 바뀌지 않고 파티션에 할당된 키도 변경되지 않는다. 유일한 변화는 노드에 어떤 파티션이 할당되는가 뿐이다. 파티션 할당 변경은 즉시 반영되지 않고 네트워크를 통해 대량의 데이터를 전송해야 하므로 시간이 좀 걸린다. 따라서 데이터 전송이 진행 중인 동안에 읽기나 쓰기가 실행되면 기존에 할당된 파티션을 사용한다.

이론상으로 클러스터에 성능이 다른 하드웨어가 섞여 있는 것을 고려할 수도 있다. 성능이 좋은 노드에 파티션을 더 할당함으로써 더 많은 부하를 담당하게 할 수 있다. 이런 재균형화 방법은 Elasticsearch에서 사용된다.

이 방식을 사용할 때는 보통 데이터베이스가 처음 구축될 때 파티션 개수가 고정되고 이후에 변하지 않는다. 이론적으로는 파티션을 쪼개거나 합치는 게 가능하지만 파티션 개수가 고정되면 운영이 단순해지므로 고정 파티션을 사용하는 데이터베이스는 파티션 분할을 지원하지 않는 경우가 많다. 따라서 처음 설정된 파티션 개수가 사용 가능한 노드 대수의 최대치가 되므로 미래에 증가될 것을 수용하기에 충분히 높은 값으로 선택해야 한다. 그러나 개별 파티션도 관리 오버헤드가 있으므로 너무 큰 수를 선택하면 역효과를 낳을 수 있다.

전체 데이터셋의 크기 변동이 심하다면 적절한 파티션 개수를 정하기 어렵다. 각 파티션에는 전체 데이터의 고정된 비율이 포함되므로 개별 파티션 크기는 클러스터의 전체 데이터 크기에 비례해서 증가한다. 파티션이 너무 크면 재균형화를 실행할 때와 노드 장애로부터 복구할 때 비용이 크다. 그러나 파티션이 너무 작으면 오버헤드가 너무 커진다. 파티션 크기가 너무 크지도 너무 작지도 않고 딱 적당할 때 성능이 가장 좋지만 파티션 개수는 고정돼 있고 데이터셋 크기는 변한다면 적절한 크기를 정하기 어려울 수 있다.

#### 동적 파티셔닝
키 범위 파티셔닝을 사용하는 데이터베이스에선 파티션 경계와 개수가 고정돼 있는 게 매우 불편하다. 파티션 경계를 잘못 지정하면 모든 데이터가 한 파티션에 저장되고 나머지 파티션은 텅 빌 수도 있다. 파티션 경계를 수동으로 재설정하는 것은 매우 성가시다.

이런 이유로 HBase나 리싱크DB처럼 키 범위 파티셔닝을 사용하는 데이터베이스에선 파티션을 동적으로 만든다. 파티션 크기가 설정된 값을 넘어서면 파티션을 두 개로 쪼개 각각에 원래 파티션의 절반 정도의 데이터가 포함되게 한다. 반대로 데이터가 많이 삭제되어 파티션 크기가 임곗값 아래로 떨어지면 파티션과 합쳐질 수 있다. 이 과정은 B 트리의 최상위 레벨에서 실행되는 작업과 유사하다.

파티션 개수가 고정된 경우와 마찬가지로 각 파티션은 노드 하나에 할당되고 각 노드는 여러 파티션을 담당할 수 있다. 큰 파티션이 쪼개진 후 부하의 균형을 맞추기 위해 분할된 파티션 중 하나가 다른 노드로 이동될 수 있다.

**동적 파티셔닝은 파티션 개수가 전체 데이터 용량에 맞춰 조정된다는 이점이 있다.** 데이터 양이 적으면 파티션 개수가 적어도 되므로 오버헤드도 작다. 데이터 양이 거대하다면 개별 파티션의 크기는 설정된 최대치로 제한된다.

**그러나 빈 데이터베이스는 파티션 경계를 어디로 정해야 하는지에 관한 사전 정보가 없으므로 시작할 때는 파티션이 하나라는 함정이 있다.** 데이터 셋이 작을 때는 모든 쓰기 요청이 하나의 노드에서 실행되고 다른 노드들은 유휴 상태에 머물게 된다. 이 문제를 완화하기 위해 HBase와 MongoDB에선 빈 데이터베이스에 초기 파티션 집합을 설정할 수 있게 한다. 키 범위 파티셔닝의 경우 사전 분할을 하려면 키가 어떤 식으로 분할될지 미리 알아야 한다.

동적 파티셔닝은 키 범위 파티셔닝에만 적합한 것은 아니고 해시 파티셔닝에도 똑같이 사용될 수 있다. MongoDB는 2.4 버전부터 키 범위 파티셔닝과 해시 파티셔닝을 모두 지원하고 두 경우 모두 파티션을 동적으로 분할한다.

#### 노드 비례 파티셔닝
동적 파티셔닝에는 파티션 분할과 병합을 통해 개별 파티션 크기가 어떤 고정된 최솟값과 최댓값 사이에 유지되게 하므로 파티션 개수가 데이터셋 크기에 비례한다. 반면 파티션 개수를 고정하면 개별 파티션의 크기가 데이터셋 크기에 비례한다. 두 경우 모두 파티션 개수는 노드 대수와 독립적이다.

카산드라와 케타마에서 사용되는 세 번째 방법은 **파티션 개수가 노드 대수에 비례하게 하는 것이다. 다시 말해 노드당 할당되는 파티션 개수를 고정한다.** 이 경우 노드 대수가 변함 없는 동안은 개별 파티션 크기가 데이터셋 크기에 비례해서 증가하지만 노드 대수를 늘리면 파티션 크기는 다시 작아진다. 일반적으로 데이터 용량이 클수록 데이터를 저장할 노드도 많이 필요하므로 이 방법을 쓰면 개별 파티션 크기도 상당히 안정적으로 유지된다.

새 노드가 클러스터에 추가되면 고정된 개수의 파티션을 무작위로 선택해 분할하고 각 분할된 파티션의 절반은 그대로 두고 다른 절반은 새 노드에 할당한다. 파티션을 무작위로 선택해서 균등하지 않은 분할이 생길 수 있지만 여러 파티션에 대해 평균적으로 보면 새 노드는 기존 노드들이 담당하던 부하에서 균등한 몫을 할당받게 된다.

### 운영: 자동 재균형화와 수동 재균형화
완전 자동 재균형화와 완전 수동 재균형화 사이에는 중간 지점이 있다. 완전 자동 재균형화는 일상적인 유지보수에 손이 덜 가므로 편리할 수 있지만 예측하기 어렵기도 하다. 재균형화는 요청 경로를 재설정해야 하고 대량의 데이터를 노드 사이에 이동해야 하므로 비용이 큰 연산이다. 주의 깊게 처리하지 않으면 네트워크나 노드에 과부하가 걸릴 수 있고 재균형화가 진행 중인 동안에 실행되는 다른 요청의 성능이 저하될 수 있다.

이런 자동화는 자동 장애 감지와 조합되면 위험해질 수도 있다. 이런 이유로 재균형화 과정에 사람이 개입하는게 좋을 수도 있다. 완전 자동 처리보다는 느릴 수 있지만 운영상 예상치 못한 일을 방지하는 데 도움될 수 있다.

## 요청 라우팅
클라이언트에서 요청을 보내려고 할 때 어느 노드로 접속해야 하는지 어떻게 알 수 있을까? 파티션이 재균형화되면서 노드에 할당되는 파티션이 바뀐다. 이 문제는 데이터베이스에 국한되지 않은 더욱 일반적인 문제인 **service discovery**의 일종이다.

네트워크를 통해 접속되는 소프트웨어라면 모두 이 문제가 있다. 상위 수준에서 보면 이 문제는 몇 가지 다른 접근법이 있다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/30221b47-c964-42cd-9d53-c45005bb1539)

1. 클라이언트가 아무 노드에나 접속하게 한다.(ex. 라운드로빈 로드 밸런서) 만약 해당 노드에 마침 요청을 적용할 파티션이 있다면 거기서 요청을 직접 처리할 수 있다. 그렇지 않으면 요청을 올바른 노드로 전달해서 응답을 받고 클라이언트에게 응답을 전달한다.
2. 클라이언트의 모든 요청을 라우팅 계층으로 먼저 보낸다. 라우팅 계층에는 각 요청을 처리할 노드를 알아내고 그에 따라 해당 노드로 요청을 전달한다. 라우팅 계층 자체에서는 아무 요청도 처리하지 않는다. 파티션 인지 로드 밸런서로 동작할 뿐이다.
3. 클라이언트가 파티셔닝 방법과 파티션이 어떤 노드에 할당됐는지를 알고 있게 한다. 이 경우 클라이언트는 중개자 없이 올바른 노드로 직접 접속할 수 있다.

모든 경우에 핵심 문제는 라우팅 결정을 내리는 구성요소가 노드에 할당된 파티션의 변경 사항을 어떻게 아느냐다. 이 문제는 참여하는 모든 곳에서 정보가 일치해야 하므로 다루기 어렵다. 그렇지 않으면 요청이 잘못된 노드로 전송되고 제대로 처리되지 못한다. 분산 시스템에서 합의를 이루는 데 쓰이는 프로토콜이 있지만 제대로 구현하기 까다롭다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/a2043a80-6d72-4ed1-9114-be83aad77200)

많은 분산 데이터 시스템은 메타데이터를 추적하기 위해 ZooKeeper와 같은 별도의 코디네이션 서비스를 사용한다. 각 노드는 주키퍼에 자신을 등록하고 주키퍼는 파티션과 노드 사이의 신뢰성 있는 할당 정보를 관리한다. 라우팅 계층이나 파티션 인지 클라이언트 같은 다른 구성요소들은 주키퍼에 있는 정보를 구독할 수 있다. 파티션 소유자가 바뀌든지, 노드가 추가되거나 삭제되면 주키퍼는 라우팅 계층에 이를 알려 라우팅 정보를 최신으로 유지할 수 있게 한다.

MongoDB도 아키텍처는 비슷하지만 자체적인 config server 구현에 의존하고 mongos 데몬을 라우팅 계층으로 사용한다.

클라이언트는 라우팅 계층을 사용하거나 임의의 노드로 요청을 보낼 때도 접속할 IP 주소를 알아내야 한다. IP 주소는 노드에 할당된 파티션 정보만큼 자주 바뀌지 않으므로 IP 주소를 찾는 데는 대개 DNS를 쓰는 것으로 충분하다.

### 병렬 질의 실행
지금까진 단일 키를 읽거나 쓰는 매우 간단한 질의에 대해서만 설명했다. 이는 대부분의 NoSQL 분산 데이터스토어에서 지원되는 접근 수준이다.

그러나 분석용으로 자주 사용되는 대규모 병렬 처리 관계형 데이터베이스 제품은 훨씬 더 복잡한 종류의 질의를 지원한다. 전형적 데이터 웨어하우스 질의는 join, filtering, grouping, aggregation 연산을 몇 개 포함한다. MPP 질의 최적화기는 복잡한 질의를 여러 실행 단계와 파티션으로 분해하며 이들 중 다수는 데이터베이스 클러스터 내의 서로 다른 노드에서 병렬적으로 실행될 수 있다. 데이터 셋의 많은 부분을 스캔하는 연산을 포함하는 질의는 특히 병렬 실행의 혜택을 받는다.