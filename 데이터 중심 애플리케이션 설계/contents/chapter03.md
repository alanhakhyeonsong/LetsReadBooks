# 3장. 저장소와 검색
데이터베이스가 저장과 검색을 내부적으로 처리하는 방법을 애플리케이션 개발자가 주의해야 하는 이유는 무엇일까?

**대개 애플리케이션 개발자가 처음부터 자신의 저장소 엔진을 구현하기보단 사용 가능한 여러 저장소 엔진 중 애플리케이션에 적합한 엔진을 선택하는 작업이 필요하다.** 특정 작업부하 유형에서 좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행되는 작업에 대해 대략적인 개념을 이해할 필요가 있다.

특히 트랜잭션 작업부하에 맞춰 최적회된 저장소 엔진과 분석을 위해 최적화된 엔진 간에는 큰 차이가 있다.

## 데이터베이스를 강력하게 만드는 데이터 구조
많은 데이터베이스는 내부적으로 추가 전용(append-only) 데이터 파일인 **로그(log)를 사용한다.** 실제 데이터베이스는 다뤄야 할 더 많은 문제(ex. 동시성 제어, 로그가 영원히 커지지 않게끔 디스크 공간을 회수, 오류 처리, 부분적으로 기록된 레코드 처리)가 있지만 기본 원리는 같다. 로그는 믿기지 않을 정도로 유용하다.

데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 일반적인 배열, 리스트 구조가 아닌 다른 데이터 구조가 필요하다. 바로 **색인**이다. 이번 장에선 다양한 색인 구조를 살펴보고 여러 색인 구조를 비교하는 방법을 알아본다.

**색인(index)의 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것이다.** 이 메타데이터는 이정표 역할을 해서 원하는 데이터의 위치를 찾는 데 도움을 준다. 동일한 데이터를 여러 가지 다양한 방법으로 검색하고자 한다면 데이터의 각 부분에 여러 가지 다양한 색인이 필요하다.

색인은 기본 데이터에서 파생된 추가적인 구조다. **많은 데이터베이스는 색인의 추가와 삭제를 허용한다. 이 작업은 데이터베이스의 내용에는 영향을 미치지 않는다. 단지 질의 성능에만 영향을 준다.** 추가적인 구조의 유지보수는 특히 쓰기 과정에서 오버헤드가 발생한다. 쓰기의 경우 단순히 파일에 추가할 때의 성능을 앞서기 어렵다. 단순히 파일에 추가하는 작업이 제일 간단한 쓰기 작업이기 때문이다. 어떤 종류의 색인이라도 대개 쓰기 속도를 느리게 만든다. 이는 데이터를 쓸 때마다 매번 색인도 갱신해야 하기 때문이다.

**색인을 잘 선택했다면 읽기 질의 속도가 향상된다. 하지만 모든 색인은 쓰기 속도를 떨어뜨린다.** 이런 이유로 데이터베이스는 보통 자동으로 모든 것을 색인하지 않는다. 개발자나 DB 관리자가 애플리케이션의 전형적인 질의 패턴에 대한 지식을 활용해 수동으로 색인을 선택해야 한다. 그래야 필요 이상으로 오버헤드를 발생시키지 않으면서 애플리케이션에 가장 큰 이익을 안겨주는 색인을 선택할 수 있다.

### 해시 색인
키-값 데이터가 색인할 수 있는 유일한 종류의 데이터는 아니지만 매우 일반적이고 더욱 복잡한 색인을 위한 구성 요소로 용이하다.

키-값 저장소는 대부분의 프로그래밍 언어에서 볼 수 있는 사전 타입과 매우 유사하다. 보통 해시 맵으로 구현한다.

책의 앞선 예제처럼 단순히 파일에 추가하는 방식으로 데이터 저장소를 구성한다 가정해보자. 가장 간단하게 가능한 색인 전략은 다음과 같다. 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지하는 전략이다. 바이트 오프셋은 다음과 같이 값을 바로 찾을 수 있는 위치다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/306edfa9-6279-44f0-a81e-72b25979f900)

파일에 새로운 키-값 쌍을 추가할 때마다 방금 기록한 데이터의 오프셋을 반영하기 위해 해시 맵도 갱신해야 한다. 값을 조회하려면 해시 맵을 사용해 데이터 파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽는다. 이 방식은 매우 단순해 보이지만 실제로 많이 사용하는 접근법이다.

비트캐스크(Bitcask)가 근본적으로 사용하는 방식인데, 해시 맵을 전부 메모리에 유지하기 때문에 사용 가능한 RAM에 모든 키가 저장된다는 조건을 전제로 고성능으로 읽기, 쓰기를 보장한다. 값은 한 번의 디스크 탐색으로 디스크에서 적재할 수 있기 때문에 사용 가능한 메모리보다 더 많은 공간을 사용할 수 있다. 만약 데이터 파일의 일부가 이미 파일 시스템 캐시에 있다면 읽기에 디스크 입출력이 필요하지 않다. 이런 저장소 엔진은 각 키의 값이 자주 갱신되는 상황에 매우 적합하다.

파일에 항상 추가만 한다면 결국 디스크 공간이 부족해진다. 이 상황은 어떻게 피할 수 있을까? **특정 크기의 세그먼트로 로그를 나누는 방식이 좋은 해결책이다.** 특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일 이후 쓰기를 수행한다. 컴팩션은 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미한다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/8e946912-8da5-4f15-9164-7d73fcad7538)

더욱이 컴팩션은 보통 세그먼트를 더 작게 만들기 때문에 컴팩션을 수행할 때 동시에 여러 세그먼트들을 병합할 수 있다. 세그먼트가 쓰여진 후엔 절대 변경할 수 없기 때문에 병합할 세그먼트는 새로운 파일로 만든다. 고정된 세그먼트의 병합과 컴팩션은 백그라운드 스레드에서 수행할 수 있다. 컴팩션을 수행하는 동안 이전 세그머트 파일을 사용해 읽기와 쓰기 요청의 처리를 정상적으로 계속 수행할 수 있다. 병합 과정이 끝난 이후엔 읽기 요청은 이전 세그먼트 대신 새로 병합한 세그먼트를 사용하게끔 전환한다. 전환 후에는 이전 세그먼트 파일을 간단히 삭제하면 된다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/df9ebff1-ca5a-4772-9947-1654f0cfc08d)

이제 각 세그먼트는 키를 파일 오프셋에 매핑한 자체 인메모리 해시 테이블을 갖는다. 키의 값을 찾으려면 최신 세그먼트 해시 맵을 먼저 확인한다. 만약 키가 없다면 두 번째 최신 세그먼트 등을 확인한다. 병합 과정을 통해 세그먼트 수를 적게 유지하기 때문에 조회할 때 많은 해시 맵을 확인할 필요가 없다.

이런 간단한 생각을 실제로 구현하려면 세부적으로 많은 사항을 고려해야 한다.

- 파일 형식: CSV는 로그에 가장 적합한 형식이 아니다. 바이트 단위의 문자열 길이를 부호화한 다음 원시 문자열을 부호화하는 바이너리 형식을 사용하는 편이 더 빠르고 간단하다.
- 레코드 삭제: 키와 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드를 추가해야 한다. 로그 세그먼트가 병합될 때 툼스톤은 병합 과정에서 삭제된 키의 이전 값을 무시하게 된다.
- 고장 복구: 데이터베이스가 재시작되면 인메모리 해시 맵은 손실된다. 원칙적으론 전체 세그먼트 파일을 처음부터 끝까지 읽고 각 키에 대한 최신 값의 오프셋을 확인해서 각 세그먼트 해시 맵을 복원할 수 있다. 하지만 세그먼트 파일이 크면 해시 맵 복원은 오랜 시간이 걸릴 수 있고 이는 서버 재시작을 고통스럽게 만든다. 비트캐스크는 각 세그먼트 해시 맵을 메모리로 조금 더 빠르게 로딩할 수 있게 스냅숏을 디스크에 저장해 복구 속도를 높인다.
- 부분적으로 레코드 쓰기: 데이터베이스는 로그에 레코드를 추가하는 도중에도 죽을 수 있다. 비트캐스크 파일은 체크섬을 포함하고 있어 로그의 손상된 부분을 탐지해 무시할 수 있다.
- 동시성 제어: 쓰기를 엄격하게 순차적으로 로그에 추가할 때 일반적인 구현 방법은 하나의 쓰기 스레드만 사용하는 것이다. 데이터 파일 세그먼트는 추가 전용이거나 불변이므로 다중 스레드로 동시에 읽기를 할 수 있다.

추가 전용 로그는 언뜻 보면 낭비처럼 보인다. 예전 값을 새로운 값으로 덮어써 정해진 자리에 파일을 갱신하는 방법은 어떨까? 하지만 추가 전용 설계는 여러 측면에서 좋은 설계다.

- 추가와 세그먼트 병합은 순차적인 쓰기 작업이기 때문에 보통 무작위 쓰기보다 훨씬 빠르다. 특히 자기 회전 디스크 하드드라이브에서 그렇다. 일부 확장된 순차 쓰기는 플래시 기반 SSD도 선호한다.
- 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구는 훨씬 간단하다. 값을 덮어 쓰는 동안 데이터베이스가 죽는 경우에 대해 걱정할 필요가 없다. 이전 값 부분과 새로운 값 부분을 포함한 파일을 나누어 함게 남겨두기 때문이다.
- 오래된 세그먼트 병합은 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있다.

하지만 해시 테이블 색인 또한 제한 사항이 있다.

- 해시 테이블은 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다. 원칙적으론 디스크에 해시 맵을 유지할 수 있지만 좋은 성능을 기대하긴 어렵다. 이는 무작위 접근 I/O가 많이 필요하고 디스크가 가득 찼을 때 확장하는 비용이 비싸며 해시 충돌 해소를 위해 성가신 로직이 필요하다.
- 해시 테이블은 범위 질의에 효율적이지 않다. 해시 맵에서 모든 개별 키를 조회해야 한다.

### SS테이블과 LSM 트리
앞선 그림 3-3에서 각 로그 구조화 저장소 세그먼트는 키-값 쌍의 연속이다. 이 쌍은 쓰여진 순서대로 나타나며 로그에서 같은 키를 갖는 값 중 나중의 값이 이전 값보다 우선한다. 이 점만 제외하면 파일에서 키-값 쌍의 순서는 문제가 되지 않는다.

키-값 쌍을 **키로 정렬**하는 변경 요구사항을 적용해보자. 이처럼 키로 정렬된 형식을 **정렬된 문자열 테이블(Sorted String Table) 또는 짧게 SS테이블이라 부른다.** 그리고 또한 각 키는 각 병합된 세그먼트 파일 내에 한 번만 나타나야 한다. SS테이블은 해시 색인을 가진 로그 세그먼트보다 몇 가지 큰 장점이 있다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/3fcd9917-ef21-4036-bd8f-38a50c9d7c46)

- 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적이다. 이 접근법은 병합정렬 알고리즘에서 사용하는 방식과 유사하다. 위 그림처럼 먼저 입력 파일을 함께 읽고 각 파일의 첫 번째 키를 본다. 그리고 가장 낮은 키를 출력 파일로 복사한 뒤 이 과정을 반복한다. 이 과정에서 새로운 병합 세그먼트 파일이 생성된다. 새로 만든 세그먼트 파일도 역시 키로 정렬돼 있다.
- 파일에서 특정 키를 찾기 위해 더는 메모리의 모든 키의 색인을 유지할 필요가 없다.

  ![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/18211d1f-cca6-4495-b582-ee0bc2cf2649)

- 읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축한다. 그러면 희소 인메모리 색인의 각 항목은 압축된 블록의 시작을 가리키게 된다. 디스크 공간을 절약한다는 점 외에도 압축은 I/O 대역폭 사용도 줄인다.

### SS테이블 생성과 유지
데이터를 키로 정렬하려면 어떻게 해야 할까? 유입되는 쓰기는 임의 순서로 발생한다.

**디스크 상에 정렬된 구조를 유지하는 일은 가능하지만 메모리에 유지하는 편이 훨씬 쉽다.** 레드 블랙 트리나 AVL 트리와 같이 잘 알려졌고 상요 가능한 트리 데이터 구조는 많이 있다. 이를 이용하면 임의 순서로 키를 삽입하고 정렬된 순서로 해당 키를 다시 읽을 수 있다.

- 쓰기가 들어오면 인메모리 균형 트리 데이터구조에 추가한다. 이 인메모리 트리는 멤테이블(memtable)이라고도 한다.
- 멤테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS테이블 파일로 디스크에 기록한다. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있기 때문에 효율적으로 수행할 수 있다. 새로운 SS테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다. SS테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다.
- 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야 한다. 그다음 디스크 상의 가장 최신 세그먼트에서 찾는다. 그다음으로 두 번째 오래된 세그먼트, 세 번째 오래된 세그먼트 등에서 찾는다.
- 가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 수행한다. 이 과정은 백그라운드에서 수행된다.

한 가지 문제가 있다. 만약 DB가 고장나면 아직 디스크로 기록되지 않고 멤테이블에 있는 가장 최신 쓰기는 손실된다. 이런 문제를 피하기 위해선 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크 상에 유지해야 한다. 이 로그는 손상 후 멤테이블을 복원할 때만 필요하기 때문에 순서가 정렬되지 않아도 문제되지 않는다. 멤테이블을 SS테이블로 기록하고 나면 해당 로그는 버릴 수 있다.

### SS테이블에서 LSM 트리 만들기
여기 기술된 알고리즘은 LevelDB, RocksDB, 다른 애플리케이션에 내장하기 위해 설계된 키-값 저장소 엔진 라이브러리에서 사용한다. 카산드라와 HBase도 유사한 저장소 엔진을 사용한다.

원래 이 색인 구조는 로그 구조화 병합 트리(LSM 트리)란 이름으로 발표됐는데, 이 색인 구조는 로그 구조화 파일 시스템의 초기 작업의 기반이 됐다. 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.

Lucene은 Elasticsearch나 솔라에서 사용하는 전문 검색 색인 엔진이다. Lucene은 **용어 사전**을 저장하기 위해 유사한 방법을 사용한다. 전문 색인은 키-값 색인보다 훨씬 더 복잡하지만 이와 유사한 개념을 기반으로 한다. **검색 질의로 단어가 들어오면 단어가 언급된 모든 문서(웹 페이지, 제품 설명 등)를 찾는다.** 이 접근법은 키를 단어로, 값은 단어를 포함한 모든 문서의 ID 목록으로 하는 키-값 구조로 구현한다. Lucene에서 용어와 포스팅 목록의 매핑은 SS테이블 같은 정렬 파일에 유지하고 필요에 따라 백그라운드에서 병합한다.

### 성능 최적화