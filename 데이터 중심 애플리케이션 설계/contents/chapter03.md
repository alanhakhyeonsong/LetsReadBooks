# 3장. 저장소와 검색
데이터베이스가 저장과 검색을 내부적으로 처리하는 방법을 애플리케이션 개발자가 주의해야 하는 이유는 무엇일까?

**대개 애플리케이션 개발자가 처음부터 자신의 저장소 엔진을 구현하기보단 사용 가능한 여러 저장소 엔진 중 애플리케이션에 적합한 엔진을 선택하는 작업이 필요하다.** 특정 작업부하 유형에서 좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행되는 작업에 대해 대략적인 개념을 이해할 필요가 있다.

특히 트랜잭션 작업부하에 맞춰 최적회된 저장소 엔진과 분석을 위해 최적화된 엔진 간에는 큰 차이가 있다.

## 데이터베이스를 강력하게 만드는 데이터 구조
많은 데이터베이스는 내부적으로 추가 전용(append-only) 데이터 파일인 **로그(log)를 사용한다.** 실제 데이터베이스는 다뤄야 할 더 많은 문제(ex. 동시성 제어, 로그가 영원히 커지지 않게끔 디스크 공간을 회수, 오류 처리, 부분적으로 기록된 레코드 처리)가 있지만 기본 원리는 같다. 로그는 믿기지 않을 정도로 유용하다.

데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 일반적인 배열, 리스트 구조가 아닌 다른 데이터 구조가 필요하다. 바로 **색인**이다. 이번 장에선 다양한 색인 구조를 살펴보고 여러 색인 구조를 비교하는 방법을 알아본다.

**색인(index)의 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것이다.** 이 메타데이터는 이정표 역할을 해서 원하는 데이터의 위치를 찾는 데 도움을 준다. 동일한 데이터를 여러 가지 다양한 방법으로 검색하고자 한다면 데이터의 각 부분에 여러 가지 다양한 색인이 필요하다.

색인은 기본 데이터에서 파생된 추가적인 구조다. **많은 데이터베이스는 색인의 추가와 삭제를 허용한다. 이 작업은 데이터베이스의 내용에는 영향을 미치지 않는다. 단지 질의 성능에만 영향을 준다.** 추가적인 구조의 유지보수는 특히 쓰기 과정에서 오버헤드가 발생한다. 쓰기의 경우 단순히 파일에 추가할 때의 성능을 앞서기 어렵다. 단순히 파일에 추가하는 작업이 제일 간단한 쓰기 작업이기 때문이다. 어떤 종류의 색인이라도 대개 쓰기 속도를 느리게 만든다. 이는 데이터를 쓸 때마다 매번 색인도 갱신해야 하기 때문이다.

**색인을 잘 선택했다면 읽기 질의 속도가 향상된다. 하지만 모든 색인은 쓰기 속도를 떨어뜨린다.** 이런 이유로 데이터베이스는 보통 자동으로 모든 것을 색인하지 않는다. 개발자나 DB 관리자가 애플리케이션의 전형적인 질의 패턴에 대한 지식을 활용해 수동으로 색인을 선택해야 한다. 그래야 필요 이상으로 오버헤드를 발생시키지 않으면서 애플리케이션에 가장 큰 이익을 안겨주는 색인을 선택할 수 있다.

### 해시 색인
키-값 데이터가 색인할 수 있는 유일한 종류의 데이터는 아니지만 매우 일반적이고 더욱 복잡한 색인을 위한 구성 요소로 용이하다.

키-값 저장소는 대부분의 프로그래밍 언어에서 볼 수 있는 사전 타입과 매우 유사하다. 보통 해시 맵으로 구현한다.

책의 앞선 예제처럼 단순히 파일에 추가하는 방식으로 데이터 저장소를 구성한다 가정해보자. 가장 간단하게 가능한 색인 전략은 다음과 같다. 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지하는 전략이다. 바이트 오프셋은 다음과 같이 값을 바로 찾을 수 있는 위치다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/306edfa9-6279-44f0-a81e-72b25979f900)

파일에 새로운 키-값 쌍을 추가할 때마다 방금 기록한 데이터의 오프셋을 반영하기 위해 해시 맵도 갱신해야 한다. 값을 조회하려면 해시 맵을 사용해 데이터 파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽는다. 이 방식은 매우 단순해 보이지만 실제로 많이 사용하는 접근법이다.

비트캐스크(Bitcask)가 근본적으로 사용하는 방식인데, 해시 맵을 전부 메모리에 유지하기 때문에 사용 가능한 RAM에 모든 키가 저장된다는 조건을 전제로 고성능으로 읽기, 쓰기를 보장한다. 값은 한 번의 디스크 탐색으로 디스크에서 적재할 수 있기 때문에 사용 가능한 메모리보다 더 많은 공간을 사용할 수 있다. 만약 데이터 파일의 일부가 이미 파일 시스템 캐시에 있다면 읽기에 디스크 입출력이 필요하지 않다. 이런 저장소 엔진은 각 키의 값이 자주 갱신되는 상황에 매우 적합하다.

파일에 항상 추가만 한다면 결국 디스크 공간이 부족해진다. 이 상황은 어떻게 피할 수 있을까? **특정 크기의 세그먼트로 로그를 나누는 방식이 좋은 해결책이다.** 특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일 이후 쓰기를 수행한다. 컴팩션은 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미한다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/8e946912-8da5-4f15-9164-7d73fcad7538)

더욱이 컴팩션은 보통 세그먼트를 더 작게 만들기 때문에 컴팩션을 수행할 때 동시에 여러 세그먼트들을 병합할 수 있다. 세그먼트가 쓰여진 후엔 절대 변경할 수 없기 때문에 병합할 세그먼트는 새로운 파일로 만든다. 고정된 세그먼트의 병합과 컴팩션은 백그라운드 스레드에서 수행할 수 있다. 컴팩션을 수행하는 동안 이전 세그머트 파일을 사용해 읽기와 쓰기 요청의 처리를 정상적으로 계속 수행할 수 있다. 병합 과정이 끝난 이후엔 읽기 요청은 이전 세그먼트 대신 새로 병합한 세그먼트를 사용하게끔 전환한다. 전환 후에는 이전 세그먼트 파일을 간단히 삭제하면 된다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/df9ebff1-ca5a-4772-9947-1654f0cfc08d)

이제 각 세그먼트는 키를 파일 오프셋에 매핑한 자체 인메모리 해시 테이블을 갖는다. 키의 값을 찾으려면 최신 세그먼트 해시 맵을 먼저 확인한다. 만약 키가 없다면 두 번째 최신 세그먼트 등을 확인한다. 병합 과정을 통해 세그먼트 수를 적게 유지하기 때문에 조회할 때 많은 해시 맵을 확인할 필요가 없다.

이런 간단한 생각을 실제로 구현하려면 세부적으로 많은 사항을 고려해야 한다.

- 파일 형식: CSV는 로그에 가장 적합한 형식이 아니다. 바이트 단위의 문자열 길이를 부호화한 다음 원시 문자열을 부호화하는 바이너리 형식을 사용하는 편이 더 빠르고 간단하다.
- 레코드 삭제: 키와 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드를 추가해야 한다. 로그 세그먼트가 병합될 때 툼스톤은 병합 과정에서 삭제된 키의 이전 값을 무시하게 된다.
- 고장 복구: 데이터베이스가 재시작되면 인메모리 해시 맵은 손실된다. 원칙적으론 전체 세그먼트 파일을 처음부터 끝까지 읽고 각 키에 대한 최신 값의 오프셋을 확인해서 각 세그먼트 해시 맵을 복원할 수 있다. 하지만 세그먼트 파일이 크면 해시 맵 복원은 오랜 시간이 걸릴 수 있고 이는 서버 재시작을 고통스럽게 만든다. 비트캐스크는 각 세그먼트 해시 맵을 메모리로 조금 더 빠르게 로딩할 수 있게 스냅숏을 디스크에 저장해 복구 속도를 높인다.
- 부분적으로 레코드 쓰기: 데이터베이스는 로그에 레코드를 추가하는 도중에도 죽을 수 있다. 비트캐스크 파일은 체크섬을 포함하고 있어 로그의 손상된 부분을 탐지해 무시할 수 있다.
- 동시성 제어: 쓰기를 엄격하게 순차적으로 로그에 추가할 때 일반적인 구현 방법은 하나의 쓰기 스레드만 사용하는 것이다. 데이터 파일 세그먼트는 추가 전용이거나 불변이므로 다중 스레드로 동시에 읽기를 할 수 있다.

추가 전용 로그는 언뜻 보면 낭비처럼 보인다. 예전 값을 새로운 값으로 덮어써 정해진 자리에 파일을 갱신하는 방법은 어떨까? 하지만 추가 전용 설계는 여러 측면에서 좋은 설계다.

- 추가와 세그먼트 병합은 순차적인 쓰기 작업이기 때문에 보통 무작위 쓰기보다 훨씬 빠르다. 특히 자기 회전 디스크 하드드라이브에서 그렇다. 일부 확장된 순차 쓰기는 플래시 기반 SSD도 선호한다.
- 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구는 훨씬 간단하다. 값을 덮어 쓰는 동안 데이터베이스가 죽는 경우에 대해 걱정할 필요가 없다. 이전 값 부분과 새로운 값 부분을 포함한 파일을 나누어 함게 남겨두기 때문이다.
- 오래된 세그먼트 병합은 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있다.

하지만 해시 테이블 색인 또한 제한 사항이 있다.

- 해시 테이블은 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다. 원칙적으론 디스크에 해시 맵을 유지할 수 있지만 좋은 성능을 기대하긴 어렵다. 이는 무작위 접근 I/O가 많이 필요하고 디스크가 가득 찼을 때 확장하는 비용이 비싸며 해시 충돌 해소를 위해 성가신 로직이 필요하다.
- 해시 테이블은 범위 질의에 효율적이지 않다. 해시 맵에서 모든 개별 키를 조회해야 한다.

### SS테이블과 LSM 트리
앞선 그림 3-3에서 각 로그 구조화 저장소 세그먼트는 키-값 쌍의 연속이다. 이 쌍은 쓰여진 순서대로 나타나며 로그에서 같은 키를 갖는 값 중 나중의 값이 이전 값보다 우선한다. 이 점만 제외하면 파일에서 키-값 쌍의 순서는 문제가 되지 않는다.

키-값 쌍을 **키로 정렬**하는 변경 요구사항을 적용해보자. 이처럼 키로 정렬된 형식을 **정렬된 문자열 테이블(Sorted String Table) 또는 짧게 SS테이블이라 부른다.** 그리고 또한 각 키는 각 병합된 세그먼트 파일 내에 한 번만 나타나야 한다. SS테이블은 해시 색인을 가진 로그 세그먼트보다 몇 가지 큰 장점이 있다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/3fcd9917-ef21-4036-bd8f-38a50c9d7c46)

- 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적이다. 이 접근법은 병합정렬 알고리즘에서 사용하는 방식과 유사하다. 위 그림처럼 먼저 입력 파일을 함께 읽고 각 파일의 첫 번째 키를 본다. 그리고 가장 낮은 키를 출력 파일로 복사한 뒤 이 과정을 반복한다. 이 과정에서 새로운 병합 세그먼트 파일이 생성된다. 새로 만든 세그먼트 파일도 역시 키로 정렬돼 있다.
- 파일에서 특정 키를 찾기 위해 더는 메모리의 모든 키의 색인을 유지할 필요가 없다.

  ![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/18211d1f-cca6-4495-b582-ee0bc2cf2649)

- 읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축한다. 그러면 희소 인메모리 색인의 각 항목은 압축된 블록의 시작을 가리키게 된다. 디스크 공간을 절약한다는 점 외에도 압축은 I/O 대역폭 사용도 줄인다.

### SS테이블 생성과 유지
데이터를 키로 정렬하려면 어떻게 해야 할까? 유입되는 쓰기는 임의 순서로 발생한다.

**디스크 상에 정렬된 구조를 유지하는 일은 가능하지만 메모리에 유지하는 편이 훨씬 쉽다.** 레드 블랙 트리나 AVL 트리와 같이 잘 알려졌고 상요 가능한 트리 데이터 구조는 많이 있다. 이를 이용하면 임의 순서로 키를 삽입하고 정렬된 순서로 해당 키를 다시 읽을 수 있다.

- 쓰기가 들어오면 인메모리 균형 트리 데이터구조에 추가한다. 이 인메모리 트리는 멤테이블(memtable)이라고도 한다.
- 멤테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS테이블 파일로 디스크에 기록한다. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있기 때문에 효율적으로 수행할 수 있다. 새로운 SS테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다. SS테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다.
- 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야 한다. 그다음 디스크 상의 가장 최신 세그먼트에서 찾는다. 그다음으로 두 번째 오래된 세그먼트, 세 번째 오래된 세그먼트 등에서 찾는다.
- 가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 수행한다. 이 과정은 백그라운드에서 수행된다.

한 가지 문제가 있다. 만약 DB가 고장나면 아직 디스크로 기록되지 않고 멤테이블에 있는 가장 최신 쓰기는 손실된다. 이런 문제를 피하기 위해선 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크 상에 유지해야 한다. 이 로그는 손상 후 멤테이블을 복원할 때만 필요하기 때문에 순서가 정렬되지 않아도 문제되지 않는다. 멤테이블을 SS테이블로 기록하고 나면 해당 로그는 버릴 수 있다.

### SS테이블에서 LSM 트리 만들기
여기 기술된 알고리즘은 LevelDB, RocksDB, 다른 애플리케이션에 내장하기 위해 설계된 키-값 저장소 엔진 라이브러리에서 사용한다. 카산드라와 HBase도 유사한 저장소 엔진을 사용한다.

원래 이 색인 구조는 로그 구조화 병합 트리(LSM 트리)란 이름으로 발표됐는데, 이 색인 구조는 로그 구조화 파일 시스템의 초기 작업의 기반이 됐다. 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.

Lucene은 Elasticsearch나 솔라에서 사용하는 전문 검색 색인 엔진이다. Lucene은 **용어 사전**을 저장하기 위해 유사한 방법을 사용한다. 전문 색인은 키-값 색인보다 훨씬 더 복잡하지만 이와 유사한 개념을 기반으로 한다. **검색 질의로 단어가 들어오면 단어가 언급된 모든 문서(웹 페이지, 제품 설명 등)를 찾는다.** 이 접근법은 키를 단어로, 값은 단어를 포함한 모든 문서의 ID 목록으로 하는 키-값 구조로 구현한다. Lucene에서 용어와 포스팅 목록의 매핑은 SS테이블 같은 정렬 파일에 유지하고 필요에 따라 백그라운드에서 병합한다.

### 성능 최적화
LSM 트리 알고리즘은 데이터베이스에 존재하지 않는 키를 찾는 경우 느릴 수 있다. 멤테이블을 확인한 다음 키가 존재하지 않는다는 사실을 확인하기 전엔 가장 오래된 세그먼트까지 거슬러 올라가야 한다.(디스크에서 읽기를 해야 할 가능성이 있다.) 이런 종류의 접근을 최적화하기 위해 저장소 엔진은 보통 **블룸 필터(Bloom Filter)** 를 추가적으로 사용한다.

또한 SS테이블을 압축하고 병합하는 순서와 시기를 결정하는 다양한 전략이 있다. **가장 일반적으로 선택하는 전략은 크기 계층(size-tiered)과 레벨 컴팩션(leveled compaction)이다.** 레벨DB와 록스DB는 레벨 컴팩션을 사용하고 HBase는 사이즈 계층을, 카산드라는 둘 다 지원한다. 사이즈 계층 컴팩션은 상대적으로 좀 더 새롭고 작은 SS테이블을 상대적으로 오래됐고 큰 SS테이블에 연이어 병합한다. 레벨 컴팩션은 키 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 레벨로 이동하기 때문에 컴팩션을 점진적으로 진행해 디스크 공간을 덜 사용한다.

LSM 트리의 기본 개념은 간단하고 효과적이다. **LSM 트리의 기본 개념은 백그라운드에서 연쇄적으로 SS테이블을 지속적으로 병합하는 것이다. 이 개념은 데이터셋이 가능한 메모리보다 훨씬 더 크더라도 여전히 효과적이다.** 데이터가 정렬된 순서로 저장돼있다면 범위 질의를 효율적으로 실행할 수 있다. 이 접그넙의 디스크 쓰기는 순차적이기 때문에 LSM 트리가 매우 높은 쓰기 처리량을 보장할 수 있다.

## B 트리
**가장 널리 사용되는 색인 구조는 B-tree로 구조가 로그 구조화 색인과는 상당히 다르다.** 거의 대부분의 관계형 데이터베이스에서 표준 색인 구현으로 B 트리를 사용할 뿐 아니라 많은 비관계형 데이터베이스에서도 사용한다.

B 트리는 SS테이블과 같이 키로 정렬된 키-값 쌍을 유지하기 때문에 키-값 검색과 범위 질의에 효율적이다. 하지만 비슷한 점은 이 정도가 전부다. B 트리는 설계 철학이 매우 다르다.

로그 구조화 색인은 데이터베이스를 일반적으로 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록한다. **반면 B 트리는 전통적으로 4KB 크기의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다.** 디스크가 고정 크기 블록으로 배열되기 때문에 이런 설계는 근본적으로 하드웨어와 조금 더 밀접한 관련이 있다.

각 페이지는 주소나 위치를 이용해 식별할 수 있다. 이 방식으로 하나의 페이지가 다른 페이지를 참조할 수 있다.(포인터와 비슷하지만 메모리 대신 디스크에 있음)

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/5894451f-9e26-42c5-8564-81bbbf4a2643)

한 페이지는 B 트리의 루트로 지정된다. 색인에서 키를 찾으려면 루트에서 시작한다. 페이지는 여러 키와 하위 페이지의 참조를 포함한다. 각 하위 페이지는 키가 계속 이어지는 범위를 담당하고 참조 사이의 키는 해당 범위 경계가 어디인지 나타낸다. 위 그림에선 키 251을 찾고 있었기에 200과 300 경계 사이의 페이지 참조를 따라 가야 한다는 사실을 알 수 있다. 그러면 200~300 범위와 비슷하지만 좀 더 작은 범위로 나눈 페이지로 이동한다. 최종적으로는 개별 키(리프 페이지)를 포함하는 페이지에 도달한다. 이 페이지는 각 키의 값을 포함하거나 값을 찾을 수 있는 페이지의 참조를 포함한다.

B 트리의 한 페이지에서 하위 페이지를 참조하는 수를 분기 계수라고 부른다. 실제로 분기 계수는 페이지 참조와 범위 경계를 저장할 공간의 양에 의존적인데, 보통 수백 개에 달한다.

B 트리에 존재하는 키의 값을 갱신하려면 키를 포함하고 있는 리프 페이지를 검색하고 페이지의 값을 바꾼 다음 페이지를 디스크에 다시 기록한다.(페이지에 대한 참조는 계속 유효하다.) 새로운 키를 추가하려면 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가한다. 새로운 키를 수용한 페이지에 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 갱신한다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/92f5ef2c-f57e-45f6-acb4-3d4831eee377)

이 알고리즘은 트리가 계속 균형을 유지하는 것을 보장한다. n개의 키를 가진 B 트리는 깊이가 항상 O(log n)이다. 대부분의 데이터베이스는 B 트리의 깊이가 3이나 4단계 정도면 충분하므로 검색하려는 페이지를 찾기 위해 많은 페이지 참조를 따라가지 않아도 된다.

### 신뢰할 수 있는 B 트리 만들기
**B 트리의 기본적인 쓰기 동작은 새로운 데이터를 디스크 상의 페이지에 덮어쓴다.** 이 동작은 덮어쓰기가 페이지 위치를 변경하지 않는다고 가정한다. 즉 페이지를 덮어쓰더라도 페이지를 가리키는 모든 참조는 온전하게 남는다. LSM 트리와 같은 로그 구조화 색인과는 아주 대조적인 점이다. 로그 구조화 색인은 파일에 추가만 할 뿐 같은 위치의 파일은 변경하지 않는다.

데이터베이스가 고장 상황에서 스스로 복구할 수 있게 만들려면 일반적으로 디스크 상에 쓰기 전 로그(redo log)라고 하는 데이터 구조를 추가해 B 트리를 구현한다. 쓰기 전 로그는 트리 페이지에 변경된 내용을 적용하기 전에 모든 B 트리의 변경 사항을 기록하는 추가 전용 파일이다. 이 로그는 데이터베이스가 고장 이후 복구될 때 일관성 있는 상태로 B 트리를 다시 복원하는 데 사용한다.

같은 자리의 페이지를 갱신하는 작업은 추가적인 골칫거리다. 다중 스레드가 동시에 B 트리에 접근한다면 주의 깊게 동시성 제어를 해야 한다. 그렇지 않으면 스레드가 일관성이 깨진 상태의 트리에 접근할 수 있다. **동시성 제어는 보통 래치로 트리의 데이터 구조를 보호한다.** 이런 상황에서 로그 구조화 접근 방식은 훨씬 간단하다. 유입 질의의 간섭 없이 백그라운드에서 모든 병합을 수행하고 이따금 원자적으로 새로운 세그먼트를 이전 세그먼트로 바꾸기 때문이다.

### B 트리 최적화
B 트리는 오랫동안 사용됐기 때문에 그동안 개발된 많은 최적화 기법이 있다.

- 페이지 덮어 쓰기와 고장 복구를 위한 WAL 유지 대신 일부 데이터베이스는 쓰기 시 복사 방식을 사용한다. 변경된 페이지는 다른 위치에 기록하고 트리에 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가리키게 한다. 이 접근 방식은 동시성 제어에도 유용하다.
- 페이지에 전체 키를 저장하는 게 아니라 키를 축약해 쓰면 공간을 절약할 수 있다. 특히 트리 내부 페이지에서 키가 키 범위 사이의 경계 역할을 하는 데 충분한 정보만 제공하면 된다. 페이지 하나에 키를 더 많이 채우면 트리는 더 높은 분기 계수를 얻는다. 그러면 트리 깊이 수준을 낮출 수 있다.
- 일반적으로 페이지는 디스크 상 어디에나 위치할 수 있다. 키 범위가 가까운 페이지들이 디스크 상에 가까이 있어야 할 필요가 없기 때문이다. 질의가 정렬된 순서로 키 범위의 상당 부분을 스캔해야 한다면 모든 페이지에 대해 디스크 찾기가 필요하기 때문에 페이지 단위 배치는 비효율적이다. 따라서 많은 B 트리 구현에서 리프 페이지를 디스크 상에 연속된 순서로 나타나게끔 트리를 배치하려 시도한다. 하지만 트리가 커지면 순서를 유지하기 어렵다. 반대로 LSM 트리는 병합하는 과정에서 저장소의 큰 세그먼트를 한 번에 다시 쓰기 때문에 디스크에서 연속된 키를 서로 가깝게 유지하기 더 쉽다.
- 트리에 포인터를 추가한다. 예를 들어 각 리프 페이지가 양쪽 형제 페이지에 대한 참조를 가지면 상위 페이지로 다시 이동하지 않아도 순서대로 키를 스캔할 수 있다.
- **프랙탈 트리**같은 B 트리 변형은 디스크 찾기를 줄이기 위해 로그 구조화 개념을 일부 빌렸다.

### B 트리와 LSM 트리 비교
B 트리가 LSM 트리보다 일반적으로 구현 성숙도가 더 높지만 LSM 트리도 그 성능 특성 때문에 관심을 받고 있다. 경험적으로 LSM 트리는 보통 쓰기에서 더 빠른 반면 B 트리는 읽기에서 더 빠르다고 여긴다. 읽기가 보통 LSM 트리에서 더 느린 이유는 각 컴팩션 단계에 있는 여러 가지 데이터 구조와 SS테이블을 확인해야 하기 때문이다.

### LSM 트리의 장점
**B 트리 색인은 모든 데이터 조각을 최소한 두 번 기록해야 한다.** 쓰기 전 로그 한 번과 트리 페이지에 한 번이다. 해당 페이지 내 몇 바이트만 바뀌어도 한 번에 전체 페이지를 기록해야 하는 오버헤드도 있다. 일부 저장소 엔진은 심지어 전원에 장애가 발생했을 때 일부만 갱신된 페이지로 끝나지 않게 동일한 페이지를 두 번 덮어쓴다.

로그 구조화 색인 또한 SS테이블의 반복된 컴팩션과 병합으로 인해 여러 번 데이터를 다시 쓴다. 데이터베이스에 쓰기 한 번이 데이터베이스 수명 동안 디스크에 여러 번의 쓰기를 야기하는 이런 효과를 **쓰기 증폭**이라 한다. 쓰기가 많은 애플리케이션에서 성능 병목은 데이터베이스가 디스크에 쓰는 속도일 수 있다. 저장소 엔진이 디스크에 기록할수록 디스크 대역폭 내 처리할 수 있는 초당 쓰기는 점점 줄어든다.

더욱이 LSM 트리는 보통 B 트리보다 쓰기 처리량을 높게 유지할 수 있다. LSM 트리가 상대적으로 쓰기 증폭이 더 낮고 트리에서 여러 페이지를 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS테이블 파일을 쓰기 때문이다. LSM 트리는 압축률이 더 좋다. 그래서 보통 B 트리보다 디스크에 더 적은 파일을 생성한다. B 트리 저장소 엔진은 파편화로 인해 사용하지 않는 디스크 공간 일부가 남는다. 페이지를 나누거나 로우가 기존 페이지에 맞지 않을 때 페이지의 일부 공간은 사용하지 않게 된다. LSM 트리는 페이지 지향적이지 않고 주기적으로 파편화를 없애기 위해 SS테이블을 다시 기록하기 때문에 저장소 오버헤드가 더 낮다. 레벨 컴팩션을 사용하면 특히 그렇다.

### LSM 트리의 단점
**로그 구조화 저장소의 단점은 컴팩션 과정이 때로는 진행 중인 읽기와 쓰기의 성능에 영향을 준다는 점이다.** 저장소 엔진은 컴팩션을 점진적으로 수행하고 동시 접근의 영향이 없게 수행하려 한다. 하지만 디스크가 가진 자원은 한계가 있다. 따라서 비싼 컴팩션 연산이 끝날 때까지 요청이 대기해야 하는 상황이 발생하기 쉽다. 처리량과 평균 응답 시간이 성능에 미치는 영향은 대개 작다. 하지만 로그 구조화 저장소 엔진의 상위 백분위 질의의 응답 시간은 때때로 꽤 길다. 반면 B 트리의 성능은 로그 구조화 저장소 엔진보다 예측하기 쉽다.

**또 다른 컴팩션 문제는 높은 쓰기 처리량에서 발생한다.** 초기 쓰기와 백그라운드에서 수행되는 컴팩션 스레드가 이 대역폭을 공유해야 한다. 빈 데이터베이스에 쓰는 경우 전체 디스크 대역폭은 초기 쓰기만을 위해 사용할 수 있지만 데이터베이스가 점점 커질수록 컴팩션을 위해 더 많은 디스크 대역폭이 필요하다.

B 트리의 장점은 각 키가 색인의 한 곳에만 정확하게 존재한다는 점이다. 반면 로그 구조화 저장소 엔진은 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다. 이런 측면 때문에 강력한 트랜잭션 시맨틱을 제공하는 데이터베이스엔 B 트리가 훨씬 매력적이다. 많은 관계형 데이터베이스에서 트랜잭션 격리는 키 범위의 잠금을 사용해 구현한 반면 B 트리 색인에선 트리에 직접 잠금을 포함시킨다.

### 기타 색인 구조
키-값 색인의 대표적인 예는 관계형 모델의 기본키(primary key) 색인이다. 기본키로 관계형 테이블에서 하나의 로우를, 문서 데이터베이스에서 하나의 문서를, 그래프 데이터베이스에서 하나의 정점을 고유하게 식별할 수 있다. 데이터베이스에서 다른 레코드는 기본키로 로우/문서/정점을 참조할 수 있다. 색인은 이런 참조를 찾을 때 사용한다.

**보조 색인(secondary index)을 사용하는 방식도 매우 일반적이다.** 관계형 데이터베이스에선 `CREATE INDEX` 명령을 사용해 같은 테이블에 다양한 보조 색인을 생성할 수 있다. 보조 색인은 보통 효율적으로 조인을 수행하는 데 결정적인 역할을 한다. 보조 색인은 키-값 색인에서 쉽게 생성할 수 있다. 기본키 색인과의 주요 차이점은 키가 고유하지 않다는 점이다. 즉 같은 키를 가진 많은 로우가 있을 수 있다. 색인의 각 값에 일치하는 로우 식별자 목록을 만드는 방법 또는 로우 식별자를 추가해 각 키를 고유하게 만드는 방법이 있다. 어느 쪽이든 보조 색인으로 B 트리와 로그 구조화 색인 둘 다 사용할 수 있다.

### 색인 안에 값 저장하기
색인에서 키는 질의가 검색하는 대상이지만, 값은 다음 두 가지 중 하나에 해당한다.

- 질문의 실제 로우
- 다룬 곳에 저장된 로우를 가리키는 참조: 로우가 저장된 곳을 heap file이라 하고 특정 순서 없이 데이터를 저장한다.

힙 파일 접근 방식은 키를 변경하지 않고 값을 갱신할 때 효율적이다. 새로운 값이 이전 값보다 많은 공간을 필요로 하지 않으면 레코드를 제자리에 덮어쓸 수 있다. 새로운 값이 많은 공간을 필요로 한다면 상황은 조금 더 복잡해진다. 힙에서 충분한 공간이 있는 새로운 곳으로 위치를 이동해야 하기 때문이다. 이런 경우 모든 색인이 레코드의 새로운 힙 위치를 가리키게끔 갱신하거나 이전 힙 위치에 전방향 포인터를 남겨둬야 한다.

**색인에서 힙 파일로 다시 이동하는 일은 읽기 성능에 불이익이 너무 많기 때문에 어떤 상황에선 색인 안에 바로 색인된 로우를 저장하는 편이 바람직하다. 이를 클러스터드 인덱스라 한다.** MySQL의 InnoDB 저장소 엔진에선 테이블의 PK가 항상 클러스터드 인덱스이고, 보조 색인은 기본키를 참조한다.

모든 종류의 데이터 복제와 마찬가지로 클러스터드 인덱스와 커버링 인덱스는 읽기 성능을 높일 수 있지만 추가적인 저장소가 필요하고 쓰기 과정에 오버헤드가 발생한다. 또한 애플리케이션 단에서 복제로 인한 불일치를 파악할 수 없기 때문에 데이터베이스는 트랜잭션 보장을 강화하기 위해 별도의 노력이 필요하다.

### 다중 칼럼 색인
다중 칼럼 색인의 가장 일반적인 유형은 결합 색인인데, 하나의 칼럼에 다른 칼럼을 추가하는 방식으로 하나의 키에 여러 필드를 단순히 결합한다.

### 전문 검색과 퍼지 색인
앞선 모든 색인들은 정확한 데이터를 대상으로 키의 정확한 값이나 정렬된 키의 값의 범위를 질의할 수 있다고 가정한다. 이 색인으로는 철자가 틀린 단어와 같이 유사한 키에 대해선 검색할 수 없다. 이처럼 애매모호한 질의에는 다른 기술이 필요하다.

예를 들어 전문 검색 엔진은 일반적으로 특정 단어를 검색할 때 해당 단어의 동의어로 질의를 확장한다. 그리고 단어의 문법적 활용을 무시하고 동일한 문서에서 서로 인접해 나타난 단어를 검색하거나 언어학적으로 텍스트를 분석해 사용하는 등 다양한 기능을 제공한다. 루씬은 문서나 질의의 오타에 대처하기 위해 특정 편집 거리 내 단어를 검색할 수 있다.

### 모든 것을 메모리에 보관
지금까지 나온 데이터 구조는 모두 디스크 한계에 대한 해결책이었다. 디스크는 메인 메모리와 비교해 다루기 어렵다. HDD와 SSD를 사용할 때 읽기와 쓰기에서 좋은 성능을 원한다면 주의해서 데이터를 디스크에 배치해야 한다. 이런 이상함을 참을 수 있는 이유는 디스크에는 주요한 두 가지 장점이 있기 때문이다. 디스크는 지속성이 있고 램보다 기가바이트당 가격이 더 저렴하다.

램이 점점 저렴해져서 가격 논쟁도 약해졌고, 데이터셋 대부분은 그다지 크지 않기 때문에 메모리에 전체를 보관하는 방식도 꽤 현실적이다. 게다가 여러 장비 간 분산해서 보관할 수도 있다. 때문에 인메모리 데이터베이스가 개발됐다.

맴캐시드 같은 일부 인매모리 키-값 저장소는 장비가 재시작되면 데이터 손실을 허용하는 캐시 용도로만 사용된다. 하지만 다른 인메모리 데이터베이스는 지속성을 목표로 한다. 이 목표를 달성하는 방법은 특수 하드웨어를 사용하거나 디스크에 변경 사항의 로그를 기록하거나 디스크에 주기적인 스냅숏을 기록하거나 다른 장비에 인메모리 상태를 복제하는 방법이 있다.

참고로 Redis는 비동기로 디스크에 기록하기 때문에 약한 지속성을 제공한다.

직관에 어긋나지만 인메모리 데이터베이스의 성능 장점은 디스크에서 읽지 않아도 된다는 사실 때문은 아니다. 심지어 디스크 기반 저장소 엔진도 OS가 최근에 사용한 디스크 블록을 메모리에 캐시하기 때문에 충분한 메모리를 가진 경우에는 디스크에서 읽을 필요가 없다. 오히려 인메모리 데이터 구조를 디스크에 기록하기 위한 형태로 부호화하는 오버헤드를 피할 수 있어 더 빠를 수도 있다.

성능 외에도 인메모리 데이터베이스는 디스크 기반 색인으로 구현하기 어려운 데이터 모델을 제공한다. Redis는 우선순위 큐와 set 같은 다양한 데이터 구조를 데이터베이스 같은 인터페이스로 제공한다. 또한 메모리에 모든 데이터를 유지하기 때문에 구현이 비교적 간단하다.

## 트랜잭션 처리나 분석?
보통 애플리케이션은 색인을 사용해 일부 키에 대한 적은 수의 레코드를 찾는다. 레코드는 사용자 입력을 기반으로 삽입되거나 갱신된다. 이런 애플리케이션은 대화식이기 때문에 이 접근 패턴을 온라인 트랜잭션 처리(OLTP)라 한다.

그러나 DB를 데이터 분석에도 점점 더 많이 사용하기 시작했다. 데이터 분석은 트랜잭션과 접근 패턴이 매우 다르다. 보통 분석 질의는 사용자에게 원시 데이터를 반환하는 것이 아니라 많은 수의 레코드를 스캔해 레코드당 일부 칼럼만 읽어(카운트, 합, 평균 같은) 집계 통계를 계산해야 한다. 이런 질의는 보통 비즈니스 인텔리전스에 사용된다. 이런 DB 사용 패턴을 트랜잭션 처리와 구별하기 위해 온라인 분석 처리(OLAP)라고 한다.

<img width="799" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/704a70ea-6290-4e0e-8068-56f93e7de837">

### 데이터 웨어하우징
OLTP 시스템은 대개 사업 운영에 대단히 중요하기 때문에 일반적으로 높은 가용성과 낮은 지연 시간의 트랜잭션 처리를 기대한다. DBA는 OLTP DB를 철저하게 보호하려 하고, 비즈니스 분석가가 이 DB에 즉석 분석 질의를 실행하는 것을 꺼려한다. 이는 비용이 대게 비싸기 때문이다. 분석 질의가 데이터셋의 많은 부분을 스캔해 이와 동시에 실행되는 트랜잭션의 성능을 저하시킬 가능성이 있다.

**반대로 데이터 웨어하우스는 분석가들이 OLTP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 DB다. 데이터 웨어하우스는 회사 내의 모든 다양한 OLTP 시스템에 있는 데이터의 읽기 전용 복사본이다.** 데이터는 OLTP DB에서 추출하고 분석 친화적인 스키마로 변환하고 깨끗하게 정리한 다음 데이터 웨어하우스에 적재한다.

<img width="600" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/8b6f402f-686f-4d00-ad7f-83867c4e3dd8">

### OLTP DB와 데이터 웨어하우스의 차이점
SQL은 일반적으로 분석 질의에 적합하기 때문에 데이터 웨어하우스의 데이터 모델은 가장 일반적인 관계형 모델을 사용한다. SQL 질의를 생성하고 결과를 시각화하고 분석가가 데이터를 탐색할 수 있게 해주는 여러 그래픽 데이터 분석 도구가 있다. (Hadoop, Spark, ...)

## 칼럼 지향 저장소
테이블에 엄청난 개수의 로우와 페타바이트 데이터가 있다면 효율적으로 저장하고 질의하기는 어려운 문제가 된다. 대부분의 OLTP DB에서 저장소는 로우 지향 방식으로 데이터를 배치한다. 테이블에서 한 로우의 모든 값은 서로 인접하게 저장된다. 이는 문서 데이터베이스와 유사하다. 문서 데이터베이스에서 전체 문서는 보통 하나의 연속된 바이트 열로 저장한다.

칼럼 지향 저장소의 기본 개념은 간단하다. 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼별로 모든 값을 함께 저장한다. 각 칼럼을 개별 파일에 저장하면 질의에 사용되는 칼럼만 읽고 구분 분석한다. 이 방식을 사용하면 작업량이 많이 줄어든다.

<img width="619" alt="image" src="https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/d42eb213-16b2-4f3f-9060-eccc7529975b">

칼럼 지향 저장소 배치는 각 칼럼 파일에 포함된 로우가 모두 같은 순서인 점에 의존한다.

### 칼럼 압축
질의에 필요한 칼럼을 디스크에서 읽어 적재하는 작업 외에도 데이터를 압축하면 디스크 처리량을 더 줄일 수 있다. 칼럼 지향 저장소는 대개 압축에 적합하다. 다양한 압축 기법 중 한 가지 기법은 데이터 웨어하우스에 특히 효과적인 비트맵 부호화다.

### 메모리 대역폭과 벡터화 처리
수백만 로우를 스캔해야 하는 데이터 웨어하우스 질의는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 큰 병목이다. 하지만 이 병목이 유일한 것은 아니다. 분석용 데이터베이스 개발자는 메인 메모리에서 CPU 캐시로 가는 대역폭을 효율적으로 사용하고 CPU 명령 처리 파이프라인에서 분기 예측 실패와 버블을 피하며 최신 CPU에서 단일 명령 다중 데이터 명령을 사용하게끔 신경 써야 한다.

- 벡터화 처리

### 집계: 데이터 큐브와 구체화 뷰
질의가 자주 사용하는 일부 count나 sum을 캐시하곤 하는데 이런 캐시를 만드는 한 가지 방법이 구체화 뷰다. 관계형 데이터 모델에선 이런 캐시를 대개 표준 (가상) 뷰로 정의한다. 표준 뷰는 테이블 같은 객체로 일부 질의의 결과가 내용이다. 차이점으로 구체화 뷰는 디스크에 기록된 질의 결과의 실제 복사본이지만 가상 뷰는 단지 질의를 작성하는 단축키일 뿐이다. 가상 뷰에서 읽을 때 SQL 엔진은 뷰의 원래 질의로 즉석에서 확장하고 나서 질의를 처리한다.