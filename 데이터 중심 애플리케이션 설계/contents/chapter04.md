# 4장. 부호화와 발전
애플리케이션은 필연적으로 시간이 지남에 따라 변한다. 새로운 제품을 출시하거나 사용자 요구사항을 잘 이해하게 되거나 비즈니스 환경이 변함에 따라 애플리케이션 기능은 추가되거나 변경된다. 대부분의 경우 애플리케이션 기능을 변경하려면 저장하는 데이터도 변경해야 한다. 아마 새로운 필드나 레코드 유형을 저장해야 하거나 기존 데이터를 새로운 방법으로 제공해야 할지 모른다.

데이터 타입이나 스키마가 변경될 때 애플리케이션 코드에 대한 변경이 종종 발생한다. 하지만 대규모 애플리케이션에서 코드 변경은 대개 즉시 반영할 수 없다.

- 서버 측 애플리케이션에서는 한 번에 몇 개의 노드에 새 버전을 배포하고 새로운 버전이 원활하게 실행되는지 확인한 다음 서서히 모든 노드에서 실행되게 하는 순회식 업그레이드(rolling upgrade)(단계적 롤아웃(staged rollout)이라고도 함) 방식이 있다. 이는 서비스 정지 시간 없이 새로운 버전을 배포할 수 있기 때문에 더욱 자주 출시할 수 있다. 이 점이 더 좋은 발전성을 갖게 해준다.
- 클라이언트 측 애플리케이션은 사용자에 전적으로 좌우된다. 어떤 사용자는 한동안 업데이트를 설치하지 않을 수도 있다.

**이것은 예전 버전의 코드와 새로운 버전의 코드, 이전의 데이터 타입과 새로운 데이터 타입이 어쩌면 모든 시스템에 동시에 공존할 수 있다는 의미다.** 시스템이 계속 원활하게 실행되게 하려면 양방향으로 호환성을 유지해야 한다.

- 하위 호환성: 새로운 코드는 예전 코드가 기록한 데이터를 읽을 수 있어야 한다. 새로운 코드 쓰기는 예전 버전의 코드가 기록한 데이터의 형식을 알기에 명시적으로 해당 형식을 다룰 수 있다.
- 상위 호환성: 예전 코드는 새로운 코드가 기록한 데이터를 읽을 수 있어야 한다. 예전 버전의 코드가 새 버전의 코드에 의해 추가된 것을 무시할 수 있어야 하므로 다루기 더 어렵다.

## 데이터 부호화 형식
프로글매은 보통 최소한 두 가지 형태로 표현된 데이터를 사용해 동작한다.

메모리에 객체(Object), 구조체(struct), 목록(list), 배열(array), 해시 테이블(hash table), 트리(tree) 등으로 데이터가 유지된다. 이런 데이터 구조는 CPU에서 효율적으로 접근하고 조작할 수 있게 보통은 포인터를 이용해 최적화된다.

데이터를 파일에 쓰거나 네트워크를 통해 전송하려면 스스로를 포함한 일련의 바이트열(ex. JSON)의 형태로 부호화해야 한다. 포인터는 다른 프로세스가 이해할 수 없으므로 이 일련의 바이트열은 보통 메모리에서 사용하는 데이터 구조와는 상당히 다르다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/17fe4278-4434-4f19-961c-fcae3f8e136e)

따라서 두 가지 표현 사이에 일종의 전환이 필요하다.

- 부호화(직렬화, 마셜링): 인메모리 표현에서 바이트열로의 전환
- 복호화(파싱, 역직렬화, 언마셜링): 바이트열에서 인메모리 표현으로 전환

### 언어별 형식
많은 프로그래밍 언어는 인메모리 객체를 바이트열로 부호화하는 기능을 내장한다.

- Java: `java.io.Serializable`
- Ruby: `Marshal`
- Python: `pickle`
- Java의 써드파티 라이브러리: Kryo

프로그래밍 언어에 내장된 부호화 라이브러리는 최소한의 추가 코드로 인메모리 객체를 저장하고 복원할 수 있기 때문에 매우 편리하지만 심각한 문제점 또한 많다.

- 부호화는 보통 특정 프로그래밍 언어와 묶여 있어 다른 언어에서 데이터를 읽기는 매우 어렵다. 이런 부호화로 데이터를 저장하고 전송하는 경우 매우 오랜 시간이 될지도 모를 기간 동안 현재 프로그래밍 언어로만 코드를 작성해야 할 뿐 아니라 다른 시스템과 통합하는 데 방해가 된다.
- 동일한 객체 유형의 데이터를 복원하려면 복호화 과정이 임의의 클래스를 인스턴스화할 수 있어야 한다. 이것은 종종 보안 문제의 원인이 된다. 공격자가 임의의 바이트열을 복호화할 수 있는 애플리케이션을 얻을 수 있으면 임의의 클래스를 인스턴스화할 수 있고 공격자가 원격으로 임의 코드를 실행하는 것과 같은 끔찍한 일이 발생할 수 있다.
- 데이터 버전 관리는 보통 부호화 라이브러리에선 나중에 생각하게 된다. 데이터를 빠르고 쉽게 부호화하기 위해 상위, 하위 호환성의 불편한 문제가 등한시되곤 한다.
- 부호화나 복호화에 소요되는 CPU 시간과 부호화된 구조체의 크기 같은 효율성도 종종 나중에 생각하게 된다. (ex. Java의 내장 직렬화는 성능이 좋지 않고 비대해지는 부호화로 유명하다.)

이런 이유로 매우 일시적인 목적 외에 언어에 내장된 부호화를 사용하는 방식은 일반적으로 좋지 않다.

### JSON과 XML, 이진 변형
JSON이 XML 대비 단순하고, 웹 브라우저에 내장된 지원 때문에 인기가 더 많다. 그리고 CSV도 있다. JSON, XML, CSV는 텍스트 형식이라 어느 정도 사람이 읽을 수 있다. 피상적인 문법적 문제 외에도 일부 미묘한 문제가 있다.

- 수(number)의 부호화에는 많은 애매함이 있다. XML과 CSV에선 수와 숫자(digit)로 구성된 문자열을 구분할 수 없다. JSON은 문자열과 수를 구분하지만 정수와 부동소수점 수를 구별하지 않고 정밀도를 지정하지 않는다.
- 2^53을 넘어가면 부동 소수점 문제가 발생한다. twitter는 이 문제를 해결하기 위해 64bit 숫자를 사용한다.
- JSON과 XML은 유니코드 문자열을 잘 지원한다. 그러나 이진 문자열을 지원하지 않는다.
  - 이진 문자열은 매우 유용하다. 그래서 이진 데이터를 Base64를 사용해 텍스트로 부호화해 이런 제한을 피한다.
  - 그리고 값이 Base64로 부호화 되었다는 사실을 스키마를 사용해 표시한다.
  - 데이터 크기가 33% 증가한다.
- CSV는 스키마가 없으므로 각 로우와 컬럼의 의미를 정의하는 작업은 애플리케이션이 해야 한다.

이런 결점에도 JSON, XML, CSV는 다양한 용도에 사용하기 충분하다. 이 부호화 형식들은 앞으로도 인기를 유지할 것이다. **특히 데이터 교환 형식(즉, 한 조직에서 다른 조직으로 데이터를 전송)으로 사용하기에 매우 좋다.**

### 이진 부호화
작은 데이터셋의 경우 부호화 형식 선택으로 얻는 이득이 무시할 정도지만 테라바이트 정도가 되면 데이터 타입의 선택이 큰 영향을 미친다.

- JSON은 XML보다 덜 장황하지만 이진 형식과 비교하면 둘 다 훨씬 많은 공간을 사용한다.
- JSON은 스키마를 지정하지 않기 때문에 부호화된 데이터 안에 모든 객체의 필드 이름을 포함해야 한다.

```json
{
  "userName": "Martin",
  "favoriteNumber": 1337,
  "interests": ["daydreaming", "hacking"]
}
```

메시지팩의 예를 살펴보자. 메시지팩은 JSON용 이진 부호화 형식이다. JSON 문서를 메시지 팩으로 부호화해 얻은 바이트다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/57d75c14-bbe7-4936-8856-7fb00010a5ad)

1. 첫 번째 바이트인 0x83은 이어지는 내용이 세 개의 필드(하위 4비트 = 0x03)를 가진 객체(상위 4비트 = 0x80)라는 뜻이다.
2. 두 번째 바이트는 0xa8은 이어지는 내용이 8바이트 길이(하위 4비트 = 0x08)의 문자열(상위 4비트 = 0xa0)이라는 의미다.
3. 다음 8바이트는 필드 이름인 `userName`의 아스키 코드다. 길이는 이전에 표시됐기 때문에 문자열이 끝나는 곳을 표시(또는 이스케이핑)할 필요가 없다.
4. 다음 7바이트는 앞에 0xa6이 붙고 `Martin`이라는 6글자 문자열 값을 부호화한다.

이진 부호화는 길이가 66바이트로 텍스트 JSON 부호화로 얻은 81바이트보다 약간 작다. JSON의 모든 이진 부호화는 이와 비슷하다. 이 같은 작은 공간의 절약이 사람의 가독성을 해칠 만큼 가치가 있는지는 확실치 않다.

### 스리프트와 프로토콜 버퍼
아파치 스리프트(Apache Thrift)와 프로토콜 버퍼(Protocol Buffers)는 같은 원리를 기반으로 한 이진 부호화 라이브러리다. 둘 다 부호화할 데이터를 위한 스키마가 필요하다.

스리프트로 앞선 JSON을 부호화하려면 다음과 같이 스리프트 인터페이스 정의 언어로 스키마를 기술해야 한다.

```thrift
struct Person {
  1: required string    userName,
  2: optional i64       favoriteNumber,
  3: optional list<string> interests
}
```

프로토콜 버퍼로 정의한 동등한 스키마는 스리프트 스키마와 매우 비슷하다.

```protobuf
message Person {
  required string user_name      = 1;
  optional int64 favorite_number = 2;
  repeated string interests      = 3;
}
```

위 두 정의를 이용해 코드를 생성하는 도구를 가지고 다양한 프로그래밍 언어로 스키마를 구현한 클래스를 생성한다. 애플리케이션 코드는 생성된 코드를 호출해 스키마의 레코드를 부호화하고 복호화할 수 있다.

이 스키마로 부호화된 데이터는 어떤 모습일까? 스리프트는 바이너리프로토콜과 컴팩트프로토콜이라는 두 가지 다른 이진 부호화 형식이 있다.

- 스리프트 바이너리 프로토콜
  - 59바이트

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/569074b5-2ab0-4022-9730-14db6c0346ca)

- 스리프트 컴팩트 프로토콜
  - 34바이트
  - 필드 타입과 태그 숫자를 단일 바이트로 줄임
  - 가변 길이 정수를 사용해서 부호화
  - 숫자 1337도 2바이트로 부호화. 더 큰 숫자는 더 많은 바이트를 사용한다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/7adc4ff0-3b88-4fee-949a-564c52d0933c)

- 프로토콜 버퍼
  - 컴팩트 프로토콜과 비슷하고 33바이트
  - 스키마에서 각 필드에는 `required`나 `optional` 표시가 되어 있다. 하지만 필드를 부호화하는 방법에는 차이가 없으냐 `required`를 사용하면 필드가 설정되지 않은 경우를 실행 시에 확인할 수 있다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/dbe9cd84-c8e0-41ac-aba1-e4ddacb0f462)

#### 필드 태그와 스키마 발전
스키마는 필연적으로 시간이 지남에 따라 변하고 이를 스키마 발전(schema evolution)이라 부른다.

- 부호화된 레코드는 부호화된 필드의 연결일 뿐이다.
  - 각 필드는 태그 숫자로 식별하고 데이터타입을 주석으로 단다.
  - 필드 값을 설정하지 않으면 부호화 레코드에서 생략한다.
- 필드 태그가 없으면 기존의 모든 부호화된 데이터를 인식 불가능하게 만들 수 있기 때문에 변경 불가능하다.
- 태그 번호를 추가하는 것으로 스키마에 새로운 필드를 추가할 수 있다.
  - 예전 코드(v1)은 새로운 태그 번호 추가에 대해 알지 못한다.
  - 새로운 코드(v2)로 기록한 데이터를 읽으려 할 때 v1 코드가 모르는 태그 번호를 가진 필드가 있기 마련인데 이 경우, 해당 필드를 무시한다. → 상위 호환성이 유지된다.
- 각 필드 태그 번호가 있는 동안에는 같은 의미를 유지하기에 새로운 코드도 항상 예전 데이터를 읽을 수 있다.
  - 하위 호환성이 유지된다.
- 하지만 새로운 필드를 추가했을 때 `required`로 하면 예전 코드로 기록한 데이터엔 이 필드가 없다. 따라서 새로운 코드가 예전 코드로 기록한 데이터를 읽는 작업은 실패한다.
- 호환성을 위해서는 스키마의 초기 배포후에 추가되는 모든 필드는 `optional`로 하거나 기본값을 가져야 한다.

#### 데이터타입과 스키마 발전
필드의 데이터타입을 변경하는 것은 불가능하진 않지만 값이 정확하지 않거나 잘릴 위험이 있다.

32bit 정수를 64bit 정수로 바꾼다고 가정해보자.

- 파서가 누락된 비트를 0으로 채울 수 있기 때문에 새로운 코드는 예전 코드가 기록한 데이터를 쉽게 읽을 수 있다.
- 새로운 코드가 기록한 데이터를 예전 코드가 읽는 경우 예전 코드는 값을 유지하기 위해 32bit 변수를 계속 사용한다.
  - 복호화된 64bit 값은 32bit에 맞지 않기 때문에 잘리게 된다.

프로토콜 버퍼에는 목록이나 배열 데이터타입이 없지만 대신 필드에 `repeated` 표시자가 있다. 이 필드의 부호화는 레코드에 단순히 동일한 필드 태그가 여러 번 나타난다. `optional` 필드를 `repeated` 필드로 변경해도 문제가 없다. 이전 데이터를 읽는 새로운 코드는 필드의 존재 여부에 따라 0이나 1개의 엘리멘트가 있는 목록으로 보게 되고 새로운 데이터를 읽는 예전 코드는 목록의 마지막 엘리먼트만 보게 된다.

### 아브로
아파치 아브로는 프로토콜 버퍼와 스리프트와는 다르지만 이들과 대적할 만한 또 하나의 이진 부호화 형식이다. 아브로도 부호화할 데이터 구조를 지정하기 위해 스키마를 사용한다. 아브로엔 두 개의 스키마 언어가 있다.

- 아브로 IDL

```
record Person {
  string                  userName;
  union { null, long }    favoriteNumber = null;
  array<string>           interests;
}
```

- JSON 표현

```json
{
  "type": "record",
  "name": "Person",
  "fields": [
    {"name": "userName", "type": "string"},
    {"name": "favoriteNumber", "type": ["null", "long"], "default": null},
    {"name": "interests", "type": {"type": "array", "items": "string"}}
  ]
}
```

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/f75da909-9dd9-4179-a8d7-580ca91adf44)

- 스키마에 태그 번호가 없다.
- 32바이트로 이진 부호화시 길이가 가장 짧다.
- 필드나 데이터 타입을 식별하기 위한 정보가 없다.
- 단순 연결된 값이다.
- 문자열은 길이 다음에 UTF-8 바이트가 이어지지만 문자열임을 알려주는 정보가 없다.
- 정수는 가변 길이 부호화를 사용해서 부호화된다.
- 아브로를 이용해 이진 데이터를 파싱하려면 스키마에 나타난 순서대로 필드를 살펴보고 스키마를 이용해 각 필드의 데이터타입을 미리 파악해야 한다.
- 데이터를 읽는 코드가 데이터를 기록한 코드와 정확히 같은 스키마를 사용할 때만 올바르게 복호화할 수 있음을 의미한다.

#### 쓰기 스키마와 읽기 스키마
애플리케이션이 파일이나 데이터베이스에 쓰기 위해 또는 네트워크를 통해 전송 등의 목적으로 어떤 데이터를 아브로로 부호화하길 원한다면 알고 있는 스키마 버전을 사용해 데이터를 부호화한다. 해당 스키마를 애플리케이션에 포함할 수 있고 이를 쓰기 스키마라 한다.

애플리케이션이 파일이나 데이터베이스에서 또는 네트워크로부터 수신 등으로 읽은 어떤 데이터를 복호화하길 원한다면 데이터가 특정 스키마로 복호화하길 기대한다. 애플리케이션 코드는 이 스키마에 의존하고 이를 읽기 스키마라 한다. 복호화 코드는 애플리케이션을 빌드하는 동안 스키마로부터 생성된다.

아브로의 핵심 아이디어는 쓰기 스키마와 읽기 스키마가 동일하지 않아도 되며 단지 호환 가능하면 된다는 것이다. 데이터를 복호화 할 때 아브로 라이브러리는 쓰기 스키마와 읽기 스키마를 함께 살펴본 다음 쓰기 스키마에서 읽기 스키마로 데이터를 변환해 그 차이를 해소한다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/f6b0636a-5e41-4836-81ce-1b0f86f75604)

스키마 해석에선 이름으로 필드를 일치시킨다. 데이터를 읽는 코드가 읽기 스키마에는 없고 쓰기 스키마에 존재하는 필드를 만나면 이 필드는 무시한다. 데이터를 읽는 코드가 기대하는 어떤 필드가 쓰기 스키마에는 포함돼 있지 않은 경우엔 읽기 스키마에 선언된 기본값으로 채운다.

#### 스키마 발전 규칙
아브로에서 상위 호환성은 새로운 버전의 쓰기 스키마와 예전 버전의 읽기 스키마를 가질 수 있음을 의미한다. 반대로 하위 호환성은 새로운 버전의 읽기 스키마와 예전 버전의 쓰기 스키마를 가질 수 있음을 의미한다.

호환성을 유지하기 위해선 기본값이 있는 필드만 추가하거나 삭제할 수 있다. 기본값이 있는 필드를 추가해서 새로운 스키마에는 추가된 필드가 있고 예전 스키마엔 없으면, 새로운 스키마를 사용하는 읽기가 예전 스키마로 기록된 레코드를 읽으면 누락된 필드는 기본값으로 채워진다. 기본값이 없는 필드를 추가하면 새로운 읽기는 예전 쓰기가 기록한 데이터를 읽을 수 없기 때문에 하위 호환성이 깨진다. 기본값이 없는 필드를 삭제하면 예전 읽기는 새로운 쓰기가 기록한 데이터를 읽을 수 없기 때문에 상위 호환성이 깨진다.

필드에 null을 허용하려면 유니온 타입을 사용해야 한다. 아브로에는 `optional`, `required` 표시자를 가지지 않고 유니온 타입과 기본값이 있다. 타입 변환이 가능하므로 필드의 데이터 타입 변경도 가능하다.

#### 그러면 쓰기 스키마는 무엇인가?
모든 레코드에 전체 스키마를 포함시킬 수는 없다. 스키마는 부호화된 데이터보다 훨씬 클 가능성이 있기 때문이다. 이진 부호화로 절약한 공간이 소용없다.

- 많은 레코드가 있는 대용량 파일
  - 동일 스키마로 인코딩된 커다란 파일인 경우 (수백만개의 레코드) → 하나만 포함해도 되므로 괜찮다.
- 개별적으로 기록된 레코드를 가진 데이터베이스
  - 데이터베이스를 따로 두고 스키마 버전 목록을 유지
- 네트워크 연결을 통해 레코드 보내기
  - 네트워크 연결중에는 동일 스키마를 쓴다고 합의

#### 동적 생성 스키마
관계형 스키마 → Avro 스키마 생성 → 그 스키마를 이용해 데이터베이스 내용을 인코딩 → Avro 객체 컨테이너 파일로 덤프

각 데이터베이스 테이블에 맞게 레코드 스키마를 생성하고 각 칼럼은 해당 레코드의 필드가 된다. 데이터베이스의 칼럼 이름은 아브로의 필드 이름에 매핑된다. 새로운 데이터 파일을 읽는 사람은 레코드 필드가 변경된 사실을 알게 되지만 필드는 이름으로 식별되기 때문에 갱신된 쓰기 스키마는 여전히 이전 읽기 스키마와 매칭 가능하다.

#### 코드 생성과 동적 타입 언어
스리프트와 프로토콜 버퍼는 코드 생성에 의존한다.

- 스키마를 정의한 후 선택한 프로그래밍 언어로 스키마를 구현한 코드를 생성할 수 있다.
- Java, C++, C# 같은 정적 타입 언어에서 유용하다.
  - 복호화된 데이터를 위해 효율적인 인메모리 구조를 사용하고 데이터 구조에 접근하는 프로그램을 작성할 때 IDE에서 타입 확인과 자동 완성이 가능하기 때문
- JavaScript, Ruby, Python 같은 동적 타입 프로그래밍 언어
  - 만족시킬 컴파일 시점의 타입 검사기가 없어서 코드를 생성하는 것이 중요하지 않다.
  - 명시적 컴파일 단계가 없다.
  - 동적 생성 스키마의 경우 코드 생성은 데이터를 가져오는 데 불필요한 장애물이다.
- Avro는 정적 타입 프로그래밍언어를 위해 코드 생성을 선택적으로 제공한다.
- 객체 컨테이너 파일이 있다면 Avro 라이브러리를 사용해 간단히 열어 JSON 파일을 보는 것과 같이 데이터를 볼 수 있다.

### 스키마의 장점
- 프로토콜 버퍼, 스리프트, 아브로와 같은 스키마 언어는 XML 스키마나 JSON 스키마보다 훨씬 간단하며 더 자세한 유효성 검사 규칙을 지원한다.
- 구현과 사용이 더 간단하므로 상당히 광범위한 프로그래밍 언어를 지원하는 방향으로 성장 중이다.
- 이진 부호화를 독자적으로 구현하기도 한다.
  - 대부분의 관계형 데이터베이스에는 질의를 데이터베이스로 보내고 응답을 받을 수 있는 네트워크 프로토콜이 있다.
  - 특정 데이터베이스에 특화되고 데이터베이스 벤더는 데이터베이스 네트워크 프로토콜로부터 응답을 인메모리 데이터 구조로 복호화 하는 드라이버를 제공한다.

JSON, XML, CSV 같은 텍스트 데이터 타입이 널리 사용되지만 스키마를 기반으로 한 이진 부호화 또한 가능한 선택이다.

- 필드 이름을 생략할 수 있어 크기가 작을 수 있다.
- 스키마 자체가 유용한 문서화 형식이다.
- 스키마 DB를 유지하면 스키마 변경을 적용하기 전에 상/하위 호환성을 확인할 수 있다.
- 정적 타입 프로그래밍 언어에서 스키마로부터 코드를 생성하는건 유용하다. 컴파일 시점에 타입 체크를 할 수 있기 때문이다.

## 데이터 플로 모드
데이터플로는 매우 추상적인 개념으로서 하나의 프로세스에서 다른 프로세스로 데이터를 전달하는 방법은 아주 많다. 누가 데이터를 부호화하고 누가 그것을 복호화할까?

- 데이터베이스를 통해
- 서비스 호출을 통해
- 비동기 메시지 전달을 통해

### 데이터베이스를 통한 데이터플로
데이터베이스에 기록하는 프로세스는 데이터를 부호화하고 데이터베이스에서 읽는 프로세스는 데이터를 복호화한다. 데이터베이스를 접근하는 단일 프로세스가 있다고 하자. 읽기는 단순히 동일 프로세스의 최신 버전이다.

데이터베이스에는 다양한 프로세스가 접근할 수 있기 때문에 데이터베이스 내 값이 새로운 버전의 코드로 기록된 다음 현재 수행 중인 예전 버전의 코드로 그 값을 읽을 가능성이 있다. 따라서 데이터베이스의 상위 호환성도 필요하다.

레코드 스키마에 필드를 추가하고 새로운 코드는 새로운 필드를 위한 값을 데이터베이스에 기록한다고 하자. 예전 버전의 코드가 레코드를 읽고 갱신한 후 갱신한 값을 다시 기록한다면 바람직한 동작은 보통 예전 코드가 해석할 수 없더라도 새로운 필드를 그대로 유지하는 것이다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/c8b113c1-0131-4299-b9e2-33c13af5ab10)

#### 다양한 시점에 기록된 다양한 값
데이터베이스는 값 갱신이 가능하므로 어떤 값은 5밀리초 전일지라도, 5년 전일지라도 애플리케이션은 몇 분 내에 예전 버전을 새로운 버전으로 완전히 대체할 수 있지만 데이터베이스는 그렇지 않다. 명시적으로 다시 기록하지 않는 한 원래의 부호화 상태로 그대로 있다.

데이터를 새로운 스키마로 다시 기록하는 것은 데용량 데이터셋 대상으로는 값비싼 작업이니 대부분의 데이터베이스에서 가능하면 이런 상황을 피한다. 대부분의 관계형 데이터베이스는 기존 데이터를 다시 기록하지 않고 null을 기본값으로 갖는 새로운 칼럼을 추가하는 간단한 스키마 변경을 허용한다. 예전 로우를 읽는 경우 디스크 상의 부호화된 데이터에서 누락된 임의 칼럼은 null로 채운다.

#### 보관 저장소
백업 목적이나 데이터 웨어하우스로 적재하기 위해 데이터베이스의 스냅숏을 수시로 만든다고 가정하자. 이 경우 데이터 덤프는 보통 최신 스키마를 사용해 부호화한다. 소스 데이터베이스의 원본 부호화에 다양한 시점의 스키마 버전이 섞여 포함됐더라도 말이다. 어쨌든 데이터를 복사하기 때문에 데이터의 복사본을 일관되게 부호화하는 편이 낫다.

데이터 덤프는 한 번에 기록하고 이후에는 변하지 않으므로 아브로 객체 컨테이너 파일과 같은 형식이 적합하다.

### 서비스를 통한 데이터플로: REST와 RPC
API는 표준화된 프로토콜과 데이터 타입(HTTP, URL, SSL/TLS, HTML 등)으로 구성된다. 웹 브라우저, 웹 서버, 웹 사이트 작성자 대부분이 이 표준에 동의하기 때문에 이론적으론 모든 웹 브라우저로 모든 웹 사이트에 접근할 수 있다.

각각의 서버는 클라이언트로 동작할 수 있고 이런식으로 하나의 서비스가 또 다른 서비스의 일부 기능이나 데이터가 필요하다면 해당 서비스에 요청을 하는 개발 방식을 서비스 지향 설계(SOA)라고 불렀고 최근에는 이를 더욱 개선해 MSA라고 부른다.

MSA에선 각 서비스들이 독립적으로 관리되고 배포된다. 예전 버전과 새로운 버전의 서버와 클라이언트가 동시에 실행된다. 예전 버전과 새로운 버전의 서버와 클라이언트가 동시에 실행되기를 기대한다. 따라서 서버와 클라이언트가 사용하는 데이터 부호화는 서비스 API의 버전 간 호환이 가능해야 한다.

#### 원격 프로시저 호출(RPC) 문제
RPC 모델은 원격 네트워크 서비스 요청을 같은 프로세스 안에서 특정 프로그래밍 언어의 함수나 메서드를 호출하는 것과 동일하게 사용 가능하게 해준다. 하지만 이 방식은 근본적으로 결함이 있다. 네트워크 요청은 로컬 함수 호출과는 매우 다르다.

로컬 함수 호출은 예측 가능하다. 그래서 제어 가능한 매개변수에 따라 성공하거나 실패한다. 네트워크 요청은 예측이 어렵다. 네트워크 문제로 요청과 응답이 유실되거나 원격 장비가 느려지거나 요청에 응답하지 않을 수 있다. 이런 문제는 전혀 제어할 수 없다. 네트워크 문제는 일상적이므로 네트워크 문제를 함께 고려해야 한다. 예를 들어 실패한 요청을 다시 보내는 것과 같은 대책을 세워야 한다.

- 로컬 함수 호출은 결과를 반환하거나 예외를 내거나 반환하지 않을 수 있다. 네트워크는 또 다른 결과가 가능하다. 네트워크 요청은 타임아웃으로 결과 없이 반환될 수 있다. 이 경우 무슨 일이 있었는지 쉽게 알 수 있는 방법이 없다.
- 실패한 네트워크 요청을 다시 시도할 때 요청이 실제로는 처리되고 응답만 유실될 수 있다. 이 경우 프로토콜에 중복 제거 기법(멱등성)을 적용하지 않으면 재시도는 작업이 여러 번 수행되는 원인이 된다. 로컬 함수는 이런 문제가 없다.
- 로컬 함수를 호출할 때마다 보통 거의 같은 실행 시간이 소요된다. 네트워크 요청은 함수 호출보다 훨씬 느리고 지연 시간은 매우 다양하다.
- 로컬 함수를 호출하는 경우 참조를 로컬 메모리 객체에 효율적으로 전달할 수 있다. 네트워크로 요청하는 경우에는 모든 매개변수는 네트워크를 통해 전송할 수 있게끔 바이트열로 부호화해야 한다. 매개변수가 숫자나 문자열처럼 원시형이라면 괜찮지만 큰 객체라면 즉시 문제가 될 수 있다.
- 클라이언트와 서비스는 다른 프로그래밍 언어로 구현할 수 있다. 따라서 RPC 프레임워크는 하나의 언어에서 다른 언어로 데이터타입을 변환해야 한다. 모든 언어가 같은 타입을 가지는 것은 아니기 때문에 깔끔하지 않은 모습이 될 수 있다. 단일 언어로 개발한 단일 프로세스에선 이런 문제가 발생하지 않는다.

#### RPC의 현재 방향
- 스리프트와 아브로는 RPC 지원 기능을 내장하고 있다.
- gRPC는 프로토콜 버퍼를 이용한 RPC 구현이다.
- 피네글은 스리프트를 사용하고 `Rest.li`는 HTTP 위에 JSON을 사용한다.

차세대 RPC 프레임워크는 원격 요청이 로컬 함수 호출과 다르다는 사실을 더욱 분명히 한다.

- 피네글과 `Rest.li`
  - 실패할지도 모를 비동기 작업을 캡슐화하기 위해 future(promise)를 사용한다.
  - future는 병렬로 여러 서비스에 요청을 보내야 하는 상황을 간소화하고 요청 결과를 취합한다.
- gRPC는 하나의 요청과 하나의 응답뿐만 아니라 시간에 따른 일련의 요청과 응답으로 구성된 스트림을 지원한다.

REST 상에서 JSON과 같은 부류의 프로토콜보다 이진 부호화 형식을 사용하는 사용자 정의 RPC 프로토콜이 우수한 성능을 제공할지 모른다. 하지만 RESTful API는 다른 중요한 이점이 있다. 실험과 디버깅에 적합하다.

#### 데이터 부호화와 RPC의 발전
발전성이 있으려면 RPC 클라이언트와 서버를 독립적으로 변경하고 배포할 수 있어야 한다.

RPC 스키마의 상하위 호환 속성은 사용된 모든 부호화로부터 상속된다.

- 스리프트 gRPC, 아브로 RPC는 각 부호화 형식의 호환성 규칙에 따라 발전할 수 있다.
- SOAP에서 요청과 응답은 XML, 스키마로 지정된다. 이 방식은 발전 가능하지만 일부 미묘한 함정이 있다.
- RESTful API는 응답에 JSON을 가장 일반적으로 사용한다. 그리고 요청에는 JSON이나 URI 부호화/폼 부호화 요청 매개변수를 사용하곤 한다. 선택적 요청 매개변수 추가나 응답 객체의 새로운 필드 추가는 대개 호환성을 유지하는 변경으로 간주한다.

RPC가 종종 조직 경계를 넘나드는 통신에 사용된다는 사실은 서비스 호환성 유지를 더욱 어렵게 한다. 서비스 제공자는 보통 클라이언트를 제어할 수 없고 강제로 업그레이드도 할 수 없기 때문에 호환성은 오랜 시간 동안 무한정 유지돼야 한다. 호환성을 깨는 변경이 필요하면 서비스 제공자는 보통 여러 버전의 서비스 API를 함께 유지한다.

API 버전 관리가 반드시 어떤 방식으로 동작해야 한다는 합의는 없다. RESTful API는 URL이나 HTTP Accept 헤더에 버전 번호를 사용하는 방식이 일반적이다. 특정 클라이언트를 식별하는 데 API 키를 사용하는 서비스는 클라이언트의 요청 API 버전을 서버에 저장한 뒤 버전 선택을 별도 관리 인터페이스를 통해 갱신할 수 있게 하는 것이 한 가지 방식이다.

### 메시지 전달 데이터플로
REST와 RPC는 하나의 프로세스가 네트워크를 통해 다른 프로세스로 요청을 전송하고 가능한 빠른 응답을 기대하는 방식이다. 그리고 데이터베이스는 하나의 프로세스가 부호화된 데이터를 기록하고 다른 프로세스가 언젠가 그 데이터를 다시 읽는 방식을 사용한다.

- 비동기 메시지 전달 시스템
  - 낮은 지연 시간으로 다른 프로세스에 전달한다는 점에서는 RPC와 비슷하다.
  - 메시지를 직접 네트워크 연결로 전송하지 않고 임시로 메시지를 저장하는 메시지 브로커, 메시지 큐, 메시지 지향 미들웨어라는 중간 단계를 거쳐 전송한다는 점에서는 데이터베이스와 유사하다.

메시지 브로커를 사용하는 방식은 직접 RPC를 사용하는 방식과 비교해 여러 장점이 있다.

- 수신자가 사용 불가능하거나 과부하 상태라면 메시지 브로커가 버퍼처럼 동작할 수 있기 때문에 시스템 안정성이 향상된다.
- 죽었던 프로세스에 메시지를 다시 전달할 수 있기 때문에 메시지 유실을 방지할 수 있다.
- 송신자가 수신자의 IP 주소나 포트 번호를 알 필요가 없다.
- 하나의 메시지를 여러 수신자로 전송할 수 있다.
- 논리적으로 송신자와 수신자는 분리된다.

메시지 전달 통신은 일반적으로 단방향이기에 송신 프로세스는 대게 메시지에 대한 응답을 기대하지 않는다. 이런 통신 패턴이 비동기다. 송신 프로세스는 메시지가 전달될 때까지 기다리지 않고 단순히 메시지를 보낸 다음 잊는다.

#### 메시지 브로커
- 과거의 메시지 브로커
  - 팁코, IBM 웹스피어, 웹메소즈
- 최근의 메시지 브로커
  - RabbitMQ, ActiveMQ, HornetQ, NATS, Apache Kafka

프로세스 하나가 메시지를 이름이 지정된 큐나 토픽으로 전송하고 브로커는 해당 큐나 토픽 하나 이상의 소비자 또는 구독자에게 메시지를 전달한다. 동일한 토픽에 여러 생산자와 소비자가 있을 수 있다. 토픽은 단방향 데이터 플로만 제공한다. 하지만 소비자 스스로 메시지를 다른 토픽으로 게시하거나 원본 메시지의 송신자가 소비하는 응답 큐로 게시할 수 있다.

메시지 브로커는 보통 특정 데이터 모델을 강요하지 않는다. 메시지는 일부 메타데이터를 가진 바이트열이므로 모든 부호화 형식을 사용할 수 있다. 부호화가 상하위 호환성을 모두 가진다면 메시지 브로커에서 게시자와 소비자를 독립적으로 변경해 임의 순서로 배포할 수 있는 유연성을 얻게 된다.