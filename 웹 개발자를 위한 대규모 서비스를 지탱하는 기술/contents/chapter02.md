# Chapter 2 - 대규모 데이터 처리 입문
## 하테나 북마크의 데이터 규모
- 데이터가 많을수록 처리에 시간이 걸린다.

2009년 8월 시점의 하테나 북마크의 데이터 규모는 다음과 같다.

- entry 테이블: 1,520만 레코드 → 3GB
- bookmark 테이블: 4,500만 레코드 → 5.5GB
- tag 테이블: 5,000만 레코드
  - 태그 4.8GB
  - HTML 200GB 이상

DB에 들어있는 데이터의 양이 테라바이트, 페타바이트 규모라면 초대규모에 해당한다.

`select url from entry use index(hoge) where eid = 9615899;` 처럼 인덱스를 태우지 않고 쿼리를 던지는 경우 1건 검색에 200초가 경과해도 결과가 나오지 않는다.

## 대규모 데이터 처리의 어려운 점
- **메모리 내에서 계산할 수 없다.**
  - 메모리에 올리지 않으면 기본적으로 디스크를 계속 읽어가며 검색하게 되어 좀처럼 발견할 수 없는 상태가 된다.
  - 데이터 건수가 많으면 그만큼 입력 데이터 건수가 늘어나 계산량이 많아지는 것도 당연하지만 더 큰 문제는 디스크를 읽고 있다는 것이다.
- 메모리는 디스크보다 10^5~10^6배 이상 빠르다.
- HDD를 기준으로 디스크의 구조를 생각하면 헤드의 이동과 원반의 회전이 물리적으로 광속에 가깝게 수행될 수 없다.
- OS는 어느 정도 커버하는 작용을 하는데, 연속된 데이터를 같은 위치에 쌓고 데이터를 읽을 때 4kb 단위로 한꺼번에 읽도록 되어 있다.
- 디스크에서 메모리로, 메모리에서 CPU로 보내는 등의 전송 속도에서도 차이가 크다.

---
병목 규명작업의 기본적인 흐름
- Load Average 확인
  - `top`, `uptime` 명령으로 확인한다.
- CPU, I/O 중 병목 원인 조사
  - `sar`, `vmstat`으로 확인한다.
- CPU 병목 시 다음 과정을 따라 조사한다.
  - 사용자 프로그램의 처리가 병목인지, 시스템 프로그램이 원인인지 확인한다. `top`이나 `sar`로 확인한다.
  - `ps`로 볼 수 있는 프로세스의 상태나 CPU 사용시간 등을 보며 원인이 되고 있는 프로세스를 찾는다.
  - 프로세스를 찾은 후 보다 상세하게 조사할 경우 `strace`로 추적하거나 `oprofile`로 프로파일링을 해서 병목 지점을 좁혀간다.
- 일반적으로 CPU에 부하가 걸리고 있는 것은 다음 상황 중 하나다.
  - 디스크나 메모리 용량 등 그 밖의 부분에선 병목이 되지 않는, 말하자면 이상적인 상태 → 이 상황에서 문제 발생 시 서버 증설이나 프로그램의 로직이나 알고리즘을 개선해 대응한다.
  - 프로그램이 폭주해서 CPU에 필요 이상의 부하가 걸리는 경우 → 오류를 제거해 프로그램이 폭주하지 않도록 대처한다.
- I/O 부하가 높은 케이스
  - 스왑이 발생하고 있을 경우 다음과 같은 점을 실마리로 조사한다.
    - 특정 프로세스가 극단적으로 메모리를 소비하고 있지 않은지를 `ps`로 확인
    - 프로그램의 오류로 메모리를 지나치게 사용하고 있는 경우 프로그램을 개선한다.
    - 탑재된 메모리가 부족한 경우 메모리를 증설한다. 그렇지 못할 경우 분산을 검토한다.
  - 디스크로의 입출력이 빈번하게 발생하고 있는 상황에는 캐시에 필요한 메모리가 부족한 경우를 생각할 수 있다.
    - 메모리 증설로 캐시영역을 확대시킬 수 있는 경우 메모리를 증설
    - 그렇지 않은 경우 데이터 분산이나 캐시서버 도입 등을 검토한다. 때론, 프로그램을 개선해서 I/O 빈도를 줄이는 것도 검토한다.
- OS 튜닝이란 부하의 원인을 알고 이것을 제거하는 것이다. → 병목이 발견되면 이를 제거하는 것.

## 규모 조정의 요소
