# Chapter 2 - 대규모 데이터 처리 입문
## 하테나 북마크의 데이터 규모
- 데이터가 많을수록 처리에 시간이 걸린다.

2009년 8월 시점의 하테나 북마크의 데이터 규모는 다음과 같다.

- entry 테이블: 1,520만 레코드 → 3GB
- bookmark 테이블: 4,500만 레코드 → 5.5GB
- tag 테이블: 5,000만 레코드
  - 태그 4.8GB
  - HTML 200GB 이상

DB에 들어있는 데이터의 양이 테라바이트, 페타바이트 규모라면 초대규모에 해당한다.

`select url from entry use index(hoge) where eid = 9615899;` 처럼 인덱스를 태우지 않고 쿼리를 던지는 경우 1건 검색에 200초가 경과해도 결과가 나오지 않는다.

## 대규모 데이터 처리의 어려운 점
- **메모리 내에서 계산할 수 없다.**
  - 메모리에 올리지 않으면 기본적으로 디스크를 계속 읽어가며 검색하게 되어 좀처럼 발견할 수 없는 상태가 된다.
  - 데이터 건수가 많으면 그만큼 입력 데이터 건수가 늘어나 계산량이 많아지는 것도 당연하지만 더 큰 문제는 디스크를 읽고 있다는 것이다.
- 메모리는 디스크보다 10^5~10^6배 이상 빠르다.
- HDD를 기준으로 디스크의 구조를 생각하면 헤드의 이동과 원반의 회전이 물리적으로 광속에 가깝게 수행될 수 없다.
- OS는 어느 정도 커버하는 작용을 하는데, 연속된 데이터를 같은 위치에 쌓고 데이터를 읽을 때 4kb 단위로 한꺼번에 읽도록 되어 있다.
- 디스크에서 메모리로, 메모리에서 CPU로 보내는 등의 전송 속도에서도 차이가 크다.

---
병목 규명작업의 기본적인 흐름
- Load Average 확인
  - `top`, `uptime` 명령으로 확인한다.
- CPU, I/O 중 병목 원인 조사
  - `sar`, `vmstat`으로 확인한다.
- CPU 병목 시 다음 과정을 따라 조사한다.
  - 사용자 프로그램의 처리가 병목인지, 시스템 프로그램이 원인인지 확인한다. `top`이나 `sar`로 확인한다.
  - `ps`로 볼 수 있는 프로세스의 상태나 CPU 사용시간 등을 보며 원인이 되고 있는 프로세스를 찾는다.
  - 프로세스를 찾은 후 보다 상세하게 조사할 경우 `strace`로 추적하거나 `oprofile`로 프로파일링을 해서 병목 지점을 좁혀간다.
- 일반적으로 CPU에 부하가 걸리고 있는 것은 다음 상황 중 하나다.
  - 디스크나 메모리 용량 등 그 밖의 부분에선 병목이 되지 않는, 말하자면 이상적인 상태 → 이 상황에서 문제 발생 시 서버 증설이나 프로그램의 로직이나 알고리즘을 개선해 대응한다.
  - 프로그램이 폭주해서 CPU에 필요 이상의 부하가 걸리는 경우 → 오류를 제거해 프로그램이 폭주하지 않도록 대처한다.
- I/O 부하가 높은 케이스
  - 스왑이 발생하고 있을 경우 다음과 같은 점을 실마리로 조사한다.
    - 특정 프로세스가 극단적으로 메모리를 소비하고 있지 않은지를 `ps`로 확인
    - 프로그램의 오류로 메모리를 지나치게 사용하고 있는 경우 프로그램을 개선한다.
    - 탑재된 메모리가 부족한 경우 메모리를 증설한다. 그렇지 못할 경우 분산을 검토한다.
  - 디스크로의 입출력이 빈번하게 발생하고 있는 상황에는 캐시에 필요한 메모리가 부족한 경우를 생각할 수 있다.
    - 메모리 증설로 캐시영역을 확대시킬 수 있는 경우 메모리를 증설
    - 그렇지 않은 경우 데이터 분산이나 캐시서버 도입 등을 검토한다. 때론, 프로그램을 개선해서 I/O 빈도를 줄이는 것도 검토한다.
- OS 튜닝이란 부하의 원인을 알고 이것을 제거하는 것이다. → 병목이 발견되면 이를 제거하는 것.

## 규모 조정의 요소
- 웹 서비스에 적합한 형태이고 비용이 저렴하다는 점과 시스템 구성에 유연성이 있다는 점에서 웹 서비스에선 스케일아웃 전략이 주류다.
- 스케일 아웃은 하드웨어를 나열해서 성능을 높이는, 즉 하드웨어를 횡으로 전개해서 확장성을 확보하게 된다.
  - 웹 애플리케이션에서 계산을 수행하고 있을 때, 기본적으로 CPU 부하만 소요된다. 이는 프록시나 AP 서버가 담당할 일이다.

웹 애플리케이션에선 기본적으로 3단 구조로 구성되어 있다.

- 프록시 → AP 서버 → DB

AP 서버에는 CPU 부하만 걸려 부하 분산이 간단하다. 새로운 서버를 추가하고자 한다면 원래 있던 서버와 완전히 동일한 구성을 갖는 서버를 추가하면 된다. 요청을 균등하게 분산하는 것은 로드밸런서가 해준다. 한편 DB측에 I/O 부하가 걸린다. DB를 스케일아웃하면 쓰기 시 데이터 동기화를 어떻게 할 것인가라는 문제가 생긴다.

대규모 환경에선 I/O 부하를 부담하고 있는 서버는 애초에 분산시키기 어려운데다 디스크 I/O가 많이 발생하면 서버가 금새 느려지는 본질적인 문제가 있다.

- CPU 부하의 규모조정은 간단하다.
  - 같은 구성의 서버를 늘리고 로드밸런서로 분산
  - 웹, AP 서버, 크롤러
- I/O 부하의 규모조정은 어렵다.
  - DB
  - 대규모 데이터

## 대규모 데이터를 다루기 위한 기초지식
대규모 데이터를 다루는 방법을 두 가지 관점에서 정리해보자.

- 프로그램을 작성할 때의 요령
- 프로그램 개발의 근간이 되는 기초라는 점에서 전제로서 알아두었으면 하는 것

### 프로그램을 작성할 때의 요령
대규모 시스템을 고민하게 만드는 대규모 데이터, 이것을 다루는 요령은 **'어떻게 하면 메모리에서 처리를 마칠 수 있을까?'** 라는 점이다. 디스크 seek 횟수를 최소화한다는 의미로 메모리를 활용하고자 한다.

또한 **데이터량 증가에 강한 알고리즘을 사용하는 것이다.** 선형탐색보다 Log Order인 알고리즘을 적용하면 횟수가 엄청나게 줄어든다. **데이터 압축이나 검색기술과 같은 테크닉이 활용될 수 있는 국면이 있다.** 압축해서 데이터량을 줄인다면 seek 횟수도 적어지게 되므로 디스크 읽기를 최소화할 수 있다. 또한 메모리에 캐싱하기 쉬워진다.

또한 검색이 중요한 이유는 확장성 면에서 DB에만 맡겨서 해결할 수 없을 때, 특정 용도에 특화된 검색엔진 등을 만들어서 해당 검색 시스템을 웹 애플리케이션에서 이용하는 형태로 전환한다면 속도를 제대로 확보할 수 있기 때문이다. 이러한 이유로 압축과 검색이 중요한 것이다.

### 대규모 데이터를 다루기 전 3대 전제 지식
- OS 캐시
- 분산을 고려한 RDBMS 운용
- 알고리즘과 데이터 구조