# Chapter 3 - OS 캐시와 분산
## OS의 캐시 구조
- 디스크와 메모리 간 속도차는 10^5 ~ 10^6배 이상
- OS는 메모리를 이용해 디스크 액세스를 줄인다.
  - OS는 캐시 구조를 갖추고 있다.

OS는 '가상 메모리 구조'를 갖추고 있다. 이는 논리적인 선형 어드레스를 물리적인 물리 어드레스로 변환하는 것이다.

### 가상 메모리 구조
![](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/46c11a97-6b3d-4e66-96b4-b2786e12bc8b)

- 프로세스에서 메모리를 다루기 쉽게 하는 이점을 제공한다.
- OS가 커널 내에서 메모리를 추상화하고 있다.
- 페이지: OS가 물리 메모리를 확보/관리하는 단위

### Linux의 페이지 캐시 원리
![](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/363e53be-5327-429f-b718-63f8bc85c5bb)

- 디스크의 내용을 일단 메모리에 읽어들인다.
  - 페이지가 작성된다.
- 작성된 페이지는 파기되지 않고 남는다.
  - 페이지 캐시
- 예외의 경우를 제외하고 모든 I/O에 투과적으로 작용한다.
  - 디스크의 캐시를 담당하는 곳(VFS)

### VFS
디스크의 캐시는 페이지 캐시에 의해 제공되지만, 실제 이 디스크를 조작하는 디스크 드라이버와 OS 사이에는 파일 시스템이 끼어 있다. 파일 시스템 위에는 VFS(Virtual File System)이라는 추상화 레이어가 있다. 파일 시스템은 다양한 함수를 갖추고 있는데, 그 인터페이스를 통일하는 것이 VFS의 역할이다. 또한 VFS가 페이지 캐시의 구조를 지니고 있다. 어떤 파일 시스템을 이용하더라도, 어떤 디스크를 읽어내더라도 반드시 동일한 구조로 캐싱된다.

### Linux는 페이지 단위로 디스크를 캐싱한다
![](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/8a9c587e-9d45-477c-9f89-bfc615c2f5fd)

- 페이지 = 가상 메모리의 최소 단위

#### LRU
메모리 여유분이 1.5GB 있고 파일을 4GB 전부 읽게 되면 어떻게 될까?  
구조상으로는 LRU 형태로 되어 있으므로 최근 읽은 부분이 캐시에 남고 과거에 읽은 부분이 파기되어 간다. 따라서 DB도 계속 구동시키면 캐시가 점점 최적화되어 가므로 기동시킨 직후보다 점점 뒤로 갈수록 부하, I/O가 내려가는 특성을 보인다.

### 메모리가 비어 있으면 캐싱
Linux는 메모리가 비어 있으면 전부 캐싱한다. 여기엔 제한이 없어 Linux는 비어 있는 메모리 공간에 계속해서 디스크 내용을 캐싱해간다. 한편 프로세스에서 메모리를 요청했을 때 캐시로 인해 더 이상 메모리가 남아있지 않다면 오래된 캐시를 버리고 프로세스에 메모리를 확보해준다.

```bash
$ sar -r 1 10000

# 생략
19:50:32  kbmemfree kbmemused %memused kbbuffers kbcached %swpused kbswpcad
19:50:33       5800   1005888    99.43     28244   694068     0.00        0
19:50:34       5800   1005888    99.43     28244   694068     0.00        0
19:50:35       5800   1005888    99.43     28244   694068     0.00        0
19:50:36       5800   1005888    99.43     28244   694068     0.00        0
```

`kbcached`는 kilo byte cached의 약자로, 캐싱되어 있는 용량이다. 현재 시스템은 대략 1GB의 메모리를 갖고 있고 그중 694MB, 700MB 가까이 캐시에 사용되고 있다. `%memused`를 보면 메모리를 99% 정도 사용하고 있다.

실제로는 메모리가 비어 있는 곳에 OS가 조금씩 디스크를 캐싱하고 있는 것일 뿐이다.

캐시 이외에 메모리가 필요해지면 오래된 캐시가 파기된다.

### 메모리를 늘려서 I/O 부하 줄이기
지금까지의 내용에 따르면 **메모리를 늘리면 실제 I/O 부하를 줄일 수 있음을 알 수 있다.**
- 메모리를 늘리면 캐시에 사용할 수 있는 용량이 늘어남.
- 캐시에 사용할 수 있는 용량이 늘어나면 보다 많은 데이터를 캐싱할 수 있다.
- 많이 캐싱되면 디스크를 읽는 횟수가 줄어든다.

```bash
$ sar -f /var/log/sa/sa05
14:10:01  CPU %user %nice %system %iowait %idle
14:20:01  all  8.58  0.00    5.84   16.58 69.00
14:30:01  all  7.41  0.00    5.14   17.81 69.63
14:40:01  all  7.74  0.00    4.97   18.56 68.73
14:50:01  all  7.02  0.00    5.01   16.24 71.72
```

`%iowait`가 대략 20% 정도다. 이는 프로세스가 작업을 수행할 때 항상 I/O에서 대기를 한다는 신호다. 이는 그다지 좋지 않다.

메모리를 8GB로 늘린 결과 아래와 같이 대기가 거의 없어졌다.

```bash
$ sar -f /var/log/sa/sa05
14:10:01  CPU %user %nice %system %iowait %idle
14:20:01  all 18.16  0.00   11.56    0.80 69.49
14:30:01  all 12.48  0.00    9.47    0.88 77.17
14:40:01  all 14.20  0.00   10.17    0.91 74.72
14:50:01  all 13.25  0.00    9.74    0.75 76.25
```

이것이 의미하는 것은 4GB에선 전부 캐싱할 수 없었으나 8GB로 늘리고 나니 데이터베이스상의 파일을 대부분 캐시로 올릴 수 있었다는 것이다.

이와 같이 메모리를 늘려 I/O 부하를 줄이자는 것이 데이터가 많아졌을 때의 기본 방침이다.

### 페이지 캐시는 투과적으로 작용한다
```bash
$ sar -r 1 10000

# 생략
18:20:01  kbmemfree kbmemused %memused kbbuffers kbcached %swpused kbswpcad
18:30:01    3566992    167272     4.42     11224    50136     0.00        0
18:40:01    3546264    178000     4.78     12752    66548     0.00        0
18:50:01     112628   3611636    96.98      4312  3499144     0.00       44
```

갑자기 메모리 사용량이 96.98%로 올라가고있다. 순간 매우 큰 파일을 read한 것이다. 이것이 전부 캐시에 저장되어 96%를 사용하게 되었다. OS 부팅 직후에는 커널이 디스크를 그다지 읽지 않았으므로 캐시로 데이터가 거의 유입되지 않았지만, 특정 파일을 read하면 이를 쭉 캐싱해가는 것이다. 파일을 캐싱하는 원리는 대략 이런 형태로 되어 있다.

## I/O 부하를 줄이는 방법
