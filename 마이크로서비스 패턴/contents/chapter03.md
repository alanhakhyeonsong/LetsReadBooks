# 3장. 프로세스 간 통신
## 마이크로서비스 아키텍처 IPC 개요
서비스에 적용 가능한 IPC 기술은 선택의 폭이 넓다.
- 동기 요청/응답 기반: HTTP REST, gRPC
- 비동기 메시지 기반: AMQP, STOMP

메시지 포맷 역시
- 텍스트 포맷: JSON, XML
- 바이너리 포맷: Avro, Protocol Buffer

### 상호 작용 스타일
클라이언트/서비스 상호 작용 스타일은 두 가지 기준으로 분류할 수 있다.

첫째, 일대일/일대다 여부이다.
- 일대일: 각 클라이언트 요청은 정확히 한 서비스가 처리한다.
  - 요청/응답: 클라이언트는 서비스에 요청을 하고 응답을 기다린다. 클라이언트는 응답이 제때 도착하리라 기대하고 대기 도중 블로킹할 수 있다. 결과적으로 **서비스가 서로 강하게 결합되는 상호 작용 스타일**이다.
  - 비동기 요청/응답: 클라이언트는 서비스에 요청을 하고 서비스는 비동기적으로 응답한다. 클라이언트는 대기 중에 블로킹하지 않고, 서비스는 오랫동안 응답하지 않을 수 있다.
  - 단방향 알림: 클라이언트는 서비스에 일방적으로 요청만 하고 서비스는 응답을 보내지 않는다.
- 일대다: 각 클라이언트 요청을 여러 서비스가 협동하여 처리한다.
  - 발행/구독: 클라이언트는 알림 메시지를 발행하고, 여기에 관심 있는 0개 이상의 서비스(즉, 관심 있는 서비스가 없는 경우도 있음)가 메시지를 소비한다.
  - 발행/비동기 응답: 클라이언트는 요청 메시지를 발행하고 주어진 시간 동안 관련 서비스가 응답하길 기다린다.

둘째, 동기/비동기 여부이다.
- 동기: 클라이언트는 서비스가 제시간에 응답하리라 기대하고 대기 도중 블로킹할 수 있다.
- 비동기: 클라이언트가 블로킹하지 않는다. 응답은 즉시 전송되지 않아도 된다.

### 마이크로서비스 API 정의
어떤 IPC를 선택하든, 서비스 API를 IDL(Interface Definition Language)로 정확하게 정의해야 한다. 인터페이스 명세를 작성한 후 클라이언트 개발자와 함께 의논하는 과정을 몇 차례 되풀이하며 API를 정의한 후 서비스를 구현해야 한다. 이런 선 설계 후 구현 방식으로 진행하면 클라이언트 니즈에 좀 더 부합한 서비스를 구축할 수 있다.

## 동기 RPI 패턴 응용 통신
**RPI는 클라이언트가 서비스에 요청을 보내면 서비스가 처리 후 응답을 회신하는 IPC이다.** 메시징으로 통신하는 클라이언트와 달리 응답이 제때 도착하리라 가정한다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/c6e6b8fe-1745-47f8-9a0e-204087b99547)

### 동기 RPI 패턴: REST
REST는 (거의 항상) HTTP로 소통하는 IPC이다. 현재 API 개발은 REST 스타일이 대세이다.

> 📌 REST는 컴포넌트 상호 작용의 확장성, 인터페이스 일반화, 컴포넌트 독립적 배포, 상호 작용 지연을 줄이기 위해 중간 컴포넌트, 보안 강화, 레거시 시스템의 캡슐화에 역점을 둔 아키텍처 제약 조건 세트를 제공한다. - Roy Fielding

레너드 리처드슨의 REST 성숙도 모델은 고민해 볼 필요가 있다.
- 레벨 0: 클라이언트는 서비스별로 유일한 URL 끝점에 HTTP POST 요청을 하여 서비스를 호출한다. 요청을 할 때마다 어떤 액션을 수행할지, 그 대상은 무엇인지 지정한다. 필요한 매개변수도 함께 전달한다.
- 레벨 1: 서비스는 리소스 개념을 지원한다. 클라이언트는 수행할 액션과 매개변수가 지정된 POST 요청을 한다.
- 레벨 2: 서비스는 HTTP 동사를 이용해 액션을 수행하고, 요청 쿼리 매개변수 및 본문, 필요 시 매개변수를 지정한다. 덕분에 서비스는 GET 요청을 캐싱하는 등 웹 인프라를 활용할 수 있다.
- 레벨 3: 서비스를 HATEOAS(Hypertext As The Engine Of Application State) 원칙에 기반하여 설계한다. HATEOAS는 GET 요청으로 반환된 리소스 표현형에 그 리소스에 대한 액션의 링크도 함께 태워 보내자는 생각이다. 가령 클라이언트는 GET 요청으로 주문 데이터를 조회하고 이때 반환된 표현형 내부 링크를 이용해서 해당 주문을 취소할 수도 있다. HATEOAS를 사용하면 하드 코딩한 URL을 클라이언트 코드에 욱여넣지 않아도 된다.

REST 리소스는 비즈니스 객체 중심이다. 어떻게 하면 클라이언트가 요청 한 번으로 연관된 객체를 모두 가져올 수 있을지 고민하게 된다.  
이 문제를 해결하는 한 가지 방법은 클라이언트가 리소스를 획득할 때 연관된 리소스도 함께 조회하도록 API가 허락하는 것이다. 그러나 시나리오가 복잡해지면 효율이 떨어지고 구현 시간이 많이 소요되는 문제도 있다. 이런 까닭에 **데이터를 효율적으로 조회할 수 있게 설계된 GraphQL이나 넷플릭스 팔코 등 대체 API 기술이 각광받기 시작했다.**

**비즈니스 객체에 수행할 작업을 HTTP 동사에 어떻게 매핑할지도 고민거리이다.** PUT 사용 시 필수 요건인 멱등성이 보장되지 않는 업데이트도 있다.  
한 가지 해결 방법은 리소스의 특정 부위를 업데이트하는 하위 리소스를 정의하는 것이다. 동사를 URL 쿼리 매개변수로 지정하는 방법도 있지만 REST 답지 않아 gRPC 같은 REST 대체 기술이 점점 인기를 끌고 있는 추세기도 하다.

REST의 장점은 다음과 같다.
- 단순하고 익숙하다.
- Postman 같은 브라우저 플러그인이나 curl 등의 CLI 도구를 사용해서 HTTP API를 간편하게 테스트할 수 있다.
- 요청/응답 스타일의 통신을 직접 지원한다.
- HTTP는 방화벽 친화적이다.
- 중간 브로커가 필요하지 않기 때문에 시스템 아키텍처가 단순해진다.

단점은 다음과 같다.
- 요청/응답 스타일의 통신만 지원한다.
- 가용성이 떨어진다. 중간에서 메시지를 버퍼링하는 매개자 없이 클라이언트/서비스가 직접 통신하기 때문에 교환이 일어나는 동안 양쪽 다 실행 중이어야 한다.
- 서비스 인스턴스(들)의 위치(URL)을 클라이언트가 알고 있어야 한다. 요즘 애플리케이션은 서비스 디스커버리 매커니즘을 이용해서 클라이언트가 서비스 인스턴스 위치를 찾을 수 있으므로 큰 단점은 아니다.
- 요청 한 번으로 여러 리소스를 가져오기 어렵다.
- 다중 업데이트 작업을 HTTP 동사에 매핑하기 어려울 때가 많다.

### 동기 RPI 패턴: gRPC
HTTP는 한정된 동사만 지원하기 때문에 다양한 업데이트 작업을 지원하는 REST API를 설계하기가 쉽지 않다. 그래서 등장한 기술이 gRPC이다.

**gRPC는 다양한 언어로 클라이언트/서버를 작성할 수 있는 프레임워크이다.** 이진 메시지 기반의 프로토콜이므로 서비스를 API 우선 방식으로 설계할 수 밖에 없다. gRPC API는 프로토콜 버퍼 기반의 IDL로 정의하며, 프로토콜 버퍼 컴파일러로 클라이언트 쪽 스텁 및 서버 쪽 스켈레톤을 생성할 수 있다. 이 컴파일러를 이용하면 Java, C#, Node.js, Go 등 다양한 언어의 코드를 생성할 수 있다. **클라이언트/서버는 프로토콜 버퍼 포맷의 이진 메시지를 HTTP/2를 통해 교환한다.**

gRPC API는 **하나 이상의 서비스와 요청/응답 메시지 데피니션으로 구성된다.** Java Interface와 비슷한 서비스 데피니션은 정적 타입 메서드를 모아 놓은 것이다. 단순 요청/응답 RPC는 물론 스트리밍 RPC도 지원하므로 서버가 클라이언트에 메시지 스트림을 응답하는 것도 가능하다. 반대로 클라이언트가 서버로 메시지 스트림을 보낼 수도 있다.

gRPC는 **프로토콜 버퍼 메시지 포맷을 사용한다.** 이는 간결하고 효율적인 이진 포맷이다. 프로토콜 버퍼 메시지는 각 필드마다 번호가 매겨지고 타입 코드가 할당된다. 메시지 수신자는 자신이 필요한 필드만 추출하고 모르는 필드는 그냥 건너뛸 수 있기 때문에 하위 호환성을 유지하며 API를 발전시킬 수 있다.

```
service OrderService {
    rpc createOrder(CreateOrderRequest) returns (CreateOrderReply) {}
    rpc createOrder(CancelOrderRequest) returns (CancelOrderReply) {}
    rpc createOrder(ReviseOrderRequest) returns (ReviseOrderReply) {}
    // ...
}

message CreateOrderRequest {
    int64 restaurantId = 1;
    int64 consumerId = 2;
    repeated LineItem lineItems = 3;
    // ...
}

message LineItem {
    string menuItemId = 1;
    int32 quantity = 2;
}

message CreateOrderReply {
    int64 orderId = 1;
}
```

gRPC는 다음과 같은 장점이 있다.
- 다양한 업데이트 작업이 포함된 API를 설계하기 쉽다.
- 특히 큰 메시지를 교환할 때 콤팩트하고 효율적인 IPC이다.
- 양방향 스트리밍 덕분에 RPI, 메시징 두 가지 통신 방식 모두 가능하다.
- 다양한 언어로 작성된 클라이언트/서버 간 연동이 가능하다.

단점은 다음과 같다.
- JavaScript 클라이언트가 하는 일이 REST/JSON 기반 API보다 더 많다.
- 구형 방화벽은 HTTP/2를 지원하지 않는다.

gRPC는 REST를 대체할 만한 유력한 방안이지만, REST 처럼 동기 통신하는 메커니즘이라 부분 실패 문제는 풀어야 할 숙제이다.

### 부분 실패 처리: Circuit Breaker(회로 차단기) 패턴
분산 시스템은 서비스가 다른 서비스를 동기 호출할 때마다 부분 실패할 가능성이 항상 존재한다. 클라이언트/서비스는 모두 개별 프로세스로 동작하기 때문에 서비스가 클라이언트 요청에 제때 응답하지 못하거나, 유지보수 또는 기술적 오류 때문에 서비스가 내려갈 수 있다. 서비스에 과부하가 걸려 응답이 매우 늦어지는 경우도 있다.

클라이언트는 응답 대기 도중 블로킹되기 때문에 서비스 실패는 클라이언트의 클라이언트로 거슬러 올라가면서 전체 시스템의 중단을 초래할 수 있다.

**Circuit Breaker 패턴은 연속 실패 횟수가 주어진 임계치를 초과하면 일정 시간 동안 호출을 즉시 거부하는 RPI 프록시다.**

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/6c6a83ac-fa21-423f-844c-e26d5d4ecf4c)

`OrderServiceProxy`를 그냥 구현하면 응답을 기다리며 무한정 블로킹할 것이다. 스레드 같은 주요 리소스가 고갈되어 결국 API Gateway가 요청을 처리할 수 없게 된다. 그 결과 전체 API는 사용 불능 상태가 될 것이다. 따라서 부분 실패가 애플리케이션 전체에 전파되지 않도록 서비스를 설계해야 한다. 솔루션은 두 부분으로 나뉜다.
- 무응답 원격 서비스를 처리하기 위해 `OrderServiceProxy` 같은 견고한 RPI 프록시를 설계한다.
- 원격 서비스가 실패하면 어떻게 조치해야 할지 결정한다.

넷플릭스 기술 블로그를 보면 서비스가 다른 서비스를 동기 호출할 때 자기 스스로를 방어하는 방법이 명쾌하게 기술되어 있다.
- 네트워크 타임아웃: 응답 대기 중에 무한정 블로킹하면 안 되고 항상 타임아웃을 걸어 둔다. 이렇게 해야 리소스가 마냥 붙잡히지 않는다.
- 미처리 요청 개수 제한: 클라이언트가 특정 서비스에 요청 가능한 미처리 요청의 최대 개수를 설정한다. 이 개수에 이르면 더 이상의 요청은 무의미하므로 즉시 실패 처리하는 것이 타당하다.
- 회로 차단기 패턴: 성공/실패 요청 개수를 지켜보다 에러율이 주어진 임계치를 초과하면 그 이후 시도는 바로 실패 처리한다. 실패된 요청이 많다는 것은 서비스가 불능 상태고 더 이상의 요청은 무의미하단 뜻이다. 타임아웃 시간 이후 클라이언트가 재시도해서 성공하면 회로 차단기는 닫힌다.

Netflix Hystrix는 이와 같이 다양한 패턴이 구현된 오픈 소스 라이브러리다.

히스트릭스 같은 라이브러리는 부분적인 솔루션에 불과하다. **무응답 원격 서비스를 어떻게 복구하면 좋을지는 그때그대 상황에 맞게 판단해야 한다.** 그냥 알기 쉽게 서비스가 클라이언트에 에러를 반환하는 것이 나을 때가 있다. 부분 실패 시 미리 정해진 기본값이나 캐시된 응답 등 대체 값을 반환하는 방법도 있다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/5385fd42-6471-4407-b223-85626685865a)

모든 서비스의 데이터가 클라이언트에 똑같이 중요하진 않다. 위 그림에선 주문 서비스 데이터가 가장 중요하다. 서비스가 불능 상태가 되어도 다른 서비스 데이터는 상대적으로 덜 중요하기 때문에 API Gateway는 캐시된 버전의 데이터 또는 에러를 반환한다.

부분 실패를 처리하도록 서비스를 설계하는 것 외에도 RPI 사용 시 해결해야 할 이슈는 많다. **어떤 서비스가 다른 서비스를 RPI로 호출할 때 해당 서비스 인스턴스의 네트워크 위치를 알고 있어야 하는 것도 문제다.** 별거 아닌 것 같지만 실제로는 꽤 골치 아픈 문제다.

### 서비스 디스커버리
요즘 클라우드 기반의 마이크로서비스 애플리케이션은 네트워크 위치가 훨씬 동적이라 이를 식별하는 일이 결코 간단하지 않다.

서비스 인스턴스마다 네트워크 위치가 동적 배정되고, 서비스 인스턴스는 자동 확장, 실패, 업그레이드 등 여러 가지 사유로 계속 달라지므로 클라이언트 코드는 서비스 디스커버리를 사용할 수 밖에 없다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/c70839a0-b63d-4a5f-a62b-b5ccdf1ee304)

서비스 IP 주소가 정적으로 구성된 클라이언트 대신 서비스 디스커버리 매커니즘을 사용해야 한다. 핵심은 **애플리케이션 서비스 인스턴스의 네트워크 위치를 DB화 한 서비스 레지스트리(service registry)이다.**

애플리케이션 수준의 서비스 디스커버리 패턴을 적용하는 방법을 먼저 살펴보자.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/95254b19-8a34-4504-b912-db054bb02f67)

애플리케이션 클라이언트/서비스가 서비스 레지스트리와 직접 통신하는 방법이다. 서비스 인스턴스는 자신의 네트워크 위치를 서비스 레지스트리에 등록하고, 서비스 클라이언트는 이 서비스 레지스트리로부터 전체 서비스 인스턴스 목록을 가져와 그중 한 인스턴스로 요청을 라우팅한다.

- 자가 등록 패턴: 서비스 인스턴스는 자신의 네트워크 위치를 서비스 레지스트리 등록 API를 호출해 등록한다. 헬스 체크 URL을 제공하는 서비스도 있고, 주기적으로 하트비트 API를 호출해야 하는 서비스 레지스트리도 있다.
- 클라이언트 쪽 디스커버리 패턴: 클라이언트는 서비스를 호출할 때 먼저 서비스 레지스트리에 서비스 인스턴스 목록을 요청해서 넘겨받는다. 그런 다음 서비스 클라이언트는 라운드-로빈이나 랜덤 같은 부하 분산 알고리즘을 이용하여 서비스 인스턴스를 선택한 후 요청을 전송한다. 대표적인 예시로 Eureka가 있다.

다음은 플랫폼에 내장된 서비스 디스커버리 패턴을 적용 방법이다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/f94ecf6c-a17c-49c5-be3b-042c5e423b0d)

Docker나 k8s 등 최신 배포 플랫폼에는 대부분 서비스 레지스트리, 서비스 디스커버리 매커니즘이 탑재되어 있다. 배포 플랫폼은 DNS명, 가상 IP 주소, VIP 주소로 해석되는 DNS명을 각 서비스마다 부여한다. 서비스 클라이언트가 DNS명/VIP를 요청하면 배포 플랫폼이 알아서 가용 서비스 인스턴스 중 하나로 요청을 라우팅한다. 배포 플랫폼이 서비스 등록, 서비스 디스커버리, 요청 라우팅을 모두 관장하는 것이다.

- 서드파티 등록 패턴: 서비스가 자신을 서비스 레지스트리에 등록하는 것이 아닌 배포 플랫폼의 일부인 등록기라는 서드파티가 이 작업을 대행한다.
- 서버 쪽 디스커버리 패턴: 클라이언트가 서비스 레지스트리를 질의하지 않고 DNS명을 요청한다. 그러면 서비스 레지스트리를 쿼리하고 요청을 부하 분산하는 요청 라우터로 해석된다.

## 비동기 메시징 패턴 응용 통신
**메시징은 서비스가 메시지를 서로 비동기적으로 주고받는 통신 방식이다.** 보통 서비스간 중개 역할을 하는 메시지 브로커를 사용하지만 서비스가 직접 서로 통신하는 브로커리스 아키텍처도 있다. 클라이언트가 서비스에 메시지를 보내 요청을 하면, 요청을 받은 서비스 인스턴스가 응답 가능할 경우 별도의 메시지를 클라이언트에 응답한다.  
**비동기 통신을 하기 때문에 클라이언트가 응답을 기다리며 블로킹하지 않는다.**

메시지는 헤더와 본문으로 구성된다.

- 헤더: 송신된 데이터에 관한 메타데이터에 해당하는 키/값들로 구성됨. 송신자 또는 메시징 인프라에서 생성된 메시지 ID, 응답이 출력될 메시지 채널을 가리키는 반환 주소(옵션) 또한 헤더에 있다.
- 바디: 실제 송신할 텍스트 또는 이진 포맷의 데이터.

메시지는 채널을 통해 교환된다.  
채널은 두 종류가 있다.

- point-to-point 채널: 채널을 읽는 컨슈머 중 딱 하나만 지정하여 메시지를 전달한다.
- publish-subscribe 채널: 같은 채널을 바라보는 모든 컨슈머에 메시지를 전달한다.

### 요청/응답 및 비동기 요청/응답
클라이언트/서비스는 한 쌍의 메시지를 주고받는 비동기 요청/응답 스타일로 상호 작용한다. 클라이언트는 수행할 작업과 매개변수가 담긴 커맨드 메시지를 서비스가 소유한 점대점 메시징 채널에 보낸다. 그러면 서비스는 요청을 처리한 후 그 결과가 담긴 응답 메시지를 클라이언트가 소유한 점대점 채널로 돌려보낸다.

![](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/c230c5e3-eb5c-48e1-888c-5bde60b94ccf)

클라이언트는 서비스가 어디로 응답 메시지를 보내야 하는지 알려 주고 이렇게 받은 응답 메시지는 요청과 짝이 맞아야 한다.

클라이언트는 `MessageId` 및 응답 채널이 헤더에 명시된 커맨드 메시지를 보내고, 서버는 `MessageId`와 같이 동일한 `CorrelationId`가 포함된 응답 메시지를 지정된 응답 채널에 쓰면 된다.

- 단방향 알림: 비동기 메시징을 이용하여 직관적으로 구현 가능. 서비스가 소유한 점대점 채널로 클라이언트가 메시지를 보내면, 서비스는 이 채널을 구독해서 메시지를 처리하는 구조. 단방향이므로 서비스는 응답을 반환하지 않는다.
- 발행/구독: 클라이언트는 여러 컨슈머가 읽는 발행/구독 채널에 메시지를 발행하고, 서비스는 도메인 객체의 변경 사실을 알리는 도메인 이벤트를 발행한다. 도메인 이벤트를 발행한 서비스는 해당 도메인 클래스의 이름을 딴 발행/구독 채널을 소유한다. 서비스는 자신이 관심 있는 도메인 객체의 이벤트 채널을 구독한다.
- 발행/비동기 응답: 발행/구독과 요청/응답의 엘리먼트를 조합한 고수준의 상호 작용 스타일.

### 메시징 기반 서비스의 API 명세 작성
서비스의 비동기 API 명세에는 메시지 채널명, 각 채널을 통해 교환되는 메시지 타입과 포맷을 명시하고, 메시지 포맷은 JSON, XML, 프로토콜 버퍼 등 표준 포맷으로 기술해야 한다. REST, Open API완 달리 채널 및 메시지 타입은 정해진 문서화 표준이 없기에 자유롭게 기술하면 된다.

- 요청/비동기 응답 스타일 API: 서비스의 커맨드 메시지 채널, 서비스가 받는 커맨드 메시지의 타입과 포맷, 서비스가 반환하는 응답 메시지 타입과 포맷으로 구성
- 단방향 알림 스타일 API: 서비스의 커맨드 메시지 채널, 서비스가 받는 커맨드 메시지의 타입과 포맷으로 구성

### 메시지 브로커
메시징 기반의 애플리케이션은 대부분 메시지 브로커를 사용한다. 메시지 브로커는 서비스가 서로 통신할 수 있게 해주는 인프라 서비스다.

먼저, 브로커리스 아키텍처의 서비스는 메시지를 서로 직접 교환한다.
- 송신자가 보낸 메시지가 브로커를 거쳐 수신자로 이동하는 것이 아니라, 송신자에서 수신자로 직접 전달되므로 네트워크 트래픽이 가볍고 지연 시간이 짧다.
- 메시지 브로커가 성능 병목점이나 SPOF가 될 일이 없다.
- 메시지 브로커를 설정/관리할 필요가 없으므로 운영 복잡도가 낮다.
- 서비스가 서로의 위치를 알고 있어야 하므로 서비스 디스커버리 매커니즘 중 하나를 사용해야 한다.
- 메시지 교환 시 송신자/수신자 모두 실행 중이어야 하므로 가용성이 떨어진다.
- 전달 보장 같은 매커니즘을 구현하기가 더 어렵다.

메시지 브로커는 모든 메시지가 지나가는 중간 지점이다. 메시지 브로커의 가장 큰 장점은 **송신자가 컨슈머의 네트워크 위치를 몰라도 된다는 것이다.** 또 컨슈머가 메시지를 처리할 수 있을 때까지 메시지 브로커에 메시지를 버퍼링할 수도 있다.

- ActiveMQ
- RabbitMQ
- Apache Kafka
- AWS Kinesis
- AWS SQS

메시지 브로커를 선택할 때는 다음 항목을 잘 검토해야 한다.

- 프로그래밍 언어 지원 여부
- 메시징 표준 지원 여부: AMQP나 STOMP 등 표준 프로토콜을 지원하는 제품인지 자체 표준만 지원하는 제품인가?
- 메시지 순서: 유지 되는지?
- 전달 보장
- 영속화
- 내구성
- 확장성
- 지연 시간
- 경쟁사 컨슈머: 경쟁사 컨슈머를 지원하는가?

브로커 기반 메시징의 장단점은 다음과 같다.

- 느슨한 결합
- 메시지 버퍼링
- 유연한 통신
- 명시적 IPC
- 성능 병목 가능성
- 단일 장애점 가능성
- 운영 복잡도 부가

### 수신자 경합과 메시지 순서 유지
메시지 순서를 유지한 채 메시지 수신자를 scale-out 할 수 있을까? 일반적으로 메시지를 동시 처리하려면 서비스 인스턴스를 여럿 두어야 한다. 메시지를 동시 처리하면 각 메시지를 정확히 한 번만 순서대로 처리해야 한다.

갖가지 네트워크 이슈나 가비지 컬렉션 문제로 지연이 발생하고 메시지 처리 순서가 어긋나면 시스템이 오작동할 수 있다.

그래서 Apache Kafka, AWS Kinesis 등 요즘 메시지 브로커는 샤딩된(or 파티셔닝된) 채널을 이용한다.

1. 샤딩된 채널은 복수의 샤드로 구성되며, 각 샤드는 채널처럼 작동한다.
2. 송신자는 메시지 헤더에 샤드 키(보통 무작위 문자열 또는 바이트)를 지정한다. 메시지 브로커는 메시지를 샤드 키별로 샤드/파티션에 배정한다. 예를 들어 샤드 키 해시 값을 샤드 개수로 나눈 나머지를 계산해서 샤드를 선택하는 식이다.
3. 메시징 브로커는 여러 수신자 인스턴스를 묶어 마치 동일한 논리 수신자처럼 취급한다. (kafka consumer group) 메시지 브로커는 각 샤드를 하나의 수신자에 배정하고, 수신자가 시동/종료하면 샤드를 재배정한다.

![](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/03280a38-eeda-4a57-b5db-e5ceeaf3eab0)

### 중복 메시지 처리
메시지 브로커가 각 메시지를 꼭 한 번만 전달하면 좋겠지만, 이는 값비싼 대가를 치러야 한다. 메시지 브로커는 보통 적어도 한 번 이상 메시지를 전달하겠노라 약속한다.

- 멱등한 메시지 핸들러를 작성한다.
- 메시지를 추적하고 중복을 솎아 낸다.

![](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/4e39ccad-b7ed-4e4e-9cae-f8c1c48bea66)

### 트랜잭셔널 메시징
서비스는 보통 DB를 업데이트하는 트랜잭션의 일부로 메시지를 발행한다. DB 업데이트와 메시지 전송을 한 트랜잭션으로 묶지 않으면, DB 업데이트 후 메시지는 아직 전송되지 않은 상태에서 서비스가 중단될 수 있기 때문에 문제가 된다. 이 두 작업이 서비스에서 원자적으로 수행되지 않으면 시스템이 실패할 경우 아주 불안정한 상태가 될 것이다.

과거에는 DB와 메시지 브로커에 분산 트랜잭션을 적용했지만, 요즘은 분산 트랜잭션이 어울리지 않고 대부분 지원하지 않는다.

이를 해결하기 위한 방법으로, 먼저 DB 테이블을 메시지 큐로 활용하는 방식이 있다.

![](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/df8dbaa8-bf5c-42bb-a683-c50557055ab9)

RDBMS 기반의 애플리케이션이라면 DB 테이블을 임시 메시지 큐로 사용하는 트랜잭셔널 아웃 박스 패턴이 가장 알기 쉬운 방법이다. 메시지를 보내는 서비스에 `OUTBOX`라는 DB 테이블을 만들고 비즈니스 객체를 생성, 수정, 삭제하는 DB 트랜잭션의 일부로 해당 테이블에 메시지를 삽입한다. 로컬 ACID 트랜잭션이기 때문에 원자성은 자동 보장된다.

NoSQL DB도 비슷하다. DB 레코드로 적재된 비즈니스 엔터티에 발행할 메시지 목록을 가리키는 속성이 있는데, 서비스가 DB 엔터티를 업데이트할 때 이 목록에 메시지를 덧붙이면 된다.

다음은 이벤트를 발행 시 폴링 발행기 패턴을 활용하는 방법이다.  
메시지 릴레이로 테이블을 폴링해서 미발행 메시지를 조회하는 것이다.

```sql
SELECT * FROM OUTBOX ORDERED BY ... ASC;
```
위와 같은 쿼리를 주기적으로 실행하면 된다. 메시지 릴레이는 이렇게 조회한 메시지를 하나씩 각자의 목적지 채널로 보내 메시지 브로커에 발행한 뒤 나중에 `OUTBOX` 테이블에서 메시지를 삭제한다. 이는 규모가 작은 경우 쓸 수 있는 방법이다. DB를 자주 폴링하면 비용이 유발하고 NoSQL은 쿼리 능력에 따라 사용 가능 여부가 결정된다.

다음은 이벤트 발행 시 트랜잭션 로그 테일링 패턴을 활용하는 방법이다.  
메시지 릴레이로 DB 트랜잭션 로그(커밋 로그)를 테일링 하는 방법이다. 애플리케이션에서 커밋된 업데이트는 각 DB의 트랜잭션 로그 항목(log entry)으로 남는다. **트랜잭션 로그 마이너로 트랜잭션 로그를 읽어 변경분을 하나씩 메시지로 브로커에 발행하는 것이다.**

![](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/eeee2e3f-a251-4fab-be94-d0c33610a289)

트랜잭션 로그 마이너는 트랜잭션 로그 항목을 읽고, 삽입된 메시지에 대응되는 각 로그 항목을 메시지로 전환하여 메시지 브로커에 발행한다. RDBMS의 `OUTBOX` 테이블에 출력된 메시지 또는 NoSQL DB에 레코드로 추가된 메시지를 이런 식으로 발행할 수 있다.

## 비동기 메시징으로 가용성 개선
먼저 동기 통신의 문제를 짚어보자.

REST는 호출한 서비스가 응답할 때까지 HTTP 클라이언트가 마냥 기다려야 한다. 따라서 서비스가 동기 프로토콜로 통신하면 그만큼 애플리케이션 가용성은 저하될 수밖에 없다. 어느 한 서비스라도 내려가면 전체 로직 처리가 불가능하다. REST 통신만 그런 것이 아니다. 어떤 서비스가 다른 서비스의 응답을 받은 이후 자신의 클라이언트에 응답하는 구조라면 가용성은 떨어진다. 비동기 메시징을 통해 요청/응답하는 방식도 이는 마찬가지다.

### 동기 상호 작용 제거
동기 요청을 하지 않아도 동기 요청을 처리할 수 있는 방법이 있다.

모든 트랜잭션은 비동기 상호 작용 스타일로 처리하는 것이 가장 좋다. 예를 들어 클라이언트가 비동기 요청/응답 상호 작용을 통해 주문을 생성했다하자. 클라이언트는 요청 메시지를 주문 서비스에 전송하여 주문을 생성한다. 그러면 주문 서비스는 다른 서비스와 메시지를 비동기 방식으로 교환하고, 최종적으로 클라이언트에 메시지를 전송한다.

![](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/9d3dc7f7-0004-4f52-bc74-6c5d5ece76ee)

클라이언트/서비스는 메시징 채널을 통해 메시지를 전송해서 서로 비동기 통신한다. 이런 상호 작용 과정에서는 어느 쪽도 응답을 대기하며 블로킹되지 않는다. 이런 아키텍처는 메시지가 소비되는 시점까지 메시지 브로커가 메시지를 버퍼링하기 때문에 매우 탄력적이다.

다음은 서비스 요청 처리에 필요한 데이터의 레플리카를 유지하는 방법이다.  
데이터 레플리카는 데이터를 소유한 서비스가 발행하는 이벤트를 구독해서 최신 데이터를 유지할 수 있다. 소비자/음식점 서비스가 소유한 데이터 레플리카를 주문 서비스가 이미 갖고 있다면 주문 서비스가 주문 생성을 요청할 때 굳이 소비자/음식점 서비스와 상호 작용할 필요가 없다.

소비자/음식점 서비스는 각자 데이터가 변경될 때마다 이벤트를 발행하고, 주문 서비스는 이 이벤트를 구독하여 자기 편 레플리카를 업데이트하는 것이다.

![](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/8483d053-189a-4c42-a2de-44916c329ffa)

물론 대용량 데이터의 레플리카를 만드는 것은 대단히 비효율적이다. 다른 서비스가 소유한 데이터를 업데이트 하는 문제도 데이터 복제만으로는 해결되지 않는다. 한 가지 해결 방법은 자신의 클라이언트에 응답하기 전까지 다른 서비스와의 상호 작용을 지연시키는 것이다. MSA에선 SAGA를 이용해서 서비스를 느슨하게 결합한다.

![image](https://github.com/alanhakhyeonsong/LetsReadBooks/assets/60968342/5ed39b40-38e1-4b25-acab-e20e6c53d868)

위와 같은 방식으로 서비스를 구현한다면 주문을 PENDING 상태로 생성하고, 다른 서비스와 메시지를 교환하며 주문을 비동기 검증한다. 주문 서비스는 어떤 순서로든 `ConsumerValidated`, `OrderDetailsValidated` 메시지를 받을 수 있다. 자신이 최초로 수신한 메시지에 따라 주문 상태를 변경한다. 주문 검증을 마친 후 나머지 주문 생성 프로세스를 완료한다. 이렇게 처리하면 혹시라도 소비자 서비스가 내려가는 사고가 발생하더라도 주문 서비스는 계속 주문을 생성하고 클라이언트에 응답할 수 있다. 나중에 소비자 서비스가 재가동하면 큐에 쌓인 메시지를 처리해서 밀린 주문을 다시 검증하면 된다.

이런 구조는 클라이언트 코드가 조금 복잡한 편이다. 클라이언트 입장에서 주문 생성 성공 여부를 알아내려면 주기적으로 폴링하거나 주문 서비스가 알림 메시지를 보내 주어야 한다.