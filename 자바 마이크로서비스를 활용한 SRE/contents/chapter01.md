# Chapter 1. 애플리케이션 플랫폼
마이크로서비스를 도입하면 애플리케이션은 여러 컴포넌트로 분리되며 각기 다른 팀이 독립적으로 개발하고 배포한다. 개발 속도는 빨라지지만 대규모 릴리스 일정을 수립하고 조율할 필요성은 감소하게 된다. 각 팀은 서로 독립적이며 자신의 고객에게 필요한 비즈니스 요건에 대응한다. 마이크로서비스는 각기 다른 클라우드 리소스에 수평적으로 조절된 규모로 다중 배포되며 네트워크 상의 다양한 프로토콜을 이용해 서로 통신한다.

이런 아키텍처는 기존의 모놀리식 애플리케이션에서 볼 수 없었던 많은 도전 과제를 수반한다.
- 모놀리식 → 주로 일정한 서버를 두고 배포되며 신중한 계획에 따라 드물게 릴리스된다. 소프트웨어 릴리스 과정은 시스템의 변화와 불안정을 유발하는 주된 요인이다.
- 마이크로서비스는 데이터 전송과 통신량으로 추가 비용과 레이턴시가 발생하며 잠재적으로 사용자 경험을 저하시킨다.
- 분산된 시스템을 관리하려면 새로운 관행, 도구, 엔지니어링 문화가 필요하다.
  - 릴리스 속도를 향상시키는 대가로 소프트웨어의 안정성을 포기할 필요는 없다.

## 플랫폼 엔지니어링 문화
- 마이크로서비스를 관리하려면 조직 내부에서 사용할 통신 규약과 지원 프레임워크를 선정하고 표준화시켜야 한다. 팀마다 자체적으로 관리하는 방식은 매우 비효율적이다.
- 보통은 플랫폼팀이 구성되어 표준화를 담당하며 그 외 팀은 각자의 비즈니스 요구 사항을 개발하는 데 집중한다.
  - 각 팀이 저마다 찾아낸 길을 가도록 둔다. 그런 다음 각 팀의 방식을 배우고 조직 전체에 일반화시킨다.

![Image](https://github.com/user-attachments/assets/8d70712b-8050-46d1-a4c6-0a863710ed8c)

- 전문성을 기준으로 구성된 엔지니어링 조직들을 나타낸다.
  - 인터페이스 및 사용자 경험 설계
  - 백엔드 서비스 구축
  - 데이터베이스 관리
  - 네트워크 자원 관리

![Image](https://github.com/user-attachments/assets/da638033-dbc4-4e13-b685-c0d85c9ba8b0)

- 한 팀 안에서 여러 기능을 감당하도록 구성된 교차 기능 팀에 해당한다.
- 이런 조직의 작업 주기가 더 빠른 이유는 팀마다 기술적 전문 분야가 다르면 새로운 비즈니스 요구 사항이 생길 때마다 결국 모든 분야를 다시 조율해야 하기 때문이다.

하지만 이런 시스템은 낭비다. 특히 각 팀의 전문가가 서로 독립적으로 같은 분야를 개발한다는 점에서 더욱 그렇다. 교차 기능팀과 전문석으로 격리된 팀은 스펙트럼의 양극단과 같다. 플랫폼 엔지니어링을 효과적으로 발휘하면 팀마다 특정 분야의 전문가를 보유해야 할 필요성이 줄어든다.

![Image](https://github.com/user-attachments/assets/46185b83-acc4-42c3-90d8-ba3c6486aba5)

- 위 그림은 플랫폼 엔지니어링을 도입한 조직으로, 양극단의 혼합적인 형태를 띤다.
- 중앙에 위치한 플랫폼 엔지니어링팀은 프로덕션팀을 고객처럼 여길 때 가장 강력한 위력을 발휘한다.

모니터링 도구를 전사적으로 도입하는 경우의 예시
- 각 마이크로서비스에 모니터링 기능을 공통 라이브러리로 탑재시키고, 기존에 정립된 보편적 가용성 척도를 공유한다.
- 각 프로덕션팀은 약간의 시간을 들여 자신의 비즈니스 영역에 해당하는 고유한 가용성 척도를 추가한다.
- 필요에 따라 중앙 관제팀과 정보를 공유하거나 효과적인 신호 수립에 대해 조언을 하기도 한다.

플랫폼 엔지니어가 빌드 도구처럼 전문적인 기술 영역에 초점을 맞춰 프로덕션팀의 다양한 관심사에 대응할 때 비로소 패턴의 모습을 드러낸다.
- 특정 스크립트가 반복적으로 실행되는 현상 → 바이너리 종속성 문제, 플러그인 버전 충돌, 릴리스 워크플로 결함 등의 원인  
→ 빌드 중단이 아닌 **빌드 결과에 자동으로 경고 문구 출력** → 중단이라면 문제 해결은 프로덕션팀의 몫이 된다.
- 결국, 자유와 책임 문화에 기반한 결정.
  - 프로덕션팀의 시각에 맞춰 문제를 바라봐야 한다.
  - 자동 수정 도구를 만들고 모니터링을 진행하며 팀이 처한 문제를 이해하고 소통한다.

유능한 플랫폼 엔지니어링팀은 프로덕션팀이 오로지 고객 경험에 열중하는 것 이상으로 개발자 경험에 깊은 관심을 기울인다. 잘 조율된 플랫폼 엔지니어링 조직에 있어 개발자는 곧 **고객**이다.

## 모니터링
애플리케이션 인프라 모니터링은 시스템의 복원성을 높이는 여러 단계 중 조직 차원의 협조가 가장 덜 필요한 작업이다. 프레임워크 수준 모니터링은 이미 기술적으로 매우 성숙해서 스위치만 올리면 바로 시작할 수 있는 정도다. 비용 대 편익으로 분석하자면 편익 쪽에 상당히 치우쳐있다. **애플리케이션 모니터링은 지금 바로 시작하자.**

### 가용성 모니터링
가용성 신호는 시스템의 전반적인 상태와 정상 작동 여부를 거시적 관점에서 측정하며, **서비스 수준 척도(SLI)** 로 정량화한다.
- 시스템 소비 자원, 물품 판매량, 초당 비디오 스트리밍 용량 등 시스템의 상태 신호 또는 비즈니스 메트릭이 가용성 신호에 포함된다.
- SLI는 **서비스 수준 목표(SLO)** 라 불리는 임계 기준을 달성해야 하며 SLO는 SLI의 상한과 하한 범위를 지정한다.
- SLO는 사업적으로 합의한 수준 또는 **서비스 수준 협약(SLA)** 에 명시된 제공 수준보다 제한적이거나 보수적인 추정치다.
- SLA를 위반할 위험이 생겼을 때 사전 경고를 일정량 제공하고 실제로 SLA를 위반하는 상태에 이르지 않도록 방지하는 것이 핵심이다.

메트릭은 가용성을 측정하는 주요 관찰 수단이며 SLI를 측정하는 지표다. 가장 보편적인 가용성 신호며 전수 데이터를 사용해도 될 정도로 값싼 자원이다.

**메트릭**
- 처리량과 무관하게 고정된 비용을 나타내야 한다.
- 특정 코드 블록의 실행 횟수를 세는 메트릭은 코드를 아무리 많이 실행해도 빠짐없이 횟수를 세야 한다.
- 측정 기간 동안 '고유한 요청이 N번 발생'이 아니라 '요청이 N번 발생'이라는 결과를 나타내야 한다.

**메트릭 데이터**
- 특정 요청의 성능이나 기능을 추정하는 데 쓸 수 없다.
- 메트릭 텔레메트리는 일정 기간 동안 애플리케이션이 요청들을 처리하면서 보인 전반적 행동을 측정하고, 이를 바탕으로 개별 요청의 처리 결과를 추론한다.

**레이턴시**
- 코드 블록을 실행하는 동안 소요된 시간을 나타낸다.
- 일반적으로 REST 기반 마이크로서비스는 애플리케이션 가용성을 측정할 때 REST 엔드포인트 레이턴시를 확인한다.

**사용률**
- 유한 자원이 소비되는 정도를 나타내며, 대표적으로 프로세서 사용률이 있다.

**포화도**
- 미처리 작업이 얼마만큼 남아있는지를 나타낸다.
  - eg) Java Heap 측정
- 메모리에 과도한 부담이 생겨 대기 작업이 쌓일 때 측정한다.
- DB 커넥션 풀, 요청 풀 등도 일반적인 포화도 모니터링 대상이다.

**에러**
- 순수하게 성능을 나타내는 정보 외에, 전체 처리량 대비 오류 발생률을 정량화한 값도 중요하다.
- 예상치 못한 예외가 발생하면 서비스 말단의 HTTP 응답 실패로 이어진다. → 예외 상황은 에러 지표에 해당한다.
- 요청 수 대비 서킷 브레이커 발동 비율도 간접적인 에러 지표로 볼 수 있다.

사용률과 포화도는 엄연히 다른 신호다. 두 가지 방식으로 모두 측정할 수 있는 자원이 있다. JVM 메모리가 그 예시다.
- 메모리 공간을 차지한 전체 바이트를 측정하면 사용률 메트릭을 구할 수 있음.
- 전체 시간 대비 가비지 수집 시간 비율을 측정하면 포화도 메트릭을 얻을 수 있음.
- 사용률과 포화도 모두 측정할 수 있을 경우 대부분 더 정확한 경고 구간을 설정할 수 있다.
  - 메모리 사용률이 95%가 넘었다는 경보는 잘 발생하지 않는데, 이 값을 넘지 않게끔 가비지 컬렉터가 역할을 수행하기 때문.
  - 메모리 사용률이 빈번하게 95%에 가까워지면 가비지 컬렉터가 실행되는 시간도 다른 작업에 비해 증가해 포화도가 상승한다.

일반적인 가용성 신호의 예시는 아래와 같다.

|SLI|SLO|L-USE 구분|
|--|--|--|
|CPU 사용률|80% 미만|포화도|
|힙 사용률|힙 영역 가용도 80% 미만|포화도|
|REST 엔드포인트 에러율|전체 엔드포인트 요청 대비 1% 미만|에러|
|REST 엔드포인트 최대 레이턴시|100ms 미만|레이턴시|

**구글의 SLO 활용 방식**
- 새로운 기능 개발과 기존 기능의 안정성, 두 목표는 서로 경쟁 관계를 형성한다.
- 프로덕션팀과 SRE 담당 엔지니어는 서비스의 신뢰성 저하를 얼마나 허용할지 규정한 에러 예산에 합의한다.
- 신뢰성 저하는 기준 시간 동안 측정 가능한 목표로 나타내며 목표치를 초과하면 신뢰성이 다시 확보될 때까지 기능 개발보다 시스템 안정성 확보에 주력한다.
- 기본적으로 구글 엔지니어는 항상 에러 예산 고갈 경보에 대응하고 필요하다면 개발에 투입된 업무 자원을 신뢰성 확보 쪽으로 전환하는 조직적 대응도 감수해야 한다.
  - 이때, 에러는 SLO가 초과되었음을 의미한다.
- 에러 예산 개념을 실제로 활용하기 위해 프로덕트 엔지니어와 SRE 엔지니어를 반드시 기능적으로 분리할 필요는 없다. 프로덕트만 전적으로 담당하는 엔지니어라도 기능 개발을 잠시 멈추고 사이트 신뢰성 향상을 고민한다면 소기의 목적을 달성할 수 있다. 반대도 마찬가지다.
- 애플리케이션 메트릭 수집, 시각화, 경보는 서비스 가용성을 지속적으로 테스트하는 과정의 일부다. 가끔 경보 데이터의 맥락 속에 숨은 단서만으로 문제를 충분히 해결할 수 있다.
  - 그렇지 않은 경우엔 장애 인스턴스를 LB에서 제외해 격리시키고 더 자세한 디버깅 정보를 얻어야 한다. (이런 상황에 쓰이는 텔레메트리 기법들이 있음)

### 디버깅 도구 역할
- 로그 및 분산 추적은 주로 장애 지속 기간을 인지한 뒤 문제 해결을 위해 사용한다.
- 모든 성능 관리 역량을 디버깅 도구 위주로 집중하는 조직은 매우 흔하다. 특히 복잡한 시장을 상대하는 조직은 더욱 그렇다.
- APM의 핵심 기능도 결국 디버깅이다. 디버깅 신호를 취합하여 추적 정보, 로깅, 가용성 신호를 제공한다.
  - Java 코드에서 연산, 메모리 부하가 일어나는 지점 식별
  - 시스템의 세부 사항을 다양한 방식으로 기록하고 세분화하는데, 신호의 샘플링 비율을 낮추는 방식으로 비용을 줄일 수 있고 필요할 때까지 신호 측정을 아예 끄기도 한다.
- 정확도와 비용 사이에서 타협점을 찾아야 하는데 어느 한 쪽을 완전히 최적화시킬 수 없다.
  - 추적 데이터를 모두 사용하지 않고 샘플링하기 때문. 추적 데이터는 메트릭에 비해 더 많은 공간을 점유한다.

### 실패 예측과 수용
- 시스템이 완벽해질 수 없다는 현실을 인식하면 시스템을 바라보는 관점이 바뀐다.
  - 모니터링, 경보, 신속한 문제 처리로 옮겨가는데 공정 관리의 목표는 결과의 완벽함이 아니라 변화에 효과적으로 대응하는 것이다.
- 전달과 릴리스 절차를 본격적으로 발전시키려면 소프트웨어의 복원력을 확보해야 하는데 현재 릴리스된 애플리케이션을 모니터링하는 것이 첫 단계다.
- MSA를 도입할 수록 모니터링의 중요성은 한층 높아진다.
  - 레이턴시와 에러는 네트워크 계층, 인프라, 서드 파티 컴포넌트와 서비스 등 여러 요인의 장애에 의해 발생한다.
  - 마이크로서비스를 담당하는 각 팀은 자신이 직접적으로 통제하지 않는 시스템의 다른 부분에 잠재적으로 부정적인 영향을 미칠 가능성이 있다.
- 소프트웨어의 최종 사용자 또한 완벽한 서비스를 기대하기보다 원활한 문제 해결을 더 선호하는 경향이 있다.

## 전달
- 소프트웨어 전달(delivery) 파이프라인을 개선하면 전달 프로세스가 기존 시스템에 장애를 일으킬 가능성을 줄일 수 있다.
- 문제가 발생하더라도 변경 사항을 빠르게 롤백하는 데 도움이 된다.
- 모니터링은 전달 과정을 안전하고 효율적으로 개선하는 과정에 일조하는 것으로 알려졌다.

지속적 통합과 지속적 전달(CD) 사이의 경계는 종종 흐릿해진다. 팀 자체 제작한 배포 자동화 스크립트를 지속적 통합 빌드 과정에서 직접 실행하기 때문이다. 또한 CI 시스템은 본래 용도보다 유연하게, 더 일반적인 업무를 자동화하는 도구로 쓰이곤 한다.

지속적 통합은 마이크로서비스 산출물을 저장소에 게시하는 시점에 종료되며, 전달은 바로 그 시점부터 시작된다.

![Image](https://github.com/user-attachments/assets/186cfaff-796e-44e4-a118-c2a24533c0cf)

- 각 단계는 실행 빈도가 서로 다르며 조직이 원하는 제어 수준도 다르다.
- 근본적으로 각기 다른 목표를 지향하는데, CI는 개발자 피드백 강화, 테스트 자동화를 통한 신속한 검증, 무분별한 통합 방지를 위한 적극적 병합 장려 등이다.
- CD 자동화의 목표는 릴리스 주기 단축, 보안 규정 준수, 안전하고 유연한 배포 관행 확립 등이다.

우수한 전달 플랫폼은 현재 배포된 자산의 인벤토리 역할을 하며 모니터링의 효과를 한층 높이는 원동력이 된다.

> 지속적 배포는 지속적 전달의 필요조건이 아니다.  
> 
> 진정한 지속적 배포는 모든 커밋을 전방위적으로 검사하고 자동으로 프로덕션에 반영해야 한다. 모든 조직이 이 정도 수준을 목표로 잡을 필요는 없다. 오히려 피드백 주기를 단축할 수록 비용이 더 든다.

## 트래픽 관리
- 분산 시스템의 복원력은 대부분 장애 예측과 보상을 기반으로 발휘된다.
- 가용성 모니터링은 장애가 실제로 발생하는 지점을 드러내고, 디버그 가능성 모니터링은 장애를 이해하는 데 도움을 주며, 전달 자동화는 증분 릴리스에 발생하는 장애를 억제한다.
- 이와 달리, 트래픽 관리 패턴은 상존하는 장애에 대처하는 기술이다.
  - 가동 중인 인스턴스가 실시간으로 트래픽에 대항할 수 있도록 돕는다.
  - 로드 밸런싱과 호출 복원력 패턴 등의 전략.

## 다루지 않는 주제
- 테스트 자동화
  - 프로덕션 환경은 테스트 환경과 현실적으로 다르고, 테스트 커버리지 100%와 진화된 모니터링 시스템 중 양자택일을 강요한다면 후자라고 한다.
  - 테스트가 덜 중요한 건 아니고 커버리지 100%는 허상에 불과하다.
  - 잘 정의되고 변화가 거의 없는 비즈니스조차 달성하기 어렵다.
- 카오스 엔지니어링과 지속적 검증
  - 분산 시스템에 발생하는 모든 상호작용을 사전에 예측하기란 불가능하다.
  - 카오스 실험은 복잡한 시스템에 새롭게 등장하는 특성들을 표면화시키는 데 도움을 준다.
- 코드형 설정
  - 12 factor 앱 방법론에 따르면 코드와 설정은 분리되어야 한다. 설정값을 환경 변수로 저장하면 이 개념을 기본적으로 구현했다 볼 수 있다.
  - eg) Spring Cloud Config Server
  - 설정이 동적으로 바뀌는 시스템은 상황이 더 복잡하다. 중앙 설정 서버의 변경이 필요할 땐 극도로 주의해야 한다.
  - 선언형 전달은 완전히 형태가 다른 코드형 설정이며, 쿠버네티스와 YAML manifest가 이에 해당한다.

## 캡슐화

### 서비스 메시
![Image](https://github.com/user-attachments/assets/90755612-e271-4133-95d2-a72d7791079e)